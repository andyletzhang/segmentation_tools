{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUCCI_input=pd.read_csv('F:/my_data/Segmentation/20240221 FUCCI halo col_glass/contours/PCA-normalized-positions.csv')\n",
    "X=FUCCI_input.iloc[:,:-1]\n",
    "y=pd.get_dummies(FUCCI_input['cell_cycle'])\n",
    "# only select rows with fluorescent info\n",
    "X_signal=X.loc[~y[0]]\n",
    "y_signal=y.loc[~y[0]]\n",
    "\n",
    "y_signal=y_signal.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bfd3ee5fee4c40ac7440631402b554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1122782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FUCCI_input=pd.read_pickle('F:/my_data/Segmentation/20240221 FUCCI halo col_glass/contours/shape-cell_cycle.pkl')\n",
    "X=FUCCI_input['contour']\n",
    "y=pd.get_dummies(FUCCI_input['cell_cycle'])\n",
    "# only select rows with fluorescent info\n",
    "y_signal=y.loc[~y[0]].iloc[:,1:] # drop the NS column\n",
    "X_signal=np.array([contour.points.flatten() for contour in tqdm(X.loc[~y[0]])]) # fetch the points from the contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_signal, y_signal, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# observe that the data is imbalanced\n",
    "plt.pie(np.sum(y_train, axis=0), labels=y_train.columns, colors=['green', 'red', 'orange'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights=np.array(len(y_train)/np.sum(y_train, axis=0))\n",
    "class_weights_dict=dict()\n",
    "for n, weight in enumerate(class_weights):\n",
    "    class_weights_dict[n]=weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_51\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_14 (Flatten)        (None, 200)               0         \n",
      "                                                                 \n",
      " sequential_46 (Sequential)  (None, 300)               60300     \n",
      "                                                                 \n",
      " sequential_47 (Sequential)  (None, 300)               90300     \n",
      "                                                                 \n",
      " sequential_48 (Sequential)  (None, 300)               90300     \n",
      "                                                                 \n",
      " sequential_49 (Sequential)  (None, 300)               90300     \n",
      "                                                                 \n",
      " sequential_50 (Sequential)  (None, 300)               90300     \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 3)                 903       \n",
      "                                                                 \n",
      " softmax_11 (Softmax)        (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 422,403\n",
      "Trainable params: 422,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def DenseDropout(layer_size, activation, drop_rate, kernel_constraint):\n",
    "    x=Sequential([layers.Dense(layer_size, activation=activation, kernel_constraint=kernel_constraint), layers.Dropout(drop_rate)])\n",
    "    return x\n",
    "\n",
    "n_layers=5\n",
    "layer_size=300\n",
    "\n",
    "model = Sequential([#norm_layer,\n",
    "    layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    *[DenseDropout(layer_size, drop_rate=0.2, activation='relu', kernel_constraint=MaxNorm(3)) for layer in range(n_layers)],\n",
    "    layers.Dense(y_train.shape[-1]), # use_bias=False\n",
    "    layers.Softmax()\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.1) # optimizer: SGD, Adam\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])#, metrics=[\"RootMeanSquaredError\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "checkpoint_path=Path('FUCCI_MLP_checkpoints/weights.{epoch:04d}-{val_accuracy:.4f}.hdf5')\n",
    "checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "checkpoint_cb=ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=0, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "351/351 [==============================] - 3s 6ms/step - loss: 44398.8320 - accuracy: 0.3154 - val_loss: 1.1222 - val_accuracy: 0.0947\n",
      "Epoch 2/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3611 - accuracy: 0.2856 - val_loss: 1.0952 - val_accuracy: 0.5018\n",
      "Epoch 3/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 4.3214 - accuracy: 0.3139 - val_loss: 1.0829 - val_accuracy: 0.4035\n",
      "Epoch 4/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3173 - val_loss: 1.1188 - val_accuracy: 0.0947\n",
      "Epoch 5/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3223 - val_loss: 1.0849 - val_accuracy: 0.4035\n",
      "Epoch 6/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2974 - val_loss: 1.0980 - val_accuracy: 0.5018\n",
      "Epoch 7/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3017 - accuracy: 0.3041 - val_loss: 1.0901 - val_accuracy: 0.5018\n",
      "Epoch 8/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2982 - val_loss: 1.0839 - val_accuracy: 0.4035\n",
      "Epoch 9/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2984 - val_loss: 1.1133 - val_accuracy: 0.0947\n",
      "Epoch 10/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2762 - val_loss: 1.1311 - val_accuracy: 0.0947\n",
      "Epoch 11/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3100 - accuracy: 0.3137 - val_loss: 1.1075 - val_accuracy: 0.4035\n",
      "Epoch 12/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.4824 - accuracy: 0.3095 - val_loss: 1.0693 - val_accuracy: 0.5018\n",
      "Epoch 13/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.6977 - accuracy: 0.2973 - val_loss: 1.1073 - val_accuracy: 0.0947\n",
      "Epoch 14/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3111 - val_loss: 1.0939 - val_accuracy: 0.5018\n",
      "Epoch 15/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3048 - val_loss: 1.1033 - val_accuracy: 0.4035\n",
      "Epoch 16/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2973 - val_loss: 1.1217 - val_accuracy: 0.0947\n",
      "Epoch 17/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3153 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 18/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3200 - val_loss: 1.1165 - val_accuracy: 0.0947\n",
      "Epoch 19/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3029 - val_loss: 1.0887 - val_accuracy: 0.4035\n",
      "Epoch 20/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3046 - val_loss: 1.0818 - val_accuracy: 0.5018\n",
      "Epoch 21/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3038 - val_loss: 1.1421 - val_accuracy: 0.0947\n",
      "Epoch 22/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2990 - val_loss: 1.1011 - val_accuracy: 0.4035\n",
      "Epoch 23/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3057 - val_loss: 1.1145 - val_accuracy: 0.0947\n",
      "Epoch 24/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3011 - accuracy: 0.3039 - val_loss: 1.1457 - val_accuracy: 0.0947\n",
      "Epoch 25/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3102 - val_loss: 1.0974 - val_accuracy: 0.5018\n",
      "Epoch 26/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3294 - val_loss: 1.0746 - val_accuracy: 0.5018\n",
      "Epoch 27/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3143 - val_loss: 1.0880 - val_accuracy: 0.5018\n",
      "Epoch 28/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2860 - val_loss: 1.0850 - val_accuracy: 0.4035\n",
      "Epoch 29/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3058 - val_loss: 1.0908 - val_accuracy: 0.5018\n",
      "Epoch 30/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.5626 - accuracy: 0.3032 - val_loss: 1.0802 - val_accuracy: 0.4035\n",
      "Epoch 31/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3025 - val_loss: 1.1094 - val_accuracy: 0.0947\n",
      "Epoch 32/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3063 - val_loss: 1.1021 - val_accuracy: 0.4035\n",
      "Epoch 33/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3058 - val_loss: 1.1027 - val_accuracy: 0.0947\n",
      "Epoch 34/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3080 - val_loss: 1.0854 - val_accuracy: 0.5018\n",
      "Epoch 35/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3001 - val_loss: 1.0903 - val_accuracy: 0.5018\n",
      "Epoch 36/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2953 - val_loss: 1.0811 - val_accuracy: 0.4035\n",
      "Epoch 37/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.2947 - val_loss: 1.0916 - val_accuracy: 0.4035\n",
      "Epoch 38/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3047 - val_loss: 1.0912 - val_accuracy: 0.4035\n",
      "Epoch 39/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3086 - val_loss: 1.1033 - val_accuracy: 0.4035\n",
      "Epoch 40/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3027 - val_loss: 1.0799 - val_accuracy: 0.5018\n",
      "Epoch 41/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3171 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 42/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3175 - val_loss: 1.0994 - val_accuracy: 0.5018\n",
      "Epoch 43/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2977 - val_loss: 1.1142 - val_accuracy: 0.0947\n",
      "Epoch 44/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3059 - val_loss: 1.1225 - val_accuracy: 0.0947\n",
      "Epoch 45/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3058 - val_loss: 1.0986 - val_accuracy: 0.4035\n",
      "Epoch 46/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3119 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 47/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3033 - val_loss: 1.1010 - val_accuracy: 0.4035\n",
      "Epoch 48/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3072 - val_loss: 1.0926 - val_accuracy: 0.4035\n",
      "Epoch 49/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3079 - val_loss: 1.1095 - val_accuracy: 0.4035\n",
      "Epoch 50/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3131 - val_loss: 1.1347 - val_accuracy: 0.0947\n",
      "Epoch 51/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3091 - val_loss: 1.1058 - val_accuracy: 0.0947\n",
      "Epoch 52/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3186 - val_loss: 1.0784 - val_accuracy: 0.5018\n",
      "Epoch 53/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3140 - val_loss: 1.0947 - val_accuracy: 0.5018\n",
      "Epoch 54/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3048 - val_loss: 1.0993 - val_accuracy: 0.4035\n",
      "Epoch 55/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3098 - val_loss: 1.1205 - val_accuracy: 0.0947\n",
      "Epoch 56/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2973 - val_loss: 1.0984 - val_accuracy: 0.4035\n",
      "Epoch 57/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3164 - val_loss: 1.1259 - val_accuracy: 0.0947\n",
      "Epoch 58/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2951 - val_loss: 1.0833 - val_accuracy: 0.5018\n",
      "Epoch 59/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3325 - val_loss: 1.1213 - val_accuracy: 0.0947\n",
      "Epoch 60/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2973 - val_loss: 1.0888 - val_accuracy: 0.4035\n",
      "Epoch 61/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3164 - val_loss: 1.0934 - val_accuracy: 0.4035\n",
      "Epoch 62/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2866 - val_loss: 1.0632 - val_accuracy: 0.5018\n",
      "Epoch 63/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3240 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 64/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3134 - val_loss: 1.1117 - val_accuracy: 0.0947\n",
      "Epoch 65/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3057 - val_loss: 1.0766 - val_accuracy: 0.5018\n",
      "Epoch 66/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3114 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 67/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3179 - val_loss: 1.0998 - val_accuracy: 0.4035\n",
      "Epoch 68/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2968 - val_loss: 1.1208 - val_accuracy: 0.0947\n",
      "Epoch 69/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3034 - val_loss: 1.0943 - val_accuracy: 0.4035\n",
      "Epoch 70/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2925 - val_loss: 1.0857 - val_accuracy: 0.4035\n",
      "Epoch 71/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3064 - val_loss: 1.1055 - val_accuracy: 0.0947\n",
      "Epoch 72/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3126 - val_loss: 1.0826 - val_accuracy: 0.5018\n",
      "Epoch 73/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3026 - val_loss: 1.0863 - val_accuracy: 0.5018\n",
      "Epoch 74/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3106 - val_loss: 1.0787 - val_accuracy: 0.5018\n",
      "Epoch 75/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2972 - val_loss: 1.1118 - val_accuracy: 0.0947\n",
      "Epoch 76/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3200 - val_loss: 1.0998 - val_accuracy: 0.5018\n",
      "Epoch 77/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3037 - val_loss: 1.0885 - val_accuracy: 0.4035\n",
      "Epoch 78/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2940 - val_loss: 1.1003 - val_accuracy: 0.4035\n",
      "Epoch 79/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3073 - val_loss: 1.0878 - val_accuracy: 0.5018\n",
      "Epoch 80/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3108 - val_loss: 1.0930 - val_accuracy: 0.4035\n",
      "Epoch 81/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3070 - val_loss: 1.0889 - val_accuracy: 0.4035\n",
      "Epoch 82/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2920 - val_loss: 1.0826 - val_accuracy: 0.5018\n",
      "Epoch 83/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3177 - val_loss: 1.0697 - val_accuracy: 0.5018\n",
      "Epoch 84/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3065 - val_loss: 1.0789 - val_accuracy: 0.4035\n",
      "Epoch 85/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3123 - val_loss: 1.0996 - val_accuracy: 0.0947\n",
      "Epoch 86/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3037 - val_loss: 1.0919 - val_accuracy: 0.5018\n",
      "Epoch 87/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3018 - val_loss: 1.1036 - val_accuracy: 0.4035\n",
      "Epoch 88/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3022 - val_loss: 1.1351 - val_accuracy: 0.0947\n",
      "Epoch 89/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2985 - val_loss: 1.0767 - val_accuracy: 0.4035\n",
      "Epoch 90/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3112 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 91/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3021 - val_loss: 1.1123 - val_accuracy: 0.0947\n",
      "Epoch 92/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3023 - val_loss: 1.0938 - val_accuracy: 0.5018\n",
      "Epoch 93/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3148 - val_loss: 1.0875 - val_accuracy: 0.4035\n",
      "Epoch 94/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3003 - val_loss: 1.0607 - val_accuracy: 0.4035\n",
      "Epoch 95/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2906 - val_loss: 1.0834 - val_accuracy: 0.5018\n",
      "Epoch 96/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3080 - val_loss: 1.0890 - val_accuracy: 0.5018\n",
      "Epoch 97/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3008 - val_loss: 1.0949 - val_accuracy: 0.4035\n",
      "Epoch 98/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3109 - val_loss: 1.0996 - val_accuracy: 0.5018\n",
      "Epoch 99/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3150 - val_loss: 1.1014 - val_accuracy: 0.5018\n",
      "Epoch 100/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2974 - val_loss: 1.0732 - val_accuracy: 0.4035\n",
      "Epoch 101/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3051 - val_loss: 1.0835 - val_accuracy: 0.5018\n",
      "Epoch 102/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3121 - val_loss: 1.0871 - val_accuracy: 0.5018\n",
      "Epoch 103/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3140 - val_loss: 1.1010 - val_accuracy: 0.4035\n",
      "Epoch 104/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3231 - val_loss: 1.0961 - val_accuracy: 0.4035\n",
      "Epoch 105/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3016 - val_loss: 1.0769 - val_accuracy: 0.5018\n",
      "Epoch 106/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3035 - val_loss: 1.0739 - val_accuracy: 0.5018\n",
      "Epoch 107/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3059 - val_loss: 1.1033 - val_accuracy: 0.0947\n",
      "Epoch 108/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3063 - val_loss: 1.0861 - val_accuracy: 0.5018\n",
      "Epoch 109/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3138 - val_loss: 1.0693 - val_accuracy: 0.4035\n",
      "Epoch 110/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3016 - val_loss: 1.1160 - val_accuracy: 0.0947\n",
      "Epoch 111/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2957 - val_loss: 1.0902 - val_accuracy: 0.4035\n",
      "Epoch 112/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3175 - val_loss: 1.0911 - val_accuracy: 0.4035\n",
      "Epoch 113/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2968 - val_loss: 1.1183 - val_accuracy: 0.0947\n",
      "Epoch 114/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3130 - val_loss: 1.0949 - val_accuracy: 0.4035\n",
      "Epoch 115/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2954 - val_loss: 1.0899 - val_accuracy: 0.5018\n",
      "Epoch 116/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3069 - val_loss: 1.0837 - val_accuracy: 0.4035\n",
      "Epoch 117/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3143 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 118/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2977 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 119/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3022 - val_loss: 1.1264 - val_accuracy: 0.0947\n",
      "Epoch 120/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3169 - val_loss: 1.1057 - val_accuracy: 0.5018\n",
      "Epoch 121/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2894 - val_loss: 1.1046 - val_accuracy: 0.0947\n",
      "Epoch 122/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2922 - val_loss: 1.1040 - val_accuracy: 0.0947\n",
      "Epoch 123/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2983 - val_loss: 1.1229 - val_accuracy: 0.0947\n",
      "Epoch 124/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3257 - val_loss: 1.0820 - val_accuracy: 0.5018\n",
      "Epoch 125/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3255 - val_loss: 1.0849 - val_accuracy: 0.5018\n",
      "Epoch 126/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3015 - val_loss: 1.1440 - val_accuracy: 0.0947\n",
      "Epoch 127/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3058 - val_loss: 1.1254 - val_accuracy: 0.0947\n",
      "Epoch 128/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.2987 - val_loss: 1.1107 - val_accuracy: 0.0947\n",
      "Epoch 129/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3038 - val_loss: 1.1118 - val_accuracy: 0.0947\n",
      "Epoch 130/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3032 - val_loss: 1.0637 - val_accuracy: 0.5018\n",
      "Epoch 131/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3112 - val_loss: 1.1065 - val_accuracy: 0.0947\n",
      "Epoch 132/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2829 - val_loss: 1.0683 - val_accuracy: 0.5018\n",
      "Epoch 133/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2981 - val_loss: 1.1003 - val_accuracy: 0.0947\n",
      "Epoch 134/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3080 - val_loss: 1.0827 - val_accuracy: 0.5018\n",
      "Epoch 135/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3057 - val_loss: 1.1236 - val_accuracy: 0.0947\n",
      "Epoch 136/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2962 - val_loss: 1.1008 - val_accuracy: 0.4035\n",
      "Epoch 137/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3149 - val_loss: 1.0714 - val_accuracy: 0.5018\n",
      "Epoch 138/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2992 - val_loss: 1.1027 - val_accuracy: 0.0947\n",
      "Epoch 139/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3085 - val_loss: 1.0830 - val_accuracy: 0.5018\n",
      "Epoch 140/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3220 - val_loss: 1.1081 - val_accuracy: 0.0947\n",
      "Epoch 141/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2991 - val_loss: 1.0690 - val_accuracy: 0.4035\n",
      "Epoch 142/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3227 - val_loss: 1.1154 - val_accuracy: 0.0947\n",
      "Epoch 143/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3024 - val_loss: 1.1299 - val_accuracy: 0.0947\n",
      "Epoch 144/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3054 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 145/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3078 - val_loss: 1.0896 - val_accuracy: 0.5018\n",
      "Epoch 146/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3050 - val_loss: 1.0732 - val_accuracy: 0.4035\n",
      "Epoch 147/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3028 - val_loss: 1.0878 - val_accuracy: 0.5018\n",
      "Epoch 148/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2990 - val_loss: 1.1031 - val_accuracy: 0.4035\n",
      "Epoch 149/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3022 - val_loss: 1.0792 - val_accuracy: 0.5018\n",
      "Epoch 150/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2999 - val_loss: 1.0836 - val_accuracy: 0.5018\n",
      "Epoch 151/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3014 - accuracy: 0.2781 - val_loss: 1.1235 - val_accuracy: 0.0947\n",
      "Epoch 152/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3016 - val_loss: 1.0925 - val_accuracy: 0.5018\n",
      "Epoch 153/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3016 - val_loss: 1.1216 - val_accuracy: 0.0947\n",
      "Epoch 154/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3018 - accuracy: 0.2886 - val_loss: 1.0924 - val_accuracy: 0.4035\n",
      "Epoch 155/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3021 - val_loss: 1.1175 - val_accuracy: 0.0947\n",
      "Epoch 156/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3058 - val_loss: 1.0971 - val_accuracy: 0.5018\n",
      "Epoch 157/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3108 - val_loss: 1.1042 - val_accuracy: 0.5018\n",
      "Epoch 158/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3041 - val_loss: 1.1288 - val_accuracy: 0.0947\n",
      "Epoch 159/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.2982 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 160/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2941 - val_loss: 1.1041 - val_accuracy: 0.0947\n",
      "Epoch 161/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3144 - val_loss: 1.0911 - val_accuracy: 0.5018\n",
      "Epoch 162/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2979 - val_loss: 1.1244 - val_accuracy: 0.0947\n",
      "Epoch 163/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3095 - val_loss: 1.1221 - val_accuracy: 0.0947\n",
      "Epoch 164/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3127 - val_loss: 1.1028 - val_accuracy: 0.0947\n",
      "Epoch 165/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3061 - val_loss: 1.0926 - val_accuracy: 0.4035\n",
      "Epoch 166/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3146 - val_loss: 1.1147 - val_accuracy: 0.0947\n",
      "Epoch 167/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3062 - val_loss: 1.0857 - val_accuracy: 0.5018\n",
      "Epoch 168/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3185 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 169/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3081 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 170/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3118 - val_loss: 1.0824 - val_accuracy: 0.4035\n",
      "Epoch 171/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3106 - val_loss: 1.0851 - val_accuracy: 0.5018\n",
      "Epoch 172/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3119 - val_loss: 1.1060 - val_accuracy: 0.0947\n",
      "Epoch 173/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2920 - val_loss: 1.1312 - val_accuracy: 0.0947\n",
      "Epoch 174/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3162 - val_loss: 1.0903 - val_accuracy: 0.5018\n",
      "Epoch 175/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3012 - val_loss: 1.1140 - val_accuracy: 0.0947\n",
      "Epoch 176/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3173 - val_loss: 1.0963 - val_accuracy: 0.5018\n",
      "Epoch 177/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3107 - val_loss: 1.1035 - val_accuracy: 0.0947\n",
      "Epoch 178/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3000 - val_loss: 1.0955 - val_accuracy: 0.5018\n",
      "Epoch 179/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3065 - val_loss: 1.1050 - val_accuracy: 0.0947\n",
      "Epoch 180/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3084 - val_loss: 1.1205 - val_accuracy: 0.0947\n",
      "Epoch 181/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3068 - val_loss: 1.0957 - val_accuracy: 0.4035\n",
      "Epoch 182/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3167 - val_loss: 1.0857 - val_accuracy: 0.5018\n",
      "Epoch 183/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3027 - val_loss: 1.0956 - val_accuracy: 0.4035\n",
      "Epoch 184/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3150 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 185/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2990 - accuracy: 0.3121 - val_loss: 1.1117 - val_accuracy: 0.0947\n",
      "Epoch 186/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3142 - val_loss: 1.0948 - val_accuracy: 0.5018\n",
      "Epoch 187/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2991 - val_loss: 1.1063 - val_accuracy: 0.0947\n",
      "Epoch 188/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3034 - val_loss: 1.0882 - val_accuracy: 0.4035\n",
      "Epoch 189/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3154 - val_loss: 1.0929 - val_accuracy: 0.4035\n",
      "Epoch 190/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3206 - val_loss: 1.1209 - val_accuracy: 0.0947\n",
      "Epoch 191/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3136 - val_loss: 1.1136 - val_accuracy: 0.0947\n",
      "Epoch 192/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3255 - val_loss: 1.0854 - val_accuracy: 0.5018\n",
      "Epoch 193/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3067 - val_loss: 1.0988 - val_accuracy: 0.4035\n",
      "Epoch 194/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2921 - val_loss: 1.0774 - val_accuracy: 0.5018\n",
      "Epoch 195/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3149 - val_loss: 1.1050 - val_accuracy: 0.0947\n",
      "Epoch 196/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2914 - val_loss: 1.0816 - val_accuracy: 0.4035\n",
      "Epoch 197/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3210 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 198/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3080 - val_loss: 1.1027 - val_accuracy: 0.0947\n",
      "Epoch 199/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3163 - val_loss: 1.0817 - val_accuracy: 0.4035\n",
      "Epoch 200/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3154 - val_loss: 1.1061 - val_accuracy: 0.0947\n",
      "Epoch 201/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3122 - val_loss: 1.1051 - val_accuracy: 0.0947\n",
      "Epoch 202/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3106 - val_loss: 1.0898 - val_accuracy: 0.4035\n",
      "Epoch 203/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3214 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 204/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3047 - val_loss: 1.0947 - val_accuracy: 0.5018\n",
      "Epoch 205/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3097 - val_loss: 1.1105 - val_accuracy: 0.0947\n",
      "Epoch 206/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3168 - val_loss: 1.1057 - val_accuracy: 0.0947\n",
      "Epoch 207/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3268 - val_loss: 1.0863 - val_accuracy: 0.4035\n",
      "Epoch 208/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3195 - val_loss: 1.0935 - val_accuracy: 0.4035\n",
      "Epoch 209/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3091 - val_loss: 1.0653 - val_accuracy: 0.4035\n",
      "Epoch 210/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3182 - val_loss: 1.1068 - val_accuracy: 0.0947\n",
      "Epoch 211/2000\n",
      "351/351 [==============================] - 2s 7ms/step - loss: 3.3000 - accuracy: 0.3070 - val_loss: 1.1011 - val_accuracy: 0.5018\n",
      "Epoch 212/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3005 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 213/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3215 - val_loss: 1.0980 - val_accuracy: 0.4035\n",
      "Epoch 214/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2953 - val_loss: 1.0888 - val_accuracy: 0.5018\n",
      "Epoch 215/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3025 - val_loss: 1.0946 - val_accuracy: 0.4035\n",
      "Epoch 216/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3148 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 217/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2982 - val_loss: 1.0997 - val_accuracy: 0.5018\n",
      "Epoch 218/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3165 - val_loss: 1.1015 - val_accuracy: 0.5018\n",
      "Epoch 219/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3013 - accuracy: 0.3002 - val_loss: 1.0879 - val_accuracy: 0.4035\n",
      "Epoch 220/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3138 - val_loss: 1.1180 - val_accuracy: 0.0947\n",
      "Epoch 221/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3207 - val_loss: 1.0950 - val_accuracy: 0.5018\n",
      "Epoch 222/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3088 - val_loss: 1.1409 - val_accuracy: 0.0947\n",
      "Epoch 223/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3145 - val_loss: 1.1212 - val_accuracy: 0.0947\n",
      "Epoch 224/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3023 - val_loss: 1.1017 - val_accuracy: 0.4035\n",
      "Epoch 225/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2950 - val_loss: 1.0923 - val_accuracy: 0.4035\n",
      "Epoch 226/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3160 - val_loss: 1.1228 - val_accuracy: 0.0947\n",
      "Epoch 227/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.2891 - val_loss: 1.1015 - val_accuracy: 0.4035\n",
      "Epoch 228/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3139 - val_loss: 1.0882 - val_accuracy: 0.5018\n",
      "Epoch 229/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3018 - val_loss: 1.0805 - val_accuracy: 0.4035\n",
      "Epoch 230/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3042 - val_loss: 1.1149 - val_accuracy: 0.0947\n",
      "Epoch 231/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2916 - val_loss: 1.0928 - val_accuracy: 0.4035\n",
      "Epoch 232/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3066 - val_loss: 1.0967 - val_accuracy: 0.4035\n",
      "Epoch 233/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3020 - val_loss: 1.0778 - val_accuracy: 0.5018\n",
      "Epoch 234/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3125 - val_loss: 1.0919 - val_accuracy: 0.4035\n",
      "Epoch 235/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3105 - val_loss: 1.1104 - val_accuracy: 0.0947\n",
      "Epoch 236/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3045 - val_loss: 1.1072 - val_accuracy: 0.0947\n",
      "Epoch 237/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2967 - val_loss: 1.1181 - val_accuracy: 0.0947\n",
      "Epoch 238/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3144 - val_loss: 1.0750 - val_accuracy: 0.5018\n",
      "Epoch 239/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2987 - val_loss: 1.0874 - val_accuracy: 0.5018\n",
      "Epoch 240/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3333 - val_loss: 1.0830 - val_accuracy: 0.4035\n",
      "Epoch 241/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3154 - val_loss: 1.1012 - val_accuracy: 0.4035\n",
      "Epoch 242/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3080 - val_loss: 1.1074 - val_accuracy: 0.0947\n",
      "Epoch 243/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3052 - val_loss: 1.1163 - val_accuracy: 0.0947\n",
      "Epoch 244/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3071 - val_loss: 1.1194 - val_accuracy: 0.0947\n",
      "Epoch 245/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3012 - val_loss: 1.0748 - val_accuracy: 0.4035\n",
      "Epoch 246/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3003 - val_loss: 1.0943 - val_accuracy: 0.4035\n",
      "Epoch 247/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2893 - val_loss: 1.0870 - val_accuracy: 0.4035\n",
      "Epoch 248/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3053 - val_loss: 1.0804 - val_accuracy: 0.4035\n",
      "Epoch 249/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3156 - val_loss: 1.1402 - val_accuracy: 0.0947\n",
      "Epoch 250/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3069 - val_loss: 1.1072 - val_accuracy: 0.4035\n",
      "Epoch 251/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2998 - val_loss: 1.0941 - val_accuracy: 0.4035\n",
      "Epoch 252/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3004 - val_loss: 1.0968 - val_accuracy: 0.5018\n",
      "Epoch 253/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2946 - val_loss: 1.0813 - val_accuracy: 0.5018\n",
      "Epoch 254/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3221 - val_loss: 1.1007 - val_accuracy: 0.4035\n",
      "Epoch 255/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2962 - val_loss: 1.1036 - val_accuracy: 0.4035\n",
      "Epoch 256/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3150 - val_loss: 1.1109 - val_accuracy: 0.0947\n",
      "Epoch 257/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3014 - accuracy: 0.2990 - val_loss: 1.1275 - val_accuracy: 0.0947\n",
      "Epoch 258/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3096 - val_loss: 1.1235 - val_accuracy: 0.0947\n",
      "Epoch 259/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3027 - val_loss: 1.1168 - val_accuracy: 0.0947\n",
      "Epoch 260/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3016 - val_loss: 1.0820 - val_accuracy: 0.4035\n",
      "Epoch 261/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3057 - val_loss: 1.1242 - val_accuracy: 0.0947\n",
      "Epoch 262/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3081 - val_loss: 1.0978 - val_accuracy: 0.4035\n",
      "Epoch 263/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3013 - accuracy: 0.3274 - val_loss: 1.1277 - val_accuracy: 0.0947\n",
      "Epoch 264/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3055 - val_loss: 1.1049 - val_accuracy: 0.0947\n",
      "Epoch 265/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3010 - accuracy: 0.2960 - val_loss: 1.0783 - val_accuracy: 0.5018\n",
      "Epoch 266/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3067 - val_loss: 1.1350 - val_accuracy: 0.0947\n",
      "Epoch 267/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.2969 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 268/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.2990 - val_loss: 1.1173 - val_accuracy: 0.0947\n",
      "Epoch 269/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2983 - val_loss: 1.0936 - val_accuracy: 0.5018\n",
      "Epoch 270/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3009 - accuracy: 0.3003 - val_loss: 1.1180 - val_accuracy: 0.0947\n",
      "Epoch 271/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2964 - val_loss: 1.0997 - val_accuracy: 0.5018\n",
      "Epoch 272/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2986 - val_loss: 1.1052 - val_accuracy: 0.0947\n",
      "Epoch 273/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3138 - val_loss: 1.1030 - val_accuracy: 0.0947\n",
      "Epoch 274/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3113 - val_loss: 1.0936 - val_accuracy: 0.4035\n",
      "Epoch 275/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3251 - val_loss: 1.1211 - val_accuracy: 0.0947\n",
      "Epoch 276/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3145 - val_loss: 1.0710 - val_accuracy: 0.5018\n",
      "Epoch 277/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2878 - val_loss: 1.1260 - val_accuracy: 0.0947\n",
      "Epoch 278/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3060 - val_loss: 1.1251 - val_accuracy: 0.0947\n",
      "Epoch 279/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3110 - val_loss: 1.1028 - val_accuracy: 0.4035\n",
      "Epoch 280/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3097 - val_loss: 1.1131 - val_accuracy: 0.0947\n",
      "Epoch 281/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3146 - val_loss: 1.0891 - val_accuracy: 0.5018\n",
      "Epoch 282/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3177 - val_loss: 1.1063 - val_accuracy: 0.0947\n",
      "Epoch 283/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3089 - val_loss: 1.0938 - val_accuracy: 0.5018\n",
      "Epoch 284/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2946 - val_loss: 1.0980 - val_accuracy: 0.4035\n",
      "Epoch 285/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3040 - val_loss: 1.0793 - val_accuracy: 0.4035\n",
      "Epoch 286/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3098 - val_loss: 1.1213 - val_accuracy: 0.0947\n",
      "Epoch 287/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3058 - val_loss: 1.1213 - val_accuracy: 0.0947\n",
      "Epoch 288/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3115 - val_loss: 1.1198 - val_accuracy: 0.0947\n",
      "Epoch 289/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3129 - val_loss: 1.0995 - val_accuracy: 0.4035\n",
      "Epoch 290/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3125 - val_loss: 1.0916 - val_accuracy: 0.5018\n",
      "Epoch 291/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3235 - val_loss: 1.0777 - val_accuracy: 0.5018\n",
      "Epoch 292/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2875 - val_loss: 1.1040 - val_accuracy: 0.0947\n",
      "Epoch 293/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2960 - val_loss: 1.0826 - val_accuracy: 0.4035\n",
      "Epoch 294/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3019 - val_loss: 1.1050 - val_accuracy: 0.0947\n",
      "Epoch 295/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2941 - val_loss: 1.0972 - val_accuracy: 0.5018\n",
      "Epoch 296/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3039 - val_loss: 1.0939 - val_accuracy: 0.5018\n",
      "Epoch 297/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3048 - val_loss: 1.1063 - val_accuracy: 0.0947\n",
      "Epoch 298/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3112 - val_loss: 1.1024 - val_accuracy: 0.5018\n",
      "Epoch 299/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3079 - val_loss: 1.1158 - val_accuracy: 0.0947\n",
      "Epoch 300/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3254 - val_loss: 1.0924 - val_accuracy: 0.5018\n",
      "Epoch 301/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3061 - val_loss: 1.1046 - val_accuracy: 0.5018\n",
      "Epoch 302/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2873 - val_loss: 1.0925 - val_accuracy: 0.5018\n",
      "Epoch 303/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2904 - val_loss: 1.0871 - val_accuracy: 0.4035\n",
      "Epoch 304/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2961 - val_loss: 1.0995 - val_accuracy: 0.5018\n",
      "Epoch 305/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3054 - val_loss: 1.1139 - val_accuracy: 0.0947\n",
      "Epoch 306/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3116 - val_loss: 1.0995 - val_accuracy: 0.0947\n",
      "Epoch 307/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3136 - val_loss: 1.0770 - val_accuracy: 0.4035\n",
      "Epoch 308/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3075 - val_loss: 1.0970 - val_accuracy: 0.5018\n",
      "Epoch 309/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3218 - val_loss: 1.1111 - val_accuracy: 0.0947\n",
      "Epoch 310/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3071 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 311/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2993 - val_loss: 1.1025 - val_accuracy: 0.4035\n",
      "Epoch 312/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3277 - val_loss: 1.1003 - val_accuracy: 0.4035\n",
      "Epoch 313/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2859 - val_loss: 1.1297 - val_accuracy: 0.0947\n",
      "Epoch 314/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.2994 - val_loss: 1.1039 - val_accuracy: 0.5018\n",
      "Epoch 315/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3012 - val_loss: 1.1043 - val_accuracy: 0.0947\n",
      "Epoch 316/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3084 - val_loss: 1.1114 - val_accuracy: 0.0947\n",
      "Epoch 317/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3141 - val_loss: 1.0759 - val_accuracy: 0.5018\n",
      "Epoch 318/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3292 - val_loss: 1.0895 - val_accuracy: 0.5018\n",
      "Epoch 319/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3042 - val_loss: 1.1083 - val_accuracy: 0.0947\n",
      "Epoch 320/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3255 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 321/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3271 - val_loss: 1.1335 - val_accuracy: 0.0947\n",
      "Epoch 322/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3210 - val_loss: 1.0756 - val_accuracy: 0.4035\n",
      "Epoch 323/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3119 - val_loss: 1.0934 - val_accuracy: 0.5018\n",
      "Epoch 324/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3034 - val_loss: 1.0830 - val_accuracy: 0.5018\n",
      "Epoch 325/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3020 - val_loss: 1.1106 - val_accuracy: 0.0947\n",
      "Epoch 326/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3039 - val_loss: 1.1298 - val_accuracy: 0.0947\n",
      "Epoch 327/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3250 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 328/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2999 - val_loss: 1.1191 - val_accuracy: 0.0947\n",
      "Epoch 329/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3103 - val_loss: 1.0971 - val_accuracy: 0.4035\n",
      "Epoch 330/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3127 - val_loss: 1.0883 - val_accuracy: 0.4035\n",
      "Epoch 331/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3211 - val_loss: 1.1090 - val_accuracy: 0.4035\n",
      "Epoch 332/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3332 - val_loss: 1.0795 - val_accuracy: 0.5018\n",
      "Epoch 333/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3038 - val_loss: 1.0811 - val_accuracy: 0.5018\n",
      "Epoch 334/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3023 - val_loss: 1.0936 - val_accuracy: 0.4035\n",
      "Epoch 335/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3055 - val_loss: 1.0982 - val_accuracy: 0.4035\n",
      "Epoch 336/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3048 - val_loss: 1.1129 - val_accuracy: 0.0947\n",
      "Epoch 337/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3173 - val_loss: 1.1068 - val_accuracy: 0.0947\n",
      "Epoch 338/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3081 - val_loss: 1.1039 - val_accuracy: 0.0947\n",
      "Epoch 339/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3046 - val_loss: 1.1014 - val_accuracy: 0.5018\n",
      "Epoch 340/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3086 - val_loss: 1.0752 - val_accuracy: 0.4035\n",
      "Epoch 341/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3167 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 342/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3217 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 343/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3001 - val_loss: 1.0869 - val_accuracy: 0.4035\n",
      "Epoch 344/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3170 - val_loss: 1.1010 - val_accuracy: 0.0947\n",
      "Epoch 345/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3070 - val_loss: 1.1058 - val_accuracy: 0.0947\n",
      "Epoch 346/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3081 - val_loss: 1.0812 - val_accuracy: 0.5018\n",
      "Epoch 347/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3089 - val_loss: 1.0745 - val_accuracy: 0.5018\n",
      "Epoch 348/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2991 - accuracy: 0.3106 - val_loss: 1.0867 - val_accuracy: 0.4035\n",
      "Epoch 349/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3156 - val_loss: 1.0979 - val_accuracy: 0.4035\n",
      "Epoch 350/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3178 - val_loss: 1.1242 - val_accuracy: 0.0947\n",
      "Epoch 351/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3041 - val_loss: 1.1262 - val_accuracy: 0.0947\n",
      "Epoch 352/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3180 - val_loss: 1.0838 - val_accuracy: 0.4035\n",
      "Epoch 353/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3020 - val_loss: 1.0799 - val_accuracy: 0.4035\n",
      "Epoch 354/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3116 - val_loss: 1.1232 - val_accuracy: 0.0947\n",
      "Epoch 355/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2886 - val_loss: 1.0970 - val_accuracy: 0.5018\n",
      "Epoch 356/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3138 - val_loss: 1.0897 - val_accuracy: 0.5018\n",
      "Epoch 357/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2996 - val_loss: 1.0997 - val_accuracy: 0.0947\n",
      "Epoch 358/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3056 - val_loss: 1.1222 - val_accuracy: 0.0947\n",
      "Epoch 359/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3045 - val_loss: 1.0898 - val_accuracy: 0.4035\n",
      "Epoch 360/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3099 - val_loss: 1.0975 - val_accuracy: 0.5018\n",
      "Epoch 361/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3171 - val_loss: 1.0739 - val_accuracy: 0.5018\n",
      "Epoch 362/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2830 - val_loss: 1.0703 - val_accuracy: 0.5018\n",
      "Epoch 363/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3040 - val_loss: 1.1141 - val_accuracy: 0.0947\n",
      "Epoch 364/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2997 - val_loss: 1.0946 - val_accuracy: 0.5018\n",
      "Epoch 365/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3099 - val_loss: 1.1345 - val_accuracy: 0.0947\n",
      "Epoch 366/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3025 - val_loss: 1.1099 - val_accuracy: 0.0947\n",
      "Epoch 367/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2993 - val_loss: 1.0644 - val_accuracy: 0.4035\n",
      "Epoch 368/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3033 - val_loss: 1.0843 - val_accuracy: 0.5018\n",
      "Epoch 369/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3020 - val_loss: 1.0979 - val_accuracy: 0.5018\n",
      "Epoch 370/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2989 - val_loss: 1.1293 - val_accuracy: 0.0947\n",
      "Epoch 371/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3010 - val_loss: 1.0836 - val_accuracy: 0.4035\n",
      "Epoch 372/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2993 - val_loss: 1.1291 - val_accuracy: 0.0947\n",
      "Epoch 373/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2910 - val_loss: 1.0680 - val_accuracy: 0.4035\n",
      "Epoch 374/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3065 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 375/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3041 - val_loss: 1.0883 - val_accuracy: 0.5018\n",
      "Epoch 376/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2955 - val_loss: 1.1111 - val_accuracy: 0.0947\n",
      "Epoch 377/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.2953 - val_loss: 1.1022 - val_accuracy: 0.4035\n",
      "Epoch 378/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3169 - val_loss: 1.1179 - val_accuracy: 0.0947\n",
      "Epoch 379/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3096 - val_loss: 1.0976 - val_accuracy: 0.4035\n",
      "Epoch 380/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3159 - val_loss: 1.1056 - val_accuracy: 0.5018\n",
      "Epoch 381/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3110 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 382/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3136 - val_loss: 1.0941 - val_accuracy: 0.5018\n",
      "Epoch 383/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3093 - val_loss: 1.1319 - val_accuracy: 0.0947\n",
      "Epoch 384/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2901 - val_loss: 1.0932 - val_accuracy: 0.4035\n",
      "Epoch 385/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3085 - val_loss: 1.1262 - val_accuracy: 0.0947\n",
      "Epoch 386/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.2965 - val_loss: 1.0747 - val_accuracy: 0.4035\n",
      "Epoch 387/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2956 - val_loss: 1.0992 - val_accuracy: 0.4035\n",
      "Epoch 388/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3080 - val_loss: 1.1009 - val_accuracy: 0.5018\n",
      "Epoch 389/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3298 - val_loss: 1.1100 - val_accuracy: 0.0947\n",
      "Epoch 390/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3032 - val_loss: 1.1108 - val_accuracy: 0.0947\n",
      "Epoch 391/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2921 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 392/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3331 - val_loss: 1.1139 - val_accuracy: 0.0947\n",
      "Epoch 393/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3068 - val_loss: 1.1076 - val_accuracy: 0.0947\n",
      "Epoch 394/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2954 - val_loss: 1.1228 - val_accuracy: 0.0947\n",
      "Epoch 395/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3039 - val_loss: 1.0777 - val_accuracy: 0.5018\n",
      "Epoch 396/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3143 - val_loss: 1.1124 - val_accuracy: 0.0947\n",
      "Epoch 397/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3111 - val_loss: 1.0893 - val_accuracy: 0.5018\n",
      "Epoch 398/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2993 - val_loss: 1.1043 - val_accuracy: 0.0947\n",
      "Epoch 399/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3034 - val_loss: 1.1196 - val_accuracy: 0.0947\n",
      "Epoch 400/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3119 - val_loss: 1.0916 - val_accuracy: 0.4035\n",
      "Epoch 401/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3220 - val_loss: 1.0901 - val_accuracy: 0.5018\n",
      "Epoch 402/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3219 - val_loss: 1.1019 - val_accuracy: 0.0947\n",
      "Epoch 403/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3076 - val_loss: 1.1099 - val_accuracy: 0.4035\n",
      "Epoch 404/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2968 - val_loss: 1.0933 - val_accuracy: 0.5018\n",
      "Epoch 405/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3229 - val_loss: 1.1140 - val_accuracy: 0.0947\n",
      "Epoch 406/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3019 - val_loss: 1.0921 - val_accuracy: 0.4035\n",
      "Epoch 407/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3010 - val_loss: 1.1259 - val_accuracy: 0.0947\n",
      "Epoch 408/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3069 - val_loss: 1.0778 - val_accuracy: 0.5018\n",
      "Epoch 409/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3026 - val_loss: 1.1122 - val_accuracy: 0.0947\n",
      "Epoch 410/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3140 - val_loss: 1.0868 - val_accuracy: 0.5018\n",
      "Epoch 411/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3056 - val_loss: 1.0858 - val_accuracy: 0.5018\n",
      "Epoch 412/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3161 - val_loss: 1.1062 - val_accuracy: 0.0947\n",
      "Epoch 413/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3124 - val_loss: 1.1105 - val_accuracy: 0.0947\n",
      "Epoch 414/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3232 - val_loss: 1.1179 - val_accuracy: 0.0947\n",
      "Epoch 415/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3086 - val_loss: 1.0947 - val_accuracy: 0.4035\n",
      "Epoch 416/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.2944 - val_loss: 1.0990 - val_accuracy: 0.5018\n",
      "Epoch 417/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3009 - accuracy: 0.3045 - val_loss: 1.1065 - val_accuracy: 0.0947\n",
      "Epoch 418/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3042 - val_loss: 1.1137 - val_accuracy: 0.0947\n",
      "Epoch 419/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3067 - val_loss: 1.0879 - val_accuracy: 0.5018\n",
      "Epoch 420/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3102 - val_loss: 1.1088 - val_accuracy: 0.0947\n",
      "Epoch 421/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2957 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 422/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3017 - val_loss: 1.0927 - val_accuracy: 0.4035\n",
      "Epoch 423/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3230 - val_loss: 1.0796 - val_accuracy: 0.5018\n",
      "Epoch 424/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3068 - val_loss: 1.1229 - val_accuracy: 0.0947\n",
      "Epoch 425/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2963 - val_loss: 1.1218 - val_accuracy: 0.0947\n",
      "Epoch 426/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3064 - val_loss: 1.1319 - val_accuracy: 0.0947\n",
      "Epoch 427/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3049 - val_loss: 1.0754 - val_accuracy: 0.5018\n",
      "Epoch 428/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3019 - val_loss: 1.0775 - val_accuracy: 0.4035\n",
      "Epoch 429/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3217 - val_loss: 1.1071 - val_accuracy: 0.0947\n",
      "Epoch 430/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3014 - val_loss: 1.1100 - val_accuracy: 0.0947\n",
      "Epoch 431/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3042 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 432/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3181 - val_loss: 1.1204 - val_accuracy: 0.0947\n",
      "Epoch 433/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3046 - val_loss: 1.0741 - val_accuracy: 0.5018\n",
      "Epoch 434/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3190 - val_loss: 1.0812 - val_accuracy: 0.4035\n",
      "Epoch 435/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3027 - val_loss: 1.0920 - val_accuracy: 0.4035\n",
      "Epoch 436/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3250 - val_loss: 1.0918 - val_accuracy: 0.5018\n",
      "Epoch 437/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3130 - val_loss: 1.0925 - val_accuracy: 0.5018\n",
      "Epoch 438/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3031 - val_loss: 1.0928 - val_accuracy: 0.5018\n",
      "Epoch 439/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3062 - val_loss: 1.0871 - val_accuracy: 0.4035\n",
      "Epoch 440/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2978 - val_loss: 1.0942 - val_accuracy: 0.4035\n",
      "Epoch 441/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2948 - val_loss: 1.0919 - val_accuracy: 0.4035\n",
      "Epoch 442/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3058 - val_loss: 1.0958 - val_accuracy: 0.5018\n",
      "Epoch 443/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3009 - val_loss: 1.0889 - val_accuracy: 0.4035\n",
      "Epoch 444/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.2995 - val_loss: 1.0858 - val_accuracy: 0.5018\n",
      "Epoch 445/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3122 - val_loss: 1.1162 - val_accuracy: 0.0947\n",
      "Epoch 446/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3107 - val_loss: 1.1357 - val_accuracy: 0.0947\n",
      "Epoch 447/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3042 - val_loss: 1.1230 - val_accuracy: 0.0947\n",
      "Epoch 448/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3051 - val_loss: 1.0852 - val_accuracy: 0.5018\n",
      "Epoch 449/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3201 - val_loss: 1.1214 - val_accuracy: 0.0947\n",
      "Epoch 450/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3116 - val_loss: 1.1033 - val_accuracy: 0.0947\n",
      "Epoch 451/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3092 - val_loss: 1.0788 - val_accuracy: 0.4035\n",
      "Epoch 452/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2940 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 453/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3102 - val_loss: 1.1198 - val_accuracy: 0.0947\n",
      "Epoch 454/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3238 - val_loss: 1.0895 - val_accuracy: 0.4035\n",
      "Epoch 455/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3084 - val_loss: 1.0771 - val_accuracy: 0.5018\n",
      "Epoch 456/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2946 - val_loss: 1.1041 - val_accuracy: 0.4035\n",
      "Epoch 457/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3012 - val_loss: 1.1048 - val_accuracy: 0.4035\n",
      "Epoch 458/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3366 - val_loss: 1.0917 - val_accuracy: 0.5018\n",
      "Epoch 459/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3206 - val_loss: 1.0858 - val_accuracy: 0.4035\n",
      "Epoch 460/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3142 - val_loss: 1.1048 - val_accuracy: 0.4035\n",
      "Epoch 461/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3211 - val_loss: 1.0889 - val_accuracy: 0.4035\n",
      "Epoch 462/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3103 - val_loss: 1.0920 - val_accuracy: 0.4035\n",
      "Epoch 463/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3082 - val_loss: 1.1143 - val_accuracy: 0.0947\n",
      "Epoch 464/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2977 - val_loss: 1.0881 - val_accuracy: 0.5018\n",
      "Epoch 465/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3000 - val_loss: 1.0774 - val_accuracy: 0.4035\n",
      "Epoch 466/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3105 - val_loss: 1.1106 - val_accuracy: 0.0947\n",
      "Epoch 467/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3150 - val_loss: 1.0844 - val_accuracy: 0.4035\n",
      "Epoch 468/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3157 - val_loss: 1.0907 - val_accuracy: 0.5018\n",
      "Epoch 469/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3063 - val_loss: 1.0969 - val_accuracy: 0.4035\n",
      "Epoch 470/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2957 - val_loss: 1.0621 - val_accuracy: 0.4035\n",
      "Epoch 471/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3047 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 472/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.2972 - val_loss: 1.1111 - val_accuracy: 0.0947\n",
      "Epoch 473/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3115 - val_loss: 1.0752 - val_accuracy: 0.5018\n",
      "Epoch 474/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3049 - val_loss: 1.0940 - val_accuracy: 0.4035\n",
      "Epoch 475/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3036 - val_loss: 1.0818 - val_accuracy: 0.4035\n",
      "Epoch 476/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2902 - val_loss: 1.0890 - val_accuracy: 0.4035\n",
      "Epoch 477/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2846 - val_loss: 1.1015 - val_accuracy: 0.4035\n",
      "Epoch 478/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3130 - val_loss: 1.0771 - val_accuracy: 0.5018\n",
      "Epoch 479/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3029 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 480/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2993 - accuracy: 0.3072 - val_loss: 1.1090 - val_accuracy: 0.0947\n",
      "Epoch 481/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3011 - accuracy: 0.3095 - val_loss: 1.1225 - val_accuracy: 0.0947\n",
      "Epoch 482/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3262 - val_loss: 1.0912 - val_accuracy: 0.4035\n",
      "Epoch 483/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3127 - val_loss: 1.1217 - val_accuracy: 0.0947\n",
      "Epoch 484/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3282 - val_loss: 1.0971 - val_accuracy: 0.4035\n",
      "Epoch 485/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3262 - val_loss: 1.0913 - val_accuracy: 0.5018\n",
      "Epoch 486/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3081 - val_loss: 1.0841 - val_accuracy: 0.4035\n",
      "Epoch 487/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3132 - val_loss: 1.0952 - val_accuracy: 0.5018\n",
      "Epoch 488/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3237 - val_loss: 1.0664 - val_accuracy: 0.4035\n",
      "Epoch 489/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3028 - val_loss: 1.0895 - val_accuracy: 0.4035\n",
      "Epoch 490/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3079 - val_loss: 1.1026 - val_accuracy: 0.5018\n",
      "Epoch 491/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3164 - val_loss: 1.1038 - val_accuracy: 0.4035\n",
      "Epoch 492/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3136 - val_loss: 1.1002 - val_accuracy: 0.4035\n",
      "Epoch 493/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3056 - val_loss: 1.0913 - val_accuracy: 0.4035\n",
      "Epoch 494/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3118 - val_loss: 1.1111 - val_accuracy: 0.4035\n",
      "Epoch 495/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3142 - val_loss: 1.1117 - val_accuracy: 0.0947\n",
      "Epoch 496/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3188 - val_loss: 1.1265 - val_accuracy: 0.0947\n",
      "Epoch 497/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3007 - val_loss: 1.0699 - val_accuracy: 0.5018\n",
      "Epoch 498/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3052 - val_loss: 1.1028 - val_accuracy: 0.0947\n",
      "Epoch 499/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3158 - val_loss: 1.1209 - val_accuracy: 0.0947\n",
      "Epoch 500/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2985 - val_loss: 1.0977 - val_accuracy: 0.5018\n",
      "Epoch 501/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3127 - val_loss: 1.1111 - val_accuracy: 0.0947\n",
      "Epoch 502/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3053 - val_loss: 1.0916 - val_accuracy: 0.4035\n",
      "Epoch 503/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3087 - val_loss: 1.1102 - val_accuracy: 0.0947\n",
      "Epoch 504/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3082 - val_loss: 1.0888 - val_accuracy: 0.4035\n",
      "Epoch 505/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2917 - val_loss: 1.0949 - val_accuracy: 0.4035\n",
      "Epoch 506/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3088 - val_loss: 1.1103 - val_accuracy: 0.0947\n",
      "Epoch 507/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3152 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 508/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3175 - val_loss: 1.1027 - val_accuracy: 0.0947\n",
      "Epoch 509/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2988 - val_loss: 1.0923 - val_accuracy: 0.4035\n",
      "Epoch 510/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3036 - val_loss: 1.1013 - val_accuracy: 0.4035\n",
      "Epoch 511/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2999 - val_loss: 1.0876 - val_accuracy: 0.5018\n",
      "Epoch 512/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2997 - val_loss: 1.0912 - val_accuracy: 0.5018\n",
      "Epoch 513/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3190 - val_loss: 1.0907 - val_accuracy: 0.5018\n",
      "Epoch 514/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3026 - val_loss: 1.0958 - val_accuracy: 0.5018\n",
      "Epoch 515/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3248 - val_loss: 1.1108 - val_accuracy: 0.4035\n",
      "Epoch 516/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3034 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 517/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3029 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 518/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3091 - val_loss: 1.1015 - val_accuracy: 0.0947\n",
      "Epoch 519/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3081 - val_loss: 1.0981 - val_accuracy: 0.4035\n",
      "Epoch 520/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2957 - val_loss: 1.0937 - val_accuracy: 0.5018\n",
      "Epoch 521/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3224 - val_loss: 1.1164 - val_accuracy: 0.0947\n",
      "Epoch 522/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3132 - val_loss: 1.0828 - val_accuracy: 0.5018\n",
      "Epoch 523/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3038 - val_loss: 1.1069 - val_accuracy: 0.0947\n",
      "Epoch 524/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3059 - val_loss: 1.1199 - val_accuracy: 0.0947\n",
      "Epoch 525/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3163 - val_loss: 1.1277 - val_accuracy: 0.0947\n",
      "Epoch 526/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3020 - val_loss: 1.0783 - val_accuracy: 0.5018\n",
      "Epoch 527/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3134 - val_loss: 1.0973 - val_accuracy: 0.5018\n",
      "Epoch 528/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3200 - val_loss: 1.0829 - val_accuracy: 0.5018\n",
      "Epoch 529/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3093 - val_loss: 1.1161 - val_accuracy: 0.0947\n",
      "Epoch 530/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3088 - val_loss: 1.1065 - val_accuracy: 0.0947\n",
      "Epoch 531/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2980 - val_loss: 1.0825 - val_accuracy: 0.4035\n",
      "Epoch 532/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3065 - val_loss: 1.1083 - val_accuracy: 0.0947\n",
      "Epoch 533/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3326 - val_loss: 1.0854 - val_accuracy: 0.5018\n",
      "Epoch 534/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3169 - val_loss: 1.1035 - val_accuracy: 0.4035\n",
      "Epoch 535/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2973 - val_loss: 1.1124 - val_accuracy: 0.0947\n",
      "Epoch 536/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2986 - val_loss: 1.1262 - val_accuracy: 0.0947\n",
      "Epoch 537/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3097 - val_loss: 1.0730 - val_accuracy: 0.4035\n",
      "Epoch 538/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3142 - val_loss: 1.0989 - val_accuracy: 0.5018\n",
      "Epoch 539/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3070 - val_loss: 1.1093 - val_accuracy: 0.0947\n",
      "Epoch 540/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2888 - val_loss: 1.0729 - val_accuracy: 0.5018\n",
      "Epoch 541/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2999 - val_loss: 1.0968 - val_accuracy: 0.5018\n",
      "Epoch 542/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3074 - val_loss: 1.1151 - val_accuracy: 0.0947\n",
      "Epoch 543/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2984 - val_loss: 1.0785 - val_accuracy: 0.5018\n",
      "Epoch 544/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3164 - val_loss: 1.1067 - val_accuracy: 0.4035\n",
      "Epoch 545/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3146 - val_loss: 1.0896 - val_accuracy: 0.4035\n",
      "Epoch 546/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3013 - val_loss: 1.1008 - val_accuracy: 0.5018\n",
      "Epoch 547/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3000 - val_loss: 1.1072 - val_accuracy: 0.0947\n",
      "Epoch 548/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3026 - val_loss: 1.0758 - val_accuracy: 0.4035\n",
      "Epoch 549/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3037 - val_loss: 1.0908 - val_accuracy: 0.4035\n",
      "Epoch 550/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3014 - accuracy: 0.3066 - val_loss: 1.1126 - val_accuracy: 0.0947\n",
      "Epoch 551/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2999 - val_loss: 1.0605 - val_accuracy: 0.4035\n",
      "Epoch 552/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3170 - val_loss: 1.0974 - val_accuracy: 0.5018\n",
      "Epoch 553/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3046 - val_loss: 1.0928 - val_accuracy: 0.4035\n",
      "Epoch 554/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3108 - val_loss: 1.0938 - val_accuracy: 0.4035\n",
      "Epoch 555/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3140 - val_loss: 1.1235 - val_accuracy: 0.0947\n",
      "Epoch 556/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3107 - val_loss: 1.0813 - val_accuracy: 0.4035\n",
      "Epoch 557/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3020 - val_loss: 1.0835 - val_accuracy: 0.4035\n",
      "Epoch 558/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3194 - val_loss: 1.1121 - val_accuracy: 0.0947\n",
      "Epoch 559/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3142 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 560/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.2969 - val_loss: 1.0773 - val_accuracy: 0.5018\n",
      "Epoch 561/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3056 - val_loss: 1.0947 - val_accuracy: 0.5018\n",
      "Epoch 562/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3279 - val_loss: 1.0886 - val_accuracy: 0.5018\n",
      "Epoch 563/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2905 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 564/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2997 - val_loss: 1.0804 - val_accuracy: 0.5018\n",
      "Epoch 565/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3019 - val_loss: 1.0774 - val_accuracy: 0.5018\n",
      "Epoch 566/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2981 - val_loss: 1.0641 - val_accuracy: 0.5018\n",
      "Epoch 567/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3097 - val_loss: 1.1239 - val_accuracy: 0.0947\n",
      "Epoch 568/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3137 - val_loss: 1.0889 - val_accuracy: 0.5018\n",
      "Epoch 569/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3108 - val_loss: 1.1018 - val_accuracy: 0.0947\n",
      "Epoch 570/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.2933 - val_loss: 1.0736 - val_accuracy: 0.5018\n",
      "Epoch 571/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3015 - val_loss: 1.0696 - val_accuracy: 0.5018\n",
      "Epoch 572/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2915 - val_loss: 1.0962 - val_accuracy: 0.4035\n",
      "Epoch 573/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3047 - val_loss: 1.0817 - val_accuracy: 0.5018\n",
      "Epoch 574/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3085 - val_loss: 1.0899 - val_accuracy: 0.4035\n",
      "Epoch 575/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3027 - val_loss: 1.0722 - val_accuracy: 0.4035\n",
      "Epoch 576/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2935 - val_loss: 1.0905 - val_accuracy: 0.5018\n",
      "Epoch 577/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3157 - val_loss: 1.0731 - val_accuracy: 0.5018\n",
      "Epoch 578/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3176 - val_loss: 1.0661 - val_accuracy: 0.5018\n",
      "Epoch 579/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3226 - val_loss: 1.1341 - val_accuracy: 0.0947\n",
      "Epoch 580/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3205 - val_loss: 1.0966 - val_accuracy: 0.5018\n",
      "Epoch 581/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3109 - val_loss: 1.1175 - val_accuracy: 0.0947\n",
      "Epoch 582/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3068 - val_loss: 1.1287 - val_accuracy: 0.0947\n",
      "Epoch 583/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3215 - val_loss: 1.0523 - val_accuracy: 0.5018\n",
      "Epoch 584/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2970 - val_loss: 1.0967 - val_accuracy: 0.4035\n",
      "Epoch 585/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3131 - val_loss: 1.1145 - val_accuracy: 0.0947\n",
      "Epoch 586/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3315 - val_loss: 1.0788 - val_accuracy: 0.5018\n",
      "Epoch 587/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3182 - val_loss: 1.0932 - val_accuracy: 0.5018\n",
      "Epoch 588/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2959 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 589/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3011 - val_loss: 1.0998 - val_accuracy: 0.0947\n",
      "Epoch 590/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.2998 - val_loss: 1.0708 - val_accuracy: 0.5018\n",
      "Epoch 591/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2975 - val_loss: 1.0939 - val_accuracy: 0.5018\n",
      "Epoch 592/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3231 - val_loss: 1.0848 - val_accuracy: 0.4035\n",
      "Epoch 593/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3064 - val_loss: 1.0749 - val_accuracy: 0.4035\n",
      "Epoch 594/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3010 - accuracy: 0.3056 - val_loss: 1.1196 - val_accuracy: 0.0947\n",
      "Epoch 595/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3090 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 596/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3084 - val_loss: 1.0939 - val_accuracy: 0.4035\n",
      "Epoch 597/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3066 - val_loss: 1.0818 - val_accuracy: 0.4035\n",
      "Epoch 598/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3011 - accuracy: 0.3190 - val_loss: 1.0822 - val_accuracy: 0.5018\n",
      "Epoch 599/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2947 - val_loss: 1.0876 - val_accuracy: 0.4035\n",
      "Epoch 600/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2986 - val_loss: 1.0897 - val_accuracy: 0.4035\n",
      "Epoch 601/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3102 - val_loss: 1.0818 - val_accuracy: 0.4035\n",
      "Epoch 602/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2971 - val_loss: 1.1430 - val_accuracy: 0.0947\n",
      "Epoch 603/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3042 - val_loss: 1.1011 - val_accuracy: 0.5018\n",
      "Epoch 604/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3234 - val_loss: 1.0880 - val_accuracy: 0.4035\n",
      "Epoch 605/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3169 - val_loss: 1.1209 - val_accuracy: 0.4035\n",
      "Epoch 606/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3162 - val_loss: 1.0807 - val_accuracy: 0.4035\n",
      "Epoch 607/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3182 - val_loss: 1.1007 - val_accuracy: 0.0947\n",
      "Epoch 608/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3329 - val_loss: 1.0953 - val_accuracy: 0.4035\n",
      "Epoch 609/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3189 - val_loss: 1.1368 - val_accuracy: 0.0947\n",
      "Epoch 610/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3063 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 611/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3186 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 612/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3086 - val_loss: 1.0998 - val_accuracy: 0.5018\n",
      "Epoch 613/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3185 - val_loss: 1.0828 - val_accuracy: 0.5018\n",
      "Epoch 614/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3075 - val_loss: 1.0935 - val_accuracy: 0.5018\n",
      "Epoch 615/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3159 - val_loss: 1.1010 - val_accuracy: 0.0947\n",
      "Epoch 616/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3008 - val_loss: 1.1137 - val_accuracy: 0.0947\n",
      "Epoch 617/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3224 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 618/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3014 - val_loss: 1.1048 - val_accuracy: 0.0947\n",
      "Epoch 619/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3068 - val_loss: 1.1039 - val_accuracy: 0.5018\n",
      "Epoch 620/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3259 - val_loss: 1.0967 - val_accuracy: 0.5018\n",
      "Epoch 621/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3197 - val_loss: 1.1159 - val_accuracy: 0.0947\n",
      "Epoch 622/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3025 - val_loss: 1.0953 - val_accuracy: 0.4035\n",
      "Epoch 623/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3210 - val_loss: 1.1020 - val_accuracy: 0.0947\n",
      "Epoch 624/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3099 - val_loss: 1.0706 - val_accuracy: 0.4035\n",
      "Epoch 625/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3027 - val_loss: 1.0766 - val_accuracy: 0.5018\n",
      "Epoch 626/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3010 - val_loss: 1.1128 - val_accuracy: 0.0947\n",
      "Epoch 627/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3020 - val_loss: 1.1230 - val_accuracy: 0.0947\n",
      "Epoch 628/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3061 - val_loss: 1.0798 - val_accuracy: 0.5018\n",
      "Epoch 629/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3090 - val_loss: 1.1108 - val_accuracy: 0.4035\n",
      "Epoch 630/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2968 - val_loss: 1.0950 - val_accuracy: 0.5018\n",
      "Epoch 631/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3197 - val_loss: 1.0959 - val_accuracy: 0.4035\n",
      "Epoch 632/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3114 - val_loss: 1.1143 - val_accuracy: 0.0947\n",
      "Epoch 633/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3169 - val_loss: 1.1485 - val_accuracy: 0.0947\n",
      "Epoch 634/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3186 - val_loss: 1.1048 - val_accuracy: 0.0947\n",
      "Epoch 635/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3033 - val_loss: 1.1000 - val_accuracy: 0.5018\n",
      "Epoch 636/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3188 - val_loss: 1.1039 - val_accuracy: 0.0947\n",
      "Epoch 637/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3048 - val_loss: 1.0772 - val_accuracy: 0.5018\n",
      "Epoch 638/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3067 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 639/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3034 - val_loss: 1.0868 - val_accuracy: 0.5018\n",
      "Epoch 640/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3038 - val_loss: 1.1340 - val_accuracy: 0.0947\n",
      "Epoch 641/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3063 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 642/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3109 - val_loss: 1.0897 - val_accuracy: 0.5018\n",
      "Epoch 643/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3043 - val_loss: 1.1195 - val_accuracy: 0.0947\n",
      "Epoch 644/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3092 - val_loss: 1.0889 - val_accuracy: 0.4035\n",
      "Epoch 645/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3037 - val_loss: 1.1231 - val_accuracy: 0.0947\n",
      "Epoch 646/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3164 - val_loss: 1.0948 - val_accuracy: 0.4035\n",
      "Epoch 647/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3098 - val_loss: 1.1212 - val_accuracy: 0.0947\n",
      "Epoch 648/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3127 - val_loss: 1.1125 - val_accuracy: 0.0947\n",
      "Epoch 649/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3067 - val_loss: 1.0831 - val_accuracy: 0.5018\n",
      "Epoch 650/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3202 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 651/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3253 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 652/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3001 - val_loss: 1.0992 - val_accuracy: 0.4035\n",
      "Epoch 653/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3045 - val_loss: 1.0900 - val_accuracy: 0.5018\n",
      "Epoch 654/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3026 - val_loss: 1.0923 - val_accuracy: 0.5018\n",
      "Epoch 655/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2985 - val_loss: 1.1199 - val_accuracy: 0.0947\n",
      "Epoch 656/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3091 - val_loss: 1.1078 - val_accuracy: 0.0947\n",
      "Epoch 657/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3204 - val_loss: 1.1121 - val_accuracy: 0.0947\n",
      "Epoch 658/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.2899 - val_loss: 1.1025 - val_accuracy: 0.0947\n",
      "Epoch 659/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3037 - val_loss: 1.1072 - val_accuracy: 0.0947\n",
      "Epoch 660/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3093 - val_loss: 1.0994 - val_accuracy: 0.0947\n",
      "Epoch 661/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3067 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 662/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2984 - val_loss: 1.0724 - val_accuracy: 0.5018\n",
      "Epoch 663/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3167 - val_loss: 1.0963 - val_accuracy: 0.4035\n",
      "Epoch 664/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3194 - val_loss: 1.0821 - val_accuracy: 0.4035\n",
      "Epoch 665/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3061 - val_loss: 1.0811 - val_accuracy: 0.4035\n",
      "Epoch 666/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2927 - val_loss: 1.1206 - val_accuracy: 0.0947\n",
      "Epoch 667/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3053 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 668/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2988 - val_loss: 1.0931 - val_accuracy: 0.4035\n",
      "Epoch 669/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2911 - val_loss: 1.0964 - val_accuracy: 0.4035\n",
      "Epoch 670/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3083 - val_loss: 1.0957 - val_accuracy: 0.4035\n",
      "Epoch 671/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3131 - val_loss: 1.0921 - val_accuracy: 0.4035\n",
      "Epoch 672/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2993 - accuracy: 0.3059 - val_loss: 1.0731 - val_accuracy: 0.4035\n",
      "Epoch 673/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3000 - val_loss: 1.0662 - val_accuracy: 0.5018\n",
      "Epoch 674/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3191 - val_loss: 1.0815 - val_accuracy: 0.4035\n",
      "Epoch 675/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2884 - val_loss: 1.1144 - val_accuracy: 0.0947\n",
      "Epoch 676/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3091 - val_loss: 1.0962 - val_accuracy: 0.5018\n",
      "Epoch 677/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3038 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 678/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3041 - val_loss: 1.1019 - val_accuracy: 0.0947\n",
      "Epoch 679/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3049 - val_loss: 1.1176 - val_accuracy: 0.0947\n",
      "Epoch 680/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2985 - val_loss: 1.1202 - val_accuracy: 0.0947\n",
      "Epoch 681/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2990 - val_loss: 1.1042 - val_accuracy: 0.0947\n",
      "Epoch 682/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3134 - val_loss: 1.1124 - val_accuracy: 0.0947\n",
      "Epoch 683/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3200 - val_loss: 1.0886 - val_accuracy: 0.4035\n",
      "Epoch 684/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3129 - val_loss: 1.0909 - val_accuracy: 0.5018\n",
      "Epoch 685/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3120 - val_loss: 1.0681 - val_accuracy: 0.5018\n",
      "Epoch 686/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2970 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 687/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3085 - val_loss: 1.1019 - val_accuracy: 0.0947\n",
      "Epoch 688/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2900 - val_loss: 1.1044 - val_accuracy: 0.4035\n",
      "Epoch 689/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3022 - val_loss: 1.0800 - val_accuracy: 0.4035\n",
      "Epoch 690/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3136 - val_loss: 1.1182 - val_accuracy: 0.0947\n",
      "Epoch 691/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2972 - val_loss: 1.1020 - val_accuracy: 0.0947\n",
      "Epoch 692/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3053 - val_loss: 1.0891 - val_accuracy: 0.5018\n",
      "Epoch 693/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2966 - val_loss: 1.1088 - val_accuracy: 0.0947\n",
      "Epoch 694/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3222 - val_loss: 1.1027 - val_accuracy: 0.0947\n",
      "Epoch 695/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3032 - val_loss: 1.0878 - val_accuracy: 0.5018\n",
      "Epoch 696/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3073 - val_loss: 1.1165 - val_accuracy: 0.4035\n",
      "Epoch 697/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3105 - val_loss: 1.0953 - val_accuracy: 0.5018\n",
      "Epoch 698/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3084 - val_loss: 1.1266 - val_accuracy: 0.0947\n",
      "Epoch 699/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3132 - val_loss: 1.1226 - val_accuracy: 0.0947\n",
      "Epoch 700/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3117 - val_loss: 1.0834 - val_accuracy: 0.5018\n",
      "Epoch 701/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3091 - val_loss: 1.0983 - val_accuracy: 0.5018\n",
      "Epoch 702/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3149 - val_loss: 1.1376 - val_accuracy: 0.0947\n",
      "Epoch 703/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3115 - val_loss: 1.1121 - val_accuracy: 0.4035\n",
      "Epoch 704/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3169 - val_loss: 1.0944 - val_accuracy: 0.4035\n",
      "Epoch 705/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3415 - val_loss: 1.1204 - val_accuracy: 0.0947\n",
      "Epoch 706/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3137 - val_loss: 1.0942 - val_accuracy: 0.5018\n",
      "Epoch 707/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3205 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 708/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3171 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 709/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3054 - val_loss: 1.0986 - val_accuracy: 0.5018\n",
      "Epoch 710/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3037 - val_loss: 1.0958 - val_accuracy: 0.5018\n",
      "Epoch 711/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3164 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 712/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3053 - val_loss: 1.1053 - val_accuracy: 0.0947\n",
      "Epoch 713/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3121 - val_loss: 1.1240 - val_accuracy: 0.0947\n",
      "Epoch 714/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3238 - val_loss: 1.0978 - val_accuracy: 0.5018\n",
      "Epoch 715/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3047 - val_loss: 1.1158 - val_accuracy: 0.0947\n",
      "Epoch 716/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3243 - val_loss: 1.1103 - val_accuracy: 0.0947\n",
      "Epoch 717/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2867 - val_loss: 1.1090 - val_accuracy: 0.0947\n",
      "Epoch 718/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3005 - val_loss: 1.1081 - val_accuracy: 0.0947\n",
      "Epoch 719/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3225 - val_loss: 1.0862 - val_accuracy: 0.4035\n",
      "Epoch 720/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2969 - val_loss: 1.1240 - val_accuracy: 0.0947\n",
      "Epoch 721/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3019 - val_loss: 1.1075 - val_accuracy: 0.0947\n",
      "Epoch 722/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3300 - val_loss: 1.1006 - val_accuracy: 0.5018\n",
      "Epoch 723/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2989 - val_loss: 1.0992 - val_accuracy: 0.4035\n",
      "Epoch 724/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3047 - val_loss: 1.0982 - val_accuracy: 0.5018\n",
      "Epoch 725/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3129 - val_loss: 1.0934 - val_accuracy: 0.4035\n",
      "Epoch 726/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3193 - val_loss: 1.0875 - val_accuracy: 0.4035\n",
      "Epoch 727/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3042 - val_loss: 1.1010 - val_accuracy: 0.0947\n",
      "Epoch 728/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2890 - val_loss: 1.0821 - val_accuracy: 0.4035\n",
      "Epoch 729/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2949 - val_loss: 1.0714 - val_accuracy: 0.4035\n",
      "Epoch 730/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3074 - val_loss: 1.1076 - val_accuracy: 0.4035\n",
      "Epoch 731/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2956 - val_loss: 1.0899 - val_accuracy: 0.5018\n",
      "Epoch 732/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2972 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 733/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2923 - val_loss: 1.0683 - val_accuracy: 0.5018\n",
      "Epoch 734/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2981 - val_loss: 1.0984 - val_accuracy: 0.5018\n",
      "Epoch 735/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3056 - val_loss: 1.0961 - val_accuracy: 0.5018\n",
      "Epoch 736/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3111 - val_loss: 1.0519 - val_accuracy: 0.5018\n",
      "Epoch 737/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3011 - accuracy: 0.3156 - val_loss: 1.0772 - val_accuracy: 0.4035\n",
      "Epoch 738/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3106 - val_loss: 1.1173 - val_accuracy: 0.0947\n",
      "Epoch 739/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3006 - val_loss: 1.1248 - val_accuracy: 0.0947\n",
      "Epoch 740/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2861 - val_loss: 1.0968 - val_accuracy: 0.4035\n",
      "Epoch 741/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3164 - val_loss: 1.1332 - val_accuracy: 0.0947\n",
      "Epoch 742/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3091 - val_loss: 1.0961 - val_accuracy: 0.5018\n",
      "Epoch 743/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3041 - val_loss: 1.1201 - val_accuracy: 0.0947\n",
      "Epoch 744/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2984 - val_loss: 1.1067 - val_accuracy: 0.0947\n",
      "Epoch 745/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3160 - val_loss: 1.0978 - val_accuracy: 0.4035\n",
      "Epoch 746/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3208 - val_loss: 1.1002 - val_accuracy: 0.4035\n",
      "Epoch 747/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3186 - val_loss: 1.0860 - val_accuracy: 0.5018\n",
      "Epoch 748/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3020 - val_loss: 1.0703 - val_accuracy: 0.5018\n",
      "Epoch 749/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3078 - val_loss: 1.1013 - val_accuracy: 0.5018\n",
      "Epoch 750/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3077 - val_loss: 1.0945 - val_accuracy: 0.5018\n",
      "Epoch 751/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3082 - val_loss: 1.0965 - val_accuracy: 0.4035\n",
      "Epoch 752/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3036 - val_loss: 1.0953 - val_accuracy: 0.5018\n",
      "Epoch 753/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3234 - val_loss: 1.0704 - val_accuracy: 0.5018\n",
      "Epoch 754/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2959 - val_loss: 1.1261 - val_accuracy: 0.0947\n",
      "Epoch 755/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3104 - val_loss: 1.0930 - val_accuracy: 0.4035\n",
      "Epoch 756/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3100 - val_loss: 1.1048 - val_accuracy: 0.4035\n",
      "Epoch 757/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3119 - val_loss: 1.1107 - val_accuracy: 0.0947\n",
      "Epoch 758/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3013 - accuracy: 0.2983 - val_loss: 1.0927 - val_accuracy: 0.5018\n",
      "Epoch 759/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3354 - val_loss: 1.0955 - val_accuracy: 0.5018\n",
      "Epoch 760/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2890 - val_loss: 1.1059 - val_accuracy: 0.0947\n",
      "Epoch 761/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3232 - val_loss: 1.0908 - val_accuracy: 0.4035\n",
      "Epoch 762/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3203 - val_loss: 1.0865 - val_accuracy: 0.5018\n",
      "Epoch 763/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3129 - val_loss: 1.1020 - val_accuracy: 0.5018\n",
      "Epoch 764/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3021 - val_loss: 1.1024 - val_accuracy: 0.0947\n",
      "Epoch 765/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3199 - val_loss: 1.0943 - val_accuracy: 0.5018\n",
      "Epoch 766/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3219 - val_loss: 1.1099 - val_accuracy: 0.0947\n",
      "Epoch 767/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3022 - val_loss: 1.1229 - val_accuracy: 0.0947\n",
      "Epoch 768/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3036 - val_loss: 1.0838 - val_accuracy: 0.5018\n",
      "Epoch 769/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3010 - val_loss: 1.1191 - val_accuracy: 0.0947\n",
      "Epoch 770/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2942 - val_loss: 1.1183 - val_accuracy: 0.0947\n",
      "Epoch 771/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3290 - val_loss: 1.1159 - val_accuracy: 0.0947\n",
      "Epoch 772/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3233 - val_loss: 1.0853 - val_accuracy: 0.5018\n",
      "Epoch 773/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3068 - val_loss: 1.0913 - val_accuracy: 0.5018\n",
      "Epoch 774/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3103 - val_loss: 1.1126 - val_accuracy: 0.0947\n",
      "Epoch 775/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2993 - accuracy: 0.3185 - val_loss: 1.0901 - val_accuracy: 0.4035\n",
      "Epoch 776/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3213 - val_loss: 1.1223 - val_accuracy: 0.0947\n",
      "Epoch 777/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3086 - val_loss: 1.1011 - val_accuracy: 0.0947\n",
      "Epoch 778/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3154 - val_loss: 1.1186 - val_accuracy: 0.0947\n",
      "Epoch 779/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3234 - val_loss: 1.0915 - val_accuracy: 0.4035\n",
      "Epoch 780/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3236 - val_loss: 1.0657 - val_accuracy: 0.5018\n",
      "Epoch 781/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3011 - accuracy: 0.3099 - val_loss: 1.0757 - val_accuracy: 0.4035\n",
      "Epoch 782/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2985 - val_loss: 1.1029 - val_accuracy: 0.4035\n",
      "Epoch 783/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3152 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 784/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3152 - val_loss: 1.1146 - val_accuracy: 0.0947\n",
      "Epoch 785/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3022 - val_loss: 1.1087 - val_accuracy: 0.0947\n",
      "Epoch 786/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3138 - val_loss: 1.0976 - val_accuracy: 0.4035\n",
      "Epoch 787/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3121 - val_loss: 1.1051 - val_accuracy: 0.0947\n",
      "Epoch 788/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3072 - val_loss: 1.1027 - val_accuracy: 0.4035\n",
      "Epoch 789/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3275 - val_loss: 1.1184 - val_accuracy: 0.0947\n",
      "Epoch 790/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3074 - val_loss: 1.1328 - val_accuracy: 0.0947\n",
      "Epoch 791/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2971 - val_loss: 1.1120 - val_accuracy: 0.0947\n",
      "Epoch 792/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3051 - val_loss: 1.0941 - val_accuracy: 0.5018\n",
      "Epoch 793/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2972 - val_loss: 1.1360 - val_accuracy: 0.0947\n",
      "Epoch 794/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3027 - val_loss: 1.1107 - val_accuracy: 0.0947\n",
      "Epoch 795/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2933 - val_loss: 1.1006 - val_accuracy: 0.0947\n",
      "Epoch 796/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3101 - val_loss: 1.1013 - val_accuracy: 0.5018\n",
      "Epoch 797/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3115 - val_loss: 1.1076 - val_accuracy: 0.4035\n",
      "Epoch 798/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2956 - val_loss: 1.1058 - val_accuracy: 0.0947\n",
      "Epoch 799/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3157 - val_loss: 1.0870 - val_accuracy: 0.4035\n",
      "Epoch 800/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3202 - val_loss: 1.1075 - val_accuracy: 0.0947\n",
      "Epoch 801/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2978 - val_loss: 1.0906 - val_accuracy: 0.5018\n",
      "Epoch 802/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3166 - val_loss: 1.1009 - val_accuracy: 0.4035\n",
      "Epoch 803/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3143 - val_loss: 1.1067 - val_accuracy: 0.0947\n",
      "Epoch 804/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3167 - val_loss: 1.1201 - val_accuracy: 0.0947\n",
      "Epoch 805/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3064 - val_loss: 1.0980 - val_accuracy: 0.4035\n",
      "Epoch 806/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3015 - val_loss: 1.0899 - val_accuracy: 0.5018\n",
      "Epoch 807/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2971 - val_loss: 1.0879 - val_accuracy: 0.4035\n",
      "Epoch 808/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3195 - val_loss: 1.0986 - val_accuracy: 0.4035\n",
      "Epoch 809/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3111 - val_loss: 1.0844 - val_accuracy: 0.5018\n",
      "Epoch 810/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3174 - val_loss: 1.0959 - val_accuracy: 0.4035\n",
      "Epoch 811/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3085 - val_loss: 1.1022 - val_accuracy: 0.4035\n",
      "Epoch 812/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3126 - val_loss: 1.1072 - val_accuracy: 0.0947\n",
      "Epoch 813/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3020 - val_loss: 1.1044 - val_accuracy: 0.0947\n",
      "Epoch 814/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3052 - val_loss: 1.0869 - val_accuracy: 0.4035\n",
      "Epoch 815/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3164 - val_loss: 1.0925 - val_accuracy: 0.4035\n",
      "Epoch 816/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3219 - val_loss: 1.0967 - val_accuracy: 0.4035\n",
      "Epoch 817/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3119 - val_loss: 1.1300 - val_accuracy: 0.0947\n",
      "Epoch 818/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3128 - val_loss: 1.1075 - val_accuracy: 0.0947\n",
      "Epoch 819/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2976 - val_loss: 1.0823 - val_accuracy: 0.4035\n",
      "Epoch 820/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3329 - val_loss: 1.0954 - val_accuracy: 0.5018\n",
      "Epoch 821/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3125 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 822/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3125 - val_loss: 1.1191 - val_accuracy: 0.4035\n",
      "Epoch 823/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3137 - val_loss: 1.1015 - val_accuracy: 0.0947\n",
      "Epoch 824/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3076 - val_loss: 1.0981 - val_accuracy: 0.4035\n",
      "Epoch 825/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3021 - val_loss: 1.1051 - val_accuracy: 0.0947\n",
      "Epoch 826/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3291 - val_loss: 1.1040 - val_accuracy: 0.0947\n",
      "Epoch 827/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.2916 - val_loss: 1.0874 - val_accuracy: 0.5018\n",
      "Epoch 828/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3155 - val_loss: 1.0871 - val_accuracy: 0.5018\n",
      "Epoch 829/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3205 - val_loss: 1.0552 - val_accuracy: 0.5018\n",
      "Epoch 830/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3196 - val_loss: 1.0871 - val_accuracy: 0.5018\n",
      "Epoch 831/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3028 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 832/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3188 - val_loss: 1.0826 - val_accuracy: 0.5018\n",
      "Epoch 833/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2950 - val_loss: 1.0904 - val_accuracy: 0.4035\n",
      "Epoch 834/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2934 - val_loss: 1.1006 - val_accuracy: 0.4035\n",
      "Epoch 835/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3082 - val_loss: 1.0992 - val_accuracy: 0.5018\n",
      "Epoch 836/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3313 - val_loss: 1.1099 - val_accuracy: 0.0947\n",
      "Epoch 837/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3227 - val_loss: 1.0655 - val_accuracy: 0.5018\n",
      "Epoch 838/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3143 - val_loss: 1.1106 - val_accuracy: 0.0947\n",
      "Epoch 839/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3014 - val_loss: 1.0970 - val_accuracy: 0.5018\n",
      "Epoch 840/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3022 - val_loss: 1.1053 - val_accuracy: 0.4035\n",
      "Epoch 841/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3102 - val_loss: 1.0811 - val_accuracy: 0.4035\n",
      "Epoch 842/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3026 - val_loss: 1.0902 - val_accuracy: 0.4035\n",
      "Epoch 843/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3081 - val_loss: 1.0834 - val_accuracy: 0.5018\n",
      "Epoch 844/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3011 - accuracy: 0.2838 - val_loss: 1.0914 - val_accuracy: 0.4035\n",
      "Epoch 845/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3076 - val_loss: 1.1183 - val_accuracy: 0.0947\n",
      "Epoch 846/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3122 - val_loss: 1.1003 - val_accuracy: 0.4035\n",
      "Epoch 847/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3073 - val_loss: 1.0897 - val_accuracy: 0.4035\n",
      "Epoch 848/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3087 - val_loss: 1.0867 - val_accuracy: 0.5018\n",
      "Epoch 849/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3068 - val_loss: 1.1000 - val_accuracy: 0.5018\n",
      "Epoch 850/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3113 - val_loss: 1.1307 - val_accuracy: 0.0947\n",
      "Epoch 851/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3133 - val_loss: 1.1003 - val_accuracy: 0.5018\n",
      "Epoch 852/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3017 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 853/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3232 - val_loss: 1.1377 - val_accuracy: 0.0947\n",
      "Epoch 854/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2993 - val_loss: 1.0857 - val_accuracy: 0.4035\n",
      "Epoch 855/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3100 - val_loss: 1.1175 - val_accuracy: 0.0947\n",
      "Epoch 856/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2982 - val_loss: 1.1236 - val_accuracy: 0.0947\n",
      "Epoch 857/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2880 - val_loss: 1.0994 - val_accuracy: 0.5018\n",
      "Epoch 858/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3197 - val_loss: 1.1299 - val_accuracy: 0.0947\n",
      "Epoch 859/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3236 - val_loss: 1.0807 - val_accuracy: 0.5018\n",
      "Epoch 860/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2936 - val_loss: 1.1098 - val_accuracy: 0.0947\n",
      "Epoch 861/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3133 - val_loss: 1.0841 - val_accuracy: 0.4035\n",
      "Epoch 862/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3043 - val_loss: 1.1038 - val_accuracy: 0.0947\n",
      "Epoch 863/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2938 - val_loss: 1.1042 - val_accuracy: 0.4035\n",
      "Epoch 864/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3001 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 865/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3166 - val_loss: 1.0892 - val_accuracy: 0.5018\n",
      "Epoch 866/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2950 - val_loss: 1.0961 - val_accuracy: 0.4035\n",
      "Epoch 867/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3055 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 868/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3005 - val_loss: 1.0956 - val_accuracy: 0.5018\n",
      "Epoch 869/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3105 - val_loss: 1.1100 - val_accuracy: 0.0947\n",
      "Epoch 870/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3105 - val_loss: 1.0880 - val_accuracy: 0.4035\n",
      "Epoch 871/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3080 - val_loss: 1.1047 - val_accuracy: 0.0947\n",
      "Epoch 872/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3118 - val_loss: 1.0983 - val_accuracy: 0.5018\n",
      "Epoch 873/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2922 - val_loss: 1.0979 - val_accuracy: 0.4035\n",
      "Epoch 874/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3105 - val_loss: 1.1136 - val_accuracy: 0.0947\n",
      "Epoch 875/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3172 - val_loss: 1.1113 - val_accuracy: 0.0947\n",
      "Epoch 876/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3097 - val_loss: 1.0726 - val_accuracy: 0.5018\n",
      "Epoch 877/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3105 - val_loss: 1.0943 - val_accuracy: 0.4035\n",
      "Epoch 878/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3279 - val_loss: 1.0812 - val_accuracy: 0.5018\n",
      "Epoch 879/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3144 - val_loss: 1.1161 - val_accuracy: 0.0947\n",
      "Epoch 880/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3095 - val_loss: 1.0970 - val_accuracy: 0.4035\n",
      "Epoch 881/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2947 - val_loss: 1.1191 - val_accuracy: 0.0947\n",
      "Epoch 882/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2983 - val_loss: 1.1244 - val_accuracy: 0.0947\n",
      "Epoch 883/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3174 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 884/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3016 - val_loss: 1.1199 - val_accuracy: 0.0947\n",
      "Epoch 885/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3052 - val_loss: 1.0803 - val_accuracy: 0.4035\n",
      "Epoch 886/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3092 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 887/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3110 - val_loss: 1.0907 - val_accuracy: 0.5018\n",
      "Epoch 888/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3079 - val_loss: 1.0989 - val_accuracy: 0.5018\n",
      "Epoch 889/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3043 - val_loss: 1.0941 - val_accuracy: 0.4035\n",
      "Epoch 890/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3044 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 891/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3064 - val_loss: 1.1038 - val_accuracy: 0.0947\n",
      "Epoch 892/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3146 - val_loss: 1.1016 - val_accuracy: 0.0947\n",
      "Epoch 893/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2981 - val_loss: 1.0748 - val_accuracy: 0.4035\n",
      "Epoch 894/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2979 - val_loss: 1.0871 - val_accuracy: 0.4035\n",
      "Epoch 895/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3087 - val_loss: 1.0886 - val_accuracy: 0.4035\n",
      "Epoch 896/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2969 - val_loss: 1.0839 - val_accuracy: 0.5018\n",
      "Epoch 897/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3053 - val_loss: 1.0794 - val_accuracy: 0.5018\n",
      "Epoch 898/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3359 - val_loss: 1.1299 - val_accuracy: 0.0947\n",
      "Epoch 899/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2964 - val_loss: 1.1108 - val_accuracy: 0.0947\n",
      "Epoch 900/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3013 - accuracy: 0.2976 - val_loss: 1.1118 - val_accuracy: 0.0947\n",
      "Epoch 901/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2939 - val_loss: 1.0823 - val_accuracy: 0.5018\n",
      "Epoch 902/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3047 - val_loss: 1.0977 - val_accuracy: 0.4035\n",
      "Epoch 903/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3135 - val_loss: 1.0914 - val_accuracy: 0.5018\n",
      "Epoch 904/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3130 - val_loss: 1.1162 - val_accuracy: 0.0947\n",
      "Epoch 905/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3026 - val_loss: 1.1073 - val_accuracy: 0.4035\n",
      "Epoch 906/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3081 - val_loss: 1.1057 - val_accuracy: 0.0947\n",
      "Epoch 907/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3121 - val_loss: 1.1088 - val_accuracy: 0.4035\n",
      "Epoch 908/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3019 - val_loss: 1.0938 - val_accuracy: 0.4035\n",
      "Epoch 909/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3080 - val_loss: 1.0767 - val_accuracy: 0.4035\n",
      "Epoch 910/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3168 - val_loss: 1.0983 - val_accuracy: 0.5018\n",
      "Epoch 911/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3125 - val_loss: 1.1048 - val_accuracy: 0.0947\n",
      "Epoch 912/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3170 - val_loss: 1.1090 - val_accuracy: 0.0947\n",
      "Epoch 913/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3031 - val_loss: 1.1469 - val_accuracy: 0.0947\n",
      "Epoch 914/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3140 - val_loss: 1.0985 - val_accuracy: 0.4035\n",
      "Epoch 915/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3128 - val_loss: 1.0808 - val_accuracy: 0.4035\n",
      "Epoch 916/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2943 - val_loss: 1.1025 - val_accuracy: 0.0947\n",
      "Epoch 917/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3030 - val_loss: 1.0959 - val_accuracy: 0.5018\n",
      "Epoch 918/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3075 - val_loss: 1.0772 - val_accuracy: 0.4035\n",
      "Epoch 919/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3173 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 920/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2981 - val_loss: 1.0832 - val_accuracy: 0.4035\n",
      "Epoch 921/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3036 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 922/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3153 - val_loss: 1.1112 - val_accuracy: 0.0947\n",
      "Epoch 923/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3046 - val_loss: 1.1074 - val_accuracy: 0.0947\n",
      "Epoch 924/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3033 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 925/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2968 - val_loss: 1.1030 - val_accuracy: 0.5018\n",
      "Epoch 926/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.2958 - val_loss: 1.1065 - val_accuracy: 0.0947\n",
      "Epoch 927/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3180 - val_loss: 1.0840 - val_accuracy: 0.5018\n",
      "Epoch 928/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3050 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 929/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3167 - val_loss: 1.1148 - val_accuracy: 0.0947\n",
      "Epoch 930/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3143 - val_loss: 1.1092 - val_accuracy: 0.0947\n",
      "Epoch 931/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3062 - val_loss: 1.1120 - val_accuracy: 0.0947\n",
      "Epoch 932/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3131 - val_loss: 1.1309 - val_accuracy: 0.0947\n",
      "Epoch 933/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3058 - val_loss: 1.0756 - val_accuracy: 0.5018\n",
      "Epoch 934/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3042 - val_loss: 1.0858 - val_accuracy: 0.5018\n",
      "Epoch 935/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3117 - val_loss: 1.1280 - val_accuracy: 0.0947\n",
      "Epoch 936/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3173 - val_loss: 1.0722 - val_accuracy: 0.4035\n",
      "Epoch 937/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3111 - val_loss: 1.1017 - val_accuracy: 0.0947\n",
      "Epoch 938/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3021 - val_loss: 1.1301 - val_accuracy: 0.0947\n",
      "Epoch 939/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3291 - val_loss: 1.1121 - val_accuracy: 0.0947\n",
      "Epoch 940/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3259 - val_loss: 1.0998 - val_accuracy: 0.5018\n",
      "Epoch 941/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3222 - val_loss: 1.1053 - val_accuracy: 0.0947\n",
      "Epoch 942/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2904 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 943/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3053 - val_loss: 1.1176 - val_accuracy: 0.0947\n",
      "Epoch 944/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3010 - val_loss: 1.1075 - val_accuracy: 0.4035\n",
      "Epoch 945/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3054 - val_loss: 1.0849 - val_accuracy: 0.5018\n",
      "Epoch 946/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3111 - val_loss: 1.0890 - val_accuracy: 0.5018\n",
      "Epoch 947/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3200 - val_loss: 1.0798 - val_accuracy: 0.5018\n",
      "Epoch 948/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3082 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 949/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3028 - val_loss: 1.0869 - val_accuracy: 0.5018\n",
      "Epoch 950/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3014 - val_loss: 1.0968 - val_accuracy: 0.5018\n",
      "Epoch 951/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3270 - val_loss: 1.0772 - val_accuracy: 0.5018\n",
      "Epoch 952/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3120 - val_loss: 1.0957 - val_accuracy: 0.4035\n",
      "Epoch 953/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3075 - val_loss: 1.0810 - val_accuracy: 0.5018\n",
      "Epoch 954/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3016 - val_loss: 1.1003 - val_accuracy: 0.5018\n",
      "Epoch 955/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3148 - val_loss: 1.1063 - val_accuracy: 0.0947\n",
      "Epoch 956/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3090 - val_loss: 1.0966 - val_accuracy: 0.4035\n",
      "Epoch 957/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3128 - val_loss: 1.1404 - val_accuracy: 0.0947\n",
      "Epoch 958/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3219 - val_loss: 1.0855 - val_accuracy: 0.5018\n",
      "Epoch 959/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3045 - val_loss: 1.0785 - val_accuracy: 0.5018\n",
      "Epoch 960/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3160 - val_loss: 1.1051 - val_accuracy: 0.4035\n",
      "Epoch 961/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2970 - val_loss: 1.0741 - val_accuracy: 0.4035\n",
      "Epoch 962/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3103 - val_loss: 1.1182 - val_accuracy: 0.0947\n",
      "Epoch 963/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2982 - val_loss: 1.1165 - val_accuracy: 0.0947\n",
      "Epoch 964/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3060 - val_loss: 1.1197 - val_accuracy: 0.0947\n",
      "Epoch 965/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3128 - val_loss: 1.0557 - val_accuracy: 0.4035\n",
      "Epoch 966/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3099 - val_loss: 1.1041 - val_accuracy: 0.0947\n",
      "Epoch 967/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3065 - val_loss: 1.1020 - val_accuracy: 0.0947\n",
      "Epoch 968/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2975 - val_loss: 1.1147 - val_accuracy: 0.0947\n",
      "Epoch 969/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2999 - val_loss: 1.0801 - val_accuracy: 0.5018\n",
      "Epoch 970/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3042 - val_loss: 1.0636 - val_accuracy: 0.5018\n",
      "Epoch 971/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2954 - val_loss: 1.0905 - val_accuracy: 0.5018\n",
      "Epoch 972/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3074 - val_loss: 1.1026 - val_accuracy: 0.4035\n",
      "Epoch 973/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3038 - val_loss: 1.1015 - val_accuracy: 0.4035\n",
      "Epoch 974/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2990 - val_loss: 1.1035 - val_accuracy: 0.0947\n",
      "Epoch 975/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3012 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 976/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3226 - val_loss: 1.0890 - val_accuracy: 0.4035\n",
      "Epoch 977/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3007 - val_loss: 1.0992 - val_accuracy: 0.0947\n",
      "Epoch 978/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3253 - val_loss: 1.1116 - val_accuracy: 0.0947\n",
      "Epoch 979/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2944 - val_loss: 1.0911 - val_accuracy: 0.4035\n",
      "Epoch 980/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3165 - val_loss: 1.1198 - val_accuracy: 0.0947\n",
      "Epoch 981/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3025 - val_loss: 1.0866 - val_accuracy: 0.5018\n",
      "Epoch 982/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3210 - val_loss: 1.1022 - val_accuracy: 0.0947\n",
      "Epoch 983/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3109 - val_loss: 1.1523 - val_accuracy: 0.0947\n",
      "Epoch 984/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2890 - val_loss: 1.0881 - val_accuracy: 0.4035\n",
      "Epoch 985/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3134 - val_loss: 1.0998 - val_accuracy: 0.5018\n",
      "Epoch 986/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3125 - val_loss: 1.1023 - val_accuracy: 0.4035\n",
      "Epoch 987/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3010 - val_loss: 1.1231 - val_accuracy: 0.0947\n",
      "Epoch 988/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3224 - val_loss: 1.0872 - val_accuracy: 0.5018\n",
      "Epoch 989/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3116 - val_loss: 1.0860 - val_accuracy: 0.5018\n",
      "Epoch 990/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3193 - val_loss: 1.1050 - val_accuracy: 0.4035\n",
      "Epoch 991/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3011 - val_loss: 1.0926 - val_accuracy: 0.4035\n",
      "Epoch 992/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3063 - val_loss: 1.1311 - val_accuracy: 0.0947\n",
      "Epoch 993/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2937 - val_loss: 1.1174 - val_accuracy: 0.0947\n",
      "Epoch 994/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3026 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 995/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3003 - val_loss: 1.1158 - val_accuracy: 0.0947\n",
      "Epoch 996/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3052 - val_loss: 1.1061 - val_accuracy: 0.0947\n",
      "Epoch 997/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3054 - val_loss: 1.1258 - val_accuracy: 0.0947\n",
      "Epoch 998/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2973 - val_loss: 1.1250 - val_accuracy: 0.0947\n",
      "Epoch 999/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3129 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 1000/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3018 - accuracy: 0.2983 - val_loss: 1.0801 - val_accuracy: 0.5018\n",
      "Epoch 1001/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2993 - accuracy: 0.3065 - val_loss: 1.0845 - val_accuracy: 0.5018\n",
      "Epoch 1002/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3030 - val_loss: 1.1139 - val_accuracy: 0.0947\n",
      "Epoch 1003/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3092 - val_loss: 1.0869 - val_accuracy: 0.5018\n",
      "Epoch 1004/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3127 - val_loss: 1.1151 - val_accuracy: 0.0947\n",
      "Epoch 1005/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3035 - val_loss: 1.1017 - val_accuracy: 0.4035\n",
      "Epoch 1006/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3058 - val_loss: 1.1035 - val_accuracy: 0.4035\n",
      "Epoch 1007/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2995 - val_loss: 1.1245 - val_accuracy: 0.0947\n",
      "Epoch 1008/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2912 - val_loss: 1.0821 - val_accuracy: 0.5018\n",
      "Epoch 1009/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3167 - val_loss: 1.0966 - val_accuracy: 0.5018\n",
      "Epoch 1010/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3103 - val_loss: 1.0919 - val_accuracy: 0.4035\n",
      "Epoch 1011/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2938 - val_loss: 1.0921 - val_accuracy: 0.4035\n",
      "Epoch 1012/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.2978 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 1013/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3029 - val_loss: 1.1302 - val_accuracy: 0.0947\n",
      "Epoch 1014/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2993 - val_loss: 1.0935 - val_accuracy: 0.5018\n",
      "Epoch 1015/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2939 - val_loss: 1.0987 - val_accuracy: 0.4035\n",
      "Epoch 1016/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3102 - val_loss: 1.1000 - val_accuracy: 0.4035\n",
      "Epoch 1017/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3020 - val_loss: 1.1112 - val_accuracy: 0.4035\n",
      "Epoch 1018/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3155 - val_loss: 1.0857 - val_accuracy: 0.5018\n",
      "Epoch 1019/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2998 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 1020/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3054 - val_loss: 1.0979 - val_accuracy: 0.4035\n",
      "Epoch 1021/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3263 - val_loss: 1.1255 - val_accuracy: 0.0947\n",
      "Epoch 1022/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3167 - val_loss: 1.1047 - val_accuracy: 0.0947\n",
      "Epoch 1023/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2813 - val_loss: 1.1030 - val_accuracy: 0.0947\n",
      "Epoch 1024/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3052 - val_loss: 1.0901 - val_accuracy: 0.5018\n",
      "Epoch 1025/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3187 - val_loss: 1.0978 - val_accuracy: 0.4035\n",
      "Epoch 1026/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3044 - val_loss: 1.1157 - val_accuracy: 0.0947\n",
      "Epoch 1027/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3036 - val_loss: 1.0907 - val_accuracy: 0.5018\n",
      "Epoch 1028/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2969 - val_loss: 1.1029 - val_accuracy: 0.0947\n",
      "Epoch 1029/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2980 - val_loss: 1.1224 - val_accuracy: 0.0947\n",
      "Epoch 1030/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3112 - val_loss: 1.0749 - val_accuracy: 0.4035\n",
      "Epoch 1031/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3150 - val_loss: 1.0924 - val_accuracy: 0.5018\n",
      "Epoch 1032/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3010 - val_loss: 1.1098 - val_accuracy: 0.0947\n",
      "Epoch 1033/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2914 - val_loss: 1.0752 - val_accuracy: 0.4035\n",
      "Epoch 1034/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3139 - val_loss: 1.0836 - val_accuracy: 0.5018\n",
      "Epoch 1035/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3076 - val_loss: 1.0895 - val_accuracy: 0.4035\n",
      "Epoch 1036/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3075 - val_loss: 1.1243 - val_accuracy: 0.0947\n",
      "Epoch 1037/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2990 - val_loss: 1.0889 - val_accuracy: 0.4035\n",
      "Epoch 1038/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3248 - val_loss: 1.0973 - val_accuracy: 0.5018\n",
      "Epoch 1039/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2985 - val_loss: 1.0945 - val_accuracy: 0.5018\n",
      "Epoch 1040/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3059 - val_loss: 1.1049 - val_accuracy: 0.0947\n",
      "Epoch 1041/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3162 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 1042/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3143 - val_loss: 1.0809 - val_accuracy: 0.4035\n",
      "Epoch 1043/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3038 - val_loss: 1.0778 - val_accuracy: 0.4035\n",
      "Epoch 1044/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3102 - val_loss: 1.1231 - val_accuracy: 0.0947\n",
      "Epoch 1045/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3031 - val_loss: 1.0823 - val_accuracy: 0.5018\n",
      "Epoch 1046/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3091 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 1047/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3263 - val_loss: 1.0727 - val_accuracy: 0.5018\n",
      "Epoch 1048/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2964 - val_loss: 1.0836 - val_accuracy: 0.4035\n",
      "Epoch 1049/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3219 - val_loss: 1.0729 - val_accuracy: 0.4035\n",
      "Epoch 1050/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3087 - val_loss: 1.0823 - val_accuracy: 0.5018\n",
      "Epoch 1051/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3013 - accuracy: 0.3056 - val_loss: 1.0997 - val_accuracy: 0.4035\n",
      "Epoch 1052/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3238 - val_loss: 1.1122 - val_accuracy: 0.0947\n",
      "Epoch 1053/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3062 - val_loss: 1.0951 - val_accuracy: 0.4035\n",
      "Epoch 1054/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3192 - val_loss: 1.1115 - val_accuracy: 0.0947\n",
      "Epoch 1055/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3196 - val_loss: 1.0962 - val_accuracy: 0.4035\n",
      "Epoch 1056/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3141 - val_loss: 1.1216 - val_accuracy: 0.0947\n",
      "Epoch 1057/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3008 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 1058/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3156 - val_loss: 1.1232 - val_accuracy: 0.0947\n",
      "Epoch 1059/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3039 - val_loss: 1.1059 - val_accuracy: 0.0947\n",
      "Epoch 1060/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3145 - val_loss: 1.0964 - val_accuracy: 0.4035\n",
      "Epoch 1061/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3067 - val_loss: 1.1150 - val_accuracy: 0.0947\n",
      "Epoch 1062/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.2920 - val_loss: 1.1104 - val_accuracy: 0.0947\n",
      "Epoch 1063/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3162 - val_loss: 1.0818 - val_accuracy: 0.5018\n",
      "Epoch 1064/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3208 - val_loss: 1.1209 - val_accuracy: 0.0947\n",
      "Epoch 1065/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3005 - val_loss: 1.1032 - val_accuracy: 0.4035\n",
      "Epoch 1066/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3118 - val_loss: 1.0627 - val_accuracy: 0.4035\n",
      "Epoch 1067/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3104 - val_loss: 1.1085 - val_accuracy: 0.4035\n",
      "Epoch 1068/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3132 - val_loss: 1.1034 - val_accuracy: 0.0947\n",
      "Epoch 1069/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3010 - val_loss: 1.1132 - val_accuracy: 0.0947\n",
      "Epoch 1070/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.2830 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 1071/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2982 - val_loss: 1.0895 - val_accuracy: 0.4035\n",
      "Epoch 1072/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3334 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 1073/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3174 - val_loss: 1.1044 - val_accuracy: 0.0947\n",
      "Epoch 1074/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3053 - val_loss: 1.1052 - val_accuracy: 0.0947\n",
      "Epoch 1075/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3107 - val_loss: 1.0843 - val_accuracy: 0.5018\n",
      "Epoch 1076/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2938 - val_loss: 1.0733 - val_accuracy: 0.5018\n",
      "Epoch 1077/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3065 - val_loss: 1.1081 - val_accuracy: 0.0947\n",
      "Epoch 1078/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3121 - val_loss: 1.0881 - val_accuracy: 0.5018\n",
      "Epoch 1079/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3121 - val_loss: 1.0932 - val_accuracy: 0.4035\n",
      "Epoch 1080/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3122 - val_loss: 1.1009 - val_accuracy: 0.0947\n",
      "Epoch 1081/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2997 - val_loss: 1.0773 - val_accuracy: 0.4035\n",
      "Epoch 1082/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3066 - val_loss: 1.1167 - val_accuracy: 0.0947\n",
      "Epoch 1083/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3034 - val_loss: 1.1022 - val_accuracy: 0.0947\n",
      "Epoch 1084/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3144 - val_loss: 1.0908 - val_accuracy: 0.5018\n",
      "Epoch 1085/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3048 - val_loss: 1.0909 - val_accuracy: 0.4035\n",
      "Epoch 1086/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3154 - val_loss: 1.1172 - val_accuracy: 0.0947\n",
      "Epoch 1087/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3236 - val_loss: 1.0778 - val_accuracy: 0.5018\n",
      "Epoch 1088/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3066 - val_loss: 1.1155 - val_accuracy: 0.0947\n",
      "Epoch 1089/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2922 - val_loss: 1.1023 - val_accuracy: 0.0947\n",
      "Epoch 1090/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3134 - val_loss: 1.1277 - val_accuracy: 0.0947\n",
      "Epoch 1091/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3037 - val_loss: 1.1057 - val_accuracy: 0.0947\n",
      "Epoch 1092/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3032 - val_loss: 1.0917 - val_accuracy: 0.5018\n",
      "Epoch 1093/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3017 - val_loss: 1.1140 - val_accuracy: 0.0947\n",
      "Epoch 1094/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2938 - val_loss: 1.1084 - val_accuracy: 0.4035\n",
      "Epoch 1095/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3057 - val_loss: 1.0802 - val_accuracy: 0.5018\n",
      "Epoch 1096/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2880 - val_loss: 1.1271 - val_accuracy: 0.0947\n",
      "Epoch 1097/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2952 - val_loss: 1.0893 - val_accuracy: 0.5018\n",
      "Epoch 1098/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3191 - val_loss: 1.1307 - val_accuracy: 0.0947\n",
      "Epoch 1099/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3242 - val_loss: 1.1114 - val_accuracy: 0.0947\n",
      "Epoch 1100/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3028 - val_loss: 1.1178 - val_accuracy: 0.0947\n",
      "Epoch 1101/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3139 - val_loss: 1.1020 - val_accuracy: 0.5018\n",
      "Epoch 1102/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3148 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 1103/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3111 - val_loss: 1.0991 - val_accuracy: 0.5018\n",
      "Epoch 1104/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2934 - val_loss: 1.1058 - val_accuracy: 0.4035\n",
      "Epoch 1105/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3170 - val_loss: 1.1094 - val_accuracy: 0.0947\n",
      "Epoch 1106/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3042 - val_loss: 1.1113 - val_accuracy: 0.0947\n",
      "Epoch 1107/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3076 - val_loss: 1.1086 - val_accuracy: 0.0947\n",
      "Epoch 1108/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3209 - val_loss: 1.0946 - val_accuracy: 0.5018\n",
      "Epoch 1109/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2996 - val_loss: 1.0897 - val_accuracy: 0.4035\n",
      "Epoch 1110/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3189 - val_loss: 1.1048 - val_accuracy: 0.4035\n",
      "Epoch 1111/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3028 - val_loss: 1.0954 - val_accuracy: 0.4035\n",
      "Epoch 1112/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3048 - val_loss: 1.1029 - val_accuracy: 0.0947\n",
      "Epoch 1113/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2964 - val_loss: 1.0807 - val_accuracy: 0.5018\n",
      "Epoch 1114/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3037 - val_loss: 1.1128 - val_accuracy: 0.0947\n",
      "Epoch 1115/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2958 - val_loss: 1.1109 - val_accuracy: 0.0947\n",
      "Epoch 1116/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3175 - val_loss: 1.0896 - val_accuracy: 0.4035\n",
      "Epoch 1117/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3163 - val_loss: 1.0852 - val_accuracy: 0.5018\n",
      "Epoch 1118/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3093 - val_loss: 1.0872 - val_accuracy: 0.4035\n",
      "Epoch 1119/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3030 - val_loss: 1.0829 - val_accuracy: 0.4035\n",
      "Epoch 1120/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3076 - val_loss: 1.0840 - val_accuracy: 0.4035\n",
      "Epoch 1121/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3101 - val_loss: 1.0752 - val_accuracy: 0.4035\n",
      "Epoch 1122/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2926 - val_loss: 1.1235 - val_accuracy: 0.0947\n",
      "Epoch 1123/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3155 - val_loss: 1.1065 - val_accuracy: 0.0947\n",
      "Epoch 1124/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3234 - val_loss: 1.1130 - val_accuracy: 0.0947\n",
      "Epoch 1125/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.2805 - val_loss: 1.0900 - val_accuracy: 0.5018\n",
      "Epoch 1126/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3071 - val_loss: 1.1140 - val_accuracy: 0.0947\n",
      "Epoch 1127/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3221 - val_loss: 1.0784 - val_accuracy: 0.5018\n",
      "Epoch 1128/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3007 - val_loss: 1.0824 - val_accuracy: 0.4035\n",
      "Epoch 1129/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3103 - val_loss: 1.1041 - val_accuracy: 0.4035\n",
      "Epoch 1130/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2952 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 1131/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3024 - val_loss: 1.0908 - val_accuracy: 0.5018\n",
      "Epoch 1132/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3142 - val_loss: 1.0959 - val_accuracy: 0.4035\n",
      "Epoch 1133/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3001 - val_loss: 1.0993 - val_accuracy: 0.0947\n",
      "Epoch 1134/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3116 - val_loss: 1.0852 - val_accuracy: 0.4035\n",
      "Epoch 1135/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3033 - val_loss: 1.0980 - val_accuracy: 0.5018\n",
      "Epoch 1136/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3032 - val_loss: 1.1046 - val_accuracy: 0.4035\n",
      "Epoch 1137/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3120 - val_loss: 1.0928 - val_accuracy: 0.5018\n",
      "Epoch 1138/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2951 - val_loss: 1.1479 - val_accuracy: 0.0947\n",
      "Epoch 1139/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2959 - val_loss: 1.0994 - val_accuracy: 0.4035\n",
      "Epoch 1140/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3002 - val_loss: 1.1042 - val_accuracy: 0.0947\n",
      "Epoch 1141/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2858 - val_loss: 1.0954 - val_accuracy: 0.5018\n",
      "Epoch 1142/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3022 - val_loss: 1.0921 - val_accuracy: 0.4035\n",
      "Epoch 1143/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3004 - val_loss: 1.0980 - val_accuracy: 0.4035\n",
      "Epoch 1144/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2946 - val_loss: 1.1030 - val_accuracy: 0.4035\n",
      "Epoch 1145/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3034 - val_loss: 1.0975 - val_accuracy: 0.4035\n",
      "Epoch 1146/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3041 - val_loss: 1.0908 - val_accuracy: 0.5018\n",
      "Epoch 1147/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3088 - val_loss: 1.0628 - val_accuracy: 0.5018\n",
      "Epoch 1148/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3065 - val_loss: 1.1082 - val_accuracy: 0.0947\n",
      "Epoch 1149/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3160 - val_loss: 1.1066 - val_accuracy: 0.4035\n",
      "Epoch 1150/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3064 - val_loss: 1.1085 - val_accuracy: 0.0947\n",
      "Epoch 1151/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3177 - val_loss: 1.1092 - val_accuracy: 0.0947\n",
      "Epoch 1152/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3062 - val_loss: 1.0858 - val_accuracy: 0.4035\n",
      "Epoch 1153/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3159 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 1154/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3181 - val_loss: 1.1204 - val_accuracy: 0.0947\n",
      "Epoch 1155/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2892 - val_loss: 1.0969 - val_accuracy: 0.4035\n",
      "Epoch 1156/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3144 - val_loss: 1.0813 - val_accuracy: 0.5018\n",
      "Epoch 1157/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3140 - val_loss: 1.1062 - val_accuracy: 0.0947\n",
      "Epoch 1158/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2931 - val_loss: 1.0938 - val_accuracy: 0.4035\n",
      "Epoch 1159/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3086 - val_loss: 1.0860 - val_accuracy: 0.5018\n",
      "Epoch 1160/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3190 - val_loss: 1.1131 - val_accuracy: 0.0947\n",
      "Epoch 1161/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2977 - val_loss: 1.1052 - val_accuracy: 0.0947\n",
      "Epoch 1162/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2953 - val_loss: 1.0977 - val_accuracy: 0.5018\n",
      "Epoch 1163/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3072 - val_loss: 1.1472 - val_accuracy: 0.0947\n",
      "Epoch 1164/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2989 - val_loss: 1.1098 - val_accuracy: 0.0947\n",
      "Epoch 1165/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3129 - val_loss: 1.1053 - val_accuracy: 0.0947\n",
      "Epoch 1166/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3097 - val_loss: 1.1010 - val_accuracy: 0.4035\n",
      "Epoch 1167/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3068 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 1168/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3141 - val_loss: 1.0961 - val_accuracy: 0.4035\n",
      "Epoch 1169/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3011 - val_loss: 1.1136 - val_accuracy: 0.0947\n",
      "Epoch 1170/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3026 - val_loss: 1.0846 - val_accuracy: 0.5018\n",
      "Epoch 1171/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3025 - val_loss: 1.1086 - val_accuracy: 0.0947\n",
      "Epoch 1172/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3026 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 1173/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2940 - val_loss: 1.0754 - val_accuracy: 0.5018\n",
      "Epoch 1174/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3023 - val_loss: 1.1046 - val_accuracy: 0.0947\n",
      "Epoch 1175/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2911 - val_loss: 1.0867 - val_accuracy: 0.5018\n",
      "Epoch 1176/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3148 - val_loss: 1.1086 - val_accuracy: 0.0947\n",
      "Epoch 1177/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3004 - val_loss: 1.1006 - val_accuracy: 0.0947\n",
      "Epoch 1178/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3043 - val_loss: 1.1125 - val_accuracy: 0.0947\n",
      "Epoch 1179/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2919 - val_loss: 1.1038 - val_accuracy: 0.0947\n",
      "Epoch 1180/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3141 - val_loss: 1.0913 - val_accuracy: 0.4035\n",
      "Epoch 1181/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3158 - val_loss: 1.0982 - val_accuracy: 0.4035\n",
      "Epoch 1182/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3207 - val_loss: 1.1338 - val_accuracy: 0.0947\n",
      "Epoch 1183/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3131 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 1184/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3141 - val_loss: 1.1138 - val_accuracy: 0.4035\n",
      "Epoch 1185/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3098 - val_loss: 1.1039 - val_accuracy: 0.0947\n",
      "Epoch 1186/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2989 - val_loss: 1.0999 - val_accuracy: 0.0947\n",
      "Epoch 1187/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3164 - val_loss: 1.0851 - val_accuracy: 0.4035\n",
      "Epoch 1188/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3154 - val_loss: 1.1113 - val_accuracy: 0.0947\n",
      "Epoch 1189/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3084 - val_loss: 1.1140 - val_accuracy: 0.0947\n",
      "Epoch 1190/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3042 - val_loss: 1.1007 - val_accuracy: 0.0947\n",
      "Epoch 1191/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2978 - val_loss: 1.0915 - val_accuracy: 0.4035\n",
      "Epoch 1192/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3051 - val_loss: 1.1185 - val_accuracy: 0.0947\n",
      "Epoch 1193/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3149 - val_loss: 1.1156 - val_accuracy: 0.0947\n",
      "Epoch 1194/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3007 - val_loss: 1.1000 - val_accuracy: 0.4035\n",
      "Epoch 1195/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3202 - val_loss: 1.0933 - val_accuracy: 0.4035\n",
      "Epoch 1196/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.2856 - val_loss: 1.0910 - val_accuracy: 0.5018\n",
      "Epoch 1197/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3139 - val_loss: 1.0761 - val_accuracy: 0.5018\n",
      "Epoch 1198/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3046 - val_loss: 1.1074 - val_accuracy: 0.5018\n",
      "Epoch 1199/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3034 - val_loss: 1.0706 - val_accuracy: 0.5018\n",
      "Epoch 1200/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3156 - val_loss: 1.0841 - val_accuracy: 0.4035\n",
      "Epoch 1201/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2980 - val_loss: 1.1294 - val_accuracy: 0.0947\n",
      "Epoch 1202/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3057 - val_loss: 1.0864 - val_accuracy: 0.5018\n",
      "Epoch 1203/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3262 - val_loss: 1.1159 - val_accuracy: 0.0947\n",
      "Epoch 1204/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3001 - val_loss: 1.1078 - val_accuracy: 0.0947\n",
      "Epoch 1205/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3007 - val_loss: 1.1005 - val_accuracy: 0.5018\n",
      "Epoch 1206/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3167 - val_loss: 1.0942 - val_accuracy: 0.5018\n",
      "Epoch 1207/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3025 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 1208/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3028 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 1209/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3049 - val_loss: 1.1128 - val_accuracy: 0.4035\n",
      "Epoch 1210/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3005 - val_loss: 1.0742 - val_accuracy: 0.5018\n",
      "Epoch 1211/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3326 - val_loss: 1.1190 - val_accuracy: 0.0947\n",
      "Epoch 1212/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3064 - val_loss: 1.0906 - val_accuracy: 0.4035\n",
      "Epoch 1213/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3159 - val_loss: 1.1153 - val_accuracy: 0.0947\n",
      "Epoch 1214/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2887 - val_loss: 1.1114 - val_accuracy: 0.0947\n",
      "Epoch 1215/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3136 - val_loss: 1.0925 - val_accuracy: 0.4035\n",
      "Epoch 1216/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3172 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 1217/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3057 - val_loss: 1.0793 - val_accuracy: 0.4035\n",
      "Epoch 1218/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3339 - val_loss: 1.1077 - val_accuracy: 0.0947\n",
      "Epoch 1219/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3251 - val_loss: 1.1163 - val_accuracy: 0.0947\n",
      "Epoch 1220/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3046 - val_loss: 1.1100 - val_accuracy: 0.0947\n",
      "Epoch 1221/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2873 - val_loss: 1.1032 - val_accuracy: 0.0947\n",
      "Epoch 1222/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3054 - val_loss: 1.1081 - val_accuracy: 0.0947\n",
      "Epoch 1223/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2960 - val_loss: 1.1275 - val_accuracy: 0.0947\n",
      "Epoch 1224/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3197 - val_loss: 1.1025 - val_accuracy: 0.4035\n",
      "Epoch 1225/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2971 - val_loss: 1.0971 - val_accuracy: 0.4035\n",
      "Epoch 1226/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2885 - val_loss: 1.0999 - val_accuracy: 0.4035\n",
      "Epoch 1227/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2912 - val_loss: 1.0862 - val_accuracy: 0.4035\n",
      "Epoch 1228/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3071 - val_loss: 1.1460 - val_accuracy: 0.0947\n",
      "Epoch 1229/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3221 - val_loss: 1.1174 - val_accuracy: 0.0947\n",
      "Epoch 1230/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3061 - val_loss: 1.1034 - val_accuracy: 0.4035\n",
      "Epoch 1231/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2964 - val_loss: 1.1305 - val_accuracy: 0.0947\n",
      "Epoch 1232/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3109 - val_loss: 1.1190 - val_accuracy: 0.0947\n",
      "Epoch 1233/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3033 - val_loss: 1.1106 - val_accuracy: 0.0947\n",
      "Epoch 1234/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3147 - val_loss: 1.1024 - val_accuracy: 0.4035\n",
      "Epoch 1235/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3155 - val_loss: 1.1132 - val_accuracy: 0.0947\n",
      "Epoch 1236/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3253 - val_loss: 1.1176 - val_accuracy: 0.0947\n",
      "Epoch 1237/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3071 - val_loss: 1.1111 - val_accuracy: 0.0947\n",
      "Epoch 1238/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2989 - val_loss: 1.0986 - val_accuracy: 0.5018\n",
      "Epoch 1239/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3045 - val_loss: 1.1129 - val_accuracy: 0.0947\n",
      "Epoch 1240/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3063 - val_loss: 1.1406 - val_accuracy: 0.0947\n",
      "Epoch 1241/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3065 - val_loss: 1.1019 - val_accuracy: 0.4035\n",
      "Epoch 1242/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3162 - val_loss: 1.0978 - val_accuracy: 0.5018\n",
      "Epoch 1243/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3158 - val_loss: 1.1254 - val_accuracy: 0.0947\n",
      "Epoch 1244/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3044 - val_loss: 1.0828 - val_accuracy: 0.4035\n",
      "Epoch 1245/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3148 - val_loss: 1.0802 - val_accuracy: 0.4035\n",
      "Epoch 1246/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3081 - val_loss: 1.0818 - val_accuracy: 0.5018\n",
      "Epoch 1247/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3004 - val_loss: 1.1208 - val_accuracy: 0.0947\n",
      "Epoch 1248/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3089 - val_loss: 1.0938 - val_accuracy: 0.4035\n",
      "Epoch 1249/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2976 - val_loss: 1.1352 - val_accuracy: 0.0947\n",
      "Epoch 1250/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3092 - val_loss: 1.0817 - val_accuracy: 0.5018\n",
      "Epoch 1251/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3069 - val_loss: 1.0789 - val_accuracy: 0.5018\n",
      "Epoch 1252/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3134 - val_loss: 1.1122 - val_accuracy: 0.0947\n",
      "Epoch 1253/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3123 - val_loss: 1.0909 - val_accuracy: 0.5018\n",
      "Epoch 1254/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3146 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 1255/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2871 - val_loss: 1.0982 - val_accuracy: 0.5018\n",
      "Epoch 1256/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3128 - val_loss: 1.0991 - val_accuracy: 0.5018\n",
      "Epoch 1257/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2935 - val_loss: 1.0840 - val_accuracy: 0.4035\n",
      "Epoch 1258/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.2995 - val_loss: 1.1085 - val_accuracy: 0.0947\n",
      "Epoch 1259/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3063 - val_loss: 1.1034 - val_accuracy: 0.4035\n",
      "Epoch 1260/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3033 - val_loss: 1.0998 - val_accuracy: 0.4035\n",
      "Epoch 1261/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2938 - val_loss: 1.0875 - val_accuracy: 0.5018\n",
      "Epoch 1262/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3147 - val_loss: 1.1142 - val_accuracy: 0.0947\n",
      "Epoch 1263/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3074 - val_loss: 1.0785 - val_accuracy: 0.5018\n",
      "Epoch 1264/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3164 - val_loss: 1.1255 - val_accuracy: 0.0947\n",
      "Epoch 1265/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2968 - val_loss: 1.1387 - val_accuracy: 0.0947\n",
      "Epoch 1266/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3013 - val_loss: 1.0790 - val_accuracy: 0.5018\n",
      "Epoch 1267/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2987 - val_loss: 1.1097 - val_accuracy: 0.0947\n",
      "Epoch 1268/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3144 - val_loss: 1.1018 - val_accuracy: 0.0947\n",
      "Epoch 1269/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3037 - val_loss: 1.0637 - val_accuracy: 0.4035\n",
      "Epoch 1270/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3139 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 1271/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3150 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 1272/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3169 - val_loss: 1.0766 - val_accuracy: 0.4035\n",
      "Epoch 1273/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3051 - val_loss: 1.1145 - val_accuracy: 0.4035\n",
      "Epoch 1274/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3041 - val_loss: 1.1048 - val_accuracy: 0.4035\n",
      "Epoch 1275/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3013 - val_loss: 1.1092 - val_accuracy: 0.0947\n",
      "Epoch 1276/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2997 - val_loss: 1.1179 - val_accuracy: 0.0947\n",
      "Epoch 1277/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3074 - val_loss: 1.0853 - val_accuracy: 0.5018\n",
      "Epoch 1278/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3101 - val_loss: 1.0827 - val_accuracy: 0.5018\n",
      "Epoch 1279/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3039 - val_loss: 1.0950 - val_accuracy: 0.4035\n",
      "Epoch 1280/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3017 - val_loss: 1.1104 - val_accuracy: 0.0947\n",
      "Epoch 1281/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3135 - val_loss: 1.1143 - val_accuracy: 0.0947\n",
      "Epoch 1282/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3245 - val_loss: 1.1030 - val_accuracy: 0.4035\n",
      "Epoch 1283/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3161 - val_loss: 1.1084 - val_accuracy: 0.4035\n",
      "Epoch 1284/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3014 - accuracy: 0.3095 - val_loss: 1.1012 - val_accuracy: 0.4035\n",
      "Epoch 1285/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3079 - val_loss: 1.0791 - val_accuracy: 0.4035\n",
      "Epoch 1286/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3062 - val_loss: 1.1053 - val_accuracy: 0.0947\n",
      "Epoch 1287/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2931 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 1288/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2954 - val_loss: 1.1132 - val_accuracy: 0.0947\n",
      "Epoch 1289/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2943 - val_loss: 1.0939 - val_accuracy: 0.4035\n",
      "Epoch 1290/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3050 - val_loss: 1.1273 - val_accuracy: 0.0947\n",
      "Epoch 1291/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3212 - val_loss: 1.1006 - val_accuracy: 0.0947\n",
      "Epoch 1292/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2974 - val_loss: 1.1189 - val_accuracy: 0.0947\n",
      "Epoch 1293/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2815 - val_loss: 1.0876 - val_accuracy: 0.4035\n",
      "Epoch 1294/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3090 - val_loss: 1.1114 - val_accuracy: 0.0947\n",
      "Epoch 1295/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2939 - val_loss: 1.0813 - val_accuracy: 0.5018\n",
      "Epoch 1296/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3052 - val_loss: 1.0726 - val_accuracy: 0.4035\n",
      "Epoch 1297/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2991 - val_loss: 1.1077 - val_accuracy: 0.0947\n",
      "Epoch 1298/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3202 - val_loss: 1.0971 - val_accuracy: 0.4035\n",
      "Epoch 1299/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3084 - val_loss: 1.0824 - val_accuracy: 0.4035\n",
      "Epoch 1300/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3032 - val_loss: 1.0772 - val_accuracy: 0.4035\n",
      "Epoch 1301/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3062 - val_loss: 1.1222 - val_accuracy: 0.0947\n",
      "Epoch 1302/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3040 - val_loss: 1.1006 - val_accuracy: 0.4035\n",
      "Epoch 1303/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2952 - val_loss: 1.1315 - val_accuracy: 0.0947\n",
      "Epoch 1304/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3089 - val_loss: 1.0948 - val_accuracy: 0.5018\n",
      "Epoch 1305/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2995 - val_loss: 1.0867 - val_accuracy: 0.5018\n",
      "Epoch 1306/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2994 - val_loss: 1.1017 - val_accuracy: 0.0947\n",
      "Epoch 1307/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3013 - accuracy: 0.3062 - val_loss: 1.0972 - val_accuracy: 0.4035\n",
      "Epoch 1308/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3146 - val_loss: 1.0980 - val_accuracy: 0.4035\n",
      "Epoch 1309/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3202 - val_loss: 1.1020 - val_accuracy: 0.4035\n",
      "Epoch 1310/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3100 - val_loss: 1.0939 - val_accuracy: 0.4035\n",
      "Epoch 1311/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3245 - val_loss: 1.0778 - val_accuracy: 0.4035\n",
      "Epoch 1312/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3034 - val_loss: 1.0876 - val_accuracy: 0.5018\n",
      "Epoch 1313/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3097 - val_loss: 1.1090 - val_accuracy: 0.0947\n",
      "Epoch 1314/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3152 - val_loss: 1.0775 - val_accuracy: 0.4035\n",
      "Epoch 1315/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3017 - val_loss: 1.0941 - val_accuracy: 0.4035\n",
      "Epoch 1316/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3083 - val_loss: 1.1009 - val_accuracy: 0.5018\n",
      "Epoch 1317/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3012 - accuracy: 0.3109 - val_loss: 1.0942 - val_accuracy: 0.5018\n",
      "Epoch 1318/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3117 - val_loss: 1.1131 - val_accuracy: 0.0947\n",
      "Epoch 1319/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3105 - val_loss: 1.1098 - val_accuracy: 0.4035\n",
      "Epoch 1320/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3015 - val_loss: 1.1012 - val_accuracy: 0.4035\n",
      "Epoch 1321/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3134 - val_loss: 1.0990 - val_accuracy: 0.0947\n",
      "Epoch 1322/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2963 - val_loss: 1.0910 - val_accuracy: 0.4035\n",
      "Epoch 1323/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3066 - val_loss: 1.1173 - val_accuracy: 0.0947\n",
      "Epoch 1324/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3104 - val_loss: 1.1117 - val_accuracy: 0.0947\n",
      "Epoch 1325/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3085 - val_loss: 1.0713 - val_accuracy: 0.5018\n",
      "Epoch 1326/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3142 - val_loss: 1.0884 - val_accuracy: 0.5018\n",
      "Epoch 1327/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3222 - val_loss: 1.0895 - val_accuracy: 0.5018\n",
      "Epoch 1328/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3119 - val_loss: 1.0878 - val_accuracy: 0.5018\n",
      "Epoch 1329/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2915 - val_loss: 1.0996 - val_accuracy: 0.5018\n",
      "Epoch 1330/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3157 - val_loss: 1.0650 - val_accuracy: 0.5018\n",
      "Epoch 1331/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3055 - val_loss: 1.1142 - val_accuracy: 0.0947\n",
      "Epoch 1332/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3075 - val_loss: 1.0871 - val_accuracy: 0.4035\n",
      "Epoch 1333/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2979 - val_loss: 1.1209 - val_accuracy: 0.0947\n",
      "Epoch 1334/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2872 - val_loss: 1.1111 - val_accuracy: 0.0947\n",
      "Epoch 1335/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3071 - val_loss: 1.0770 - val_accuracy: 0.4035\n",
      "Epoch 1336/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2992 - val_loss: 1.1045 - val_accuracy: 0.0947\n",
      "Epoch 1337/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3190 - val_loss: 1.0950 - val_accuracy: 0.4035\n",
      "Epoch 1338/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2874 - val_loss: 1.0967 - val_accuracy: 0.4035\n",
      "Epoch 1339/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3038 - val_loss: 1.0972 - val_accuracy: 0.5018\n",
      "Epoch 1340/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3054 - val_loss: 1.1197 - val_accuracy: 0.0947\n",
      "Epoch 1341/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3140 - val_loss: 1.1063 - val_accuracy: 0.0947\n",
      "Epoch 1342/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2816 - val_loss: 1.0978 - val_accuracy: 0.4035\n",
      "Epoch 1343/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3233 - val_loss: 1.1274 - val_accuracy: 0.0947\n",
      "Epoch 1344/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3061 - val_loss: 1.1008 - val_accuracy: 0.4035\n",
      "Epoch 1345/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3279 - val_loss: 1.0994 - val_accuracy: 0.5018\n",
      "Epoch 1346/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3033 - val_loss: 1.1105 - val_accuracy: 0.0947\n",
      "Epoch 1347/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2972 - val_loss: 1.1072 - val_accuracy: 0.0947\n",
      "Epoch 1348/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2874 - val_loss: 1.1185 - val_accuracy: 0.0947\n",
      "Epoch 1349/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2926 - val_loss: 1.1157 - val_accuracy: 0.0947\n",
      "Epoch 1350/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3049 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 1351/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3110 - val_loss: 1.1053 - val_accuracy: 0.0947\n",
      "Epoch 1352/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3116 - val_loss: 1.1189 - val_accuracy: 0.0947\n",
      "Epoch 1353/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3080 - val_loss: 1.0945 - val_accuracy: 0.4035\n",
      "Epoch 1354/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3058 - val_loss: 1.1160 - val_accuracy: 0.0947\n",
      "Epoch 1355/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3199 - val_loss: 1.0720 - val_accuracy: 0.4035\n",
      "Epoch 1356/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3247 - val_loss: 1.1093 - val_accuracy: 0.0947\n",
      "Epoch 1357/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3042 - val_loss: 1.1070 - val_accuracy: 0.4035\n",
      "Epoch 1358/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3212 - val_loss: 1.0966 - val_accuracy: 0.4035\n",
      "Epoch 1359/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3012 - val_loss: 1.0762 - val_accuracy: 0.5018\n",
      "Epoch 1360/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3137 - val_loss: 1.1067 - val_accuracy: 0.0947\n",
      "Epoch 1361/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3196 - val_loss: 1.1250 - val_accuracy: 0.0947\n",
      "Epoch 1362/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3180 - val_loss: 1.1358 - val_accuracy: 0.0947\n",
      "Epoch 1363/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3021 - val_loss: 1.1213 - val_accuracy: 0.0947\n",
      "Epoch 1364/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3070 - val_loss: 1.0838 - val_accuracy: 0.4035\n",
      "Epoch 1365/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3013 - val_loss: 1.1139 - val_accuracy: 0.0947\n",
      "Epoch 1366/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3199 - val_loss: 1.1086 - val_accuracy: 0.0947\n",
      "Epoch 1367/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3174 - val_loss: 1.0846 - val_accuracy: 0.5018\n",
      "Epoch 1368/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3117 - val_loss: 1.0674 - val_accuracy: 0.4035\n",
      "Epoch 1369/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3099 - val_loss: 1.1044 - val_accuracy: 0.0947\n",
      "Epoch 1370/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3152 - val_loss: 1.1067 - val_accuracy: 0.4035\n",
      "Epoch 1371/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3137 - val_loss: 1.0966 - val_accuracy: 0.4035\n",
      "Epoch 1372/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2904 - val_loss: 1.1120 - val_accuracy: 0.0947\n",
      "Epoch 1373/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3094 - val_loss: 1.1124 - val_accuracy: 0.4035\n",
      "Epoch 1374/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3156 - val_loss: 1.0937 - val_accuracy: 0.4035\n",
      "Epoch 1375/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3058 - val_loss: 1.1015 - val_accuracy: 0.0947\n",
      "Epoch 1376/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3095 - val_loss: 1.1067 - val_accuracy: 0.0947\n",
      "Epoch 1377/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2992 - val_loss: 1.1168 - val_accuracy: 0.0947\n",
      "Epoch 1378/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3101 - val_loss: 1.0732 - val_accuracy: 0.5018\n",
      "Epoch 1379/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2930 - val_loss: 1.0907 - val_accuracy: 0.5018\n",
      "Epoch 1380/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3028 - val_loss: 1.1004 - val_accuracy: 0.5018\n",
      "Epoch 1381/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3006 - val_loss: 1.1043 - val_accuracy: 0.4035\n",
      "Epoch 1382/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3105 - val_loss: 1.0970 - val_accuracy: 0.5018\n",
      "Epoch 1383/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3128 - val_loss: 1.1178 - val_accuracy: 0.0947\n",
      "Epoch 1384/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3116 - val_loss: 1.0964 - val_accuracy: 0.5018\n",
      "Epoch 1385/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3063 - val_loss: 1.0777 - val_accuracy: 0.5018\n",
      "Epoch 1386/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3058 - val_loss: 1.0741 - val_accuracy: 0.4035\n",
      "Epoch 1387/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3101 - val_loss: 1.0995 - val_accuracy: 0.5018\n",
      "Epoch 1388/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3128 - val_loss: 1.0824 - val_accuracy: 0.5018\n",
      "Epoch 1389/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3088 - val_loss: 1.0869 - val_accuracy: 0.5018\n",
      "Epoch 1390/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3138 - val_loss: 1.0917 - val_accuracy: 0.5018\n",
      "Epoch 1391/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2981 - val_loss: 1.0962 - val_accuracy: 0.5018\n",
      "Epoch 1392/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3098 - val_loss: 1.1112 - val_accuracy: 0.0947\n",
      "Epoch 1393/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3155 - val_loss: 1.0884 - val_accuracy: 0.4035\n",
      "Epoch 1394/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3171 - val_loss: 1.1050 - val_accuracy: 0.0947\n",
      "Epoch 1395/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3071 - val_loss: 1.1011 - val_accuracy: 0.4035\n",
      "Epoch 1396/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3117 - val_loss: 1.0882 - val_accuracy: 0.4035\n",
      "Epoch 1397/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3100 - val_loss: 1.1255 - val_accuracy: 0.0947\n",
      "Epoch 1398/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2941 - val_loss: 1.1009 - val_accuracy: 0.0947\n",
      "Epoch 1399/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3043 - val_loss: 1.0994 - val_accuracy: 0.4035\n",
      "Epoch 1400/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3146 - val_loss: 1.0896 - val_accuracy: 0.4035\n",
      "Epoch 1401/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3245 - val_loss: 1.0899 - val_accuracy: 0.4035\n",
      "Epoch 1402/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3031 - val_loss: 1.0890 - val_accuracy: 0.4035\n",
      "Epoch 1403/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3145 - val_loss: 1.1067 - val_accuracy: 0.0947\n",
      "Epoch 1404/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3249 - val_loss: 1.0881 - val_accuracy: 0.4035\n",
      "Epoch 1405/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2945 - val_loss: 1.0892 - val_accuracy: 0.4035\n",
      "Epoch 1406/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3114 - val_loss: 1.1157 - val_accuracy: 0.0947\n",
      "Epoch 1407/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3041 - val_loss: 1.1041 - val_accuracy: 0.0947\n",
      "Epoch 1408/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3002 - val_loss: 1.0875 - val_accuracy: 0.4035\n",
      "Epoch 1409/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3072 - val_loss: 1.1081 - val_accuracy: 0.0947\n",
      "Epoch 1410/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3061 - val_loss: 1.1252 - val_accuracy: 0.0947\n",
      "Epoch 1411/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3036 - val_loss: 1.1090 - val_accuracy: 0.4035\n",
      "Epoch 1412/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3071 - val_loss: 1.0845 - val_accuracy: 0.4035\n",
      "Epoch 1413/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3023 - val_loss: 1.0832 - val_accuracy: 0.5018\n",
      "Epoch 1414/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3119 - val_loss: 1.0945 - val_accuracy: 0.4035\n",
      "Epoch 1415/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3008 - val_loss: 1.0941 - val_accuracy: 0.4035\n",
      "Epoch 1416/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2971 - val_loss: 1.0882 - val_accuracy: 0.4035\n",
      "Epoch 1417/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3226 - val_loss: 1.1167 - val_accuracy: 0.0947\n",
      "Epoch 1418/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3279 - val_loss: 1.0757 - val_accuracy: 0.4035\n",
      "Epoch 1419/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3070 - val_loss: 1.1012 - val_accuracy: 0.5018\n",
      "Epoch 1420/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3112 - val_loss: 1.1006 - val_accuracy: 0.4035\n",
      "Epoch 1421/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3004 - val_loss: 1.0809 - val_accuracy: 0.5018\n",
      "Epoch 1422/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3020 - val_loss: 1.0962 - val_accuracy: 0.4035\n",
      "Epoch 1423/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3046 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 1424/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3111 - val_loss: 1.1001 - val_accuracy: 0.0947\n",
      "Epoch 1425/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2997 - val_loss: 1.1034 - val_accuracy: 0.0947\n",
      "Epoch 1426/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2984 - val_loss: 1.1205 - val_accuracy: 0.0947\n",
      "Epoch 1427/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3006 - val_loss: 1.1386 - val_accuracy: 0.0947\n",
      "Epoch 1428/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3078 - val_loss: 1.0923 - val_accuracy: 0.5018\n",
      "Epoch 1429/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3052 - val_loss: 1.0877 - val_accuracy: 0.5018\n",
      "Epoch 1430/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3039 - val_loss: 1.1279 - val_accuracy: 0.0947\n",
      "Epoch 1431/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2923 - val_loss: 1.1011 - val_accuracy: 0.5018\n",
      "Epoch 1432/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3091 - val_loss: 1.0854 - val_accuracy: 0.4035\n",
      "Epoch 1433/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3142 - val_loss: 1.0895 - val_accuracy: 0.4035\n",
      "Epoch 1434/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2979 - val_loss: 1.1057 - val_accuracy: 0.5018\n",
      "Epoch 1435/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3054 - val_loss: 1.0887 - val_accuracy: 0.5018\n",
      "Epoch 1436/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3109 - val_loss: 1.0617 - val_accuracy: 0.4035\n",
      "Epoch 1437/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3019 - val_loss: 1.0697 - val_accuracy: 0.5018\n",
      "Epoch 1438/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3109 - val_loss: 1.0892 - val_accuracy: 0.5018\n",
      "Epoch 1439/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2983 - val_loss: 1.0949 - val_accuracy: 0.5018\n",
      "Epoch 1440/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3316 - val_loss: 1.1110 - val_accuracy: 0.0947\n",
      "Epoch 1441/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3006 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 1442/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3068 - val_loss: 1.1198 - val_accuracy: 0.0947\n",
      "Epoch 1443/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2920 - val_loss: 1.1122 - val_accuracy: 0.0947\n",
      "Epoch 1444/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3185 - val_loss: 1.0712 - val_accuracy: 0.5018\n",
      "Epoch 1445/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3039 - val_loss: 1.1195 - val_accuracy: 0.0947\n",
      "Epoch 1446/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3041 - val_loss: 1.0698 - val_accuracy: 0.5018\n",
      "Epoch 1447/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3199 - val_loss: 1.1043 - val_accuracy: 0.0947\n",
      "Epoch 1448/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2910 - val_loss: 1.1328 - val_accuracy: 0.0947\n",
      "Epoch 1449/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3178 - val_loss: 1.0900 - val_accuracy: 0.5018\n",
      "Epoch 1450/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3008 - val_loss: 1.0757 - val_accuracy: 0.5018\n",
      "Epoch 1451/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3071 - val_loss: 1.0927 - val_accuracy: 0.5018\n",
      "Epoch 1452/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3087 - val_loss: 1.0914 - val_accuracy: 0.5018\n",
      "Epoch 1453/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3025 - val_loss: 1.1308 - val_accuracy: 0.0947\n",
      "Epoch 1454/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3095 - val_loss: 1.1088 - val_accuracy: 0.0947\n",
      "Epoch 1455/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3015 - val_loss: 1.0925 - val_accuracy: 0.4035\n",
      "Epoch 1456/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2869 - val_loss: 1.0852 - val_accuracy: 0.5018\n",
      "Epoch 1457/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3060 - val_loss: 1.1185 - val_accuracy: 0.0947\n",
      "Epoch 1458/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3103 - val_loss: 1.0975 - val_accuracy: 0.5018\n",
      "Epoch 1459/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3145 - val_loss: 1.0960 - val_accuracy: 0.5018\n",
      "Epoch 1460/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3246 - val_loss: 1.1292 - val_accuracy: 0.0947\n",
      "Epoch 1461/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2967 - val_loss: 1.0912 - val_accuracy: 0.4035\n",
      "Epoch 1462/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3128 - val_loss: 1.1116 - val_accuracy: 0.0947\n",
      "Epoch 1463/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2961 - val_loss: 1.0933 - val_accuracy: 0.5018\n",
      "Epoch 1464/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3076 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 1465/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3106 - val_loss: 1.1028 - val_accuracy: 0.0947\n",
      "Epoch 1466/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3004 - val_loss: 1.1056 - val_accuracy: 0.0947\n",
      "Epoch 1467/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3093 - val_loss: 1.1151 - val_accuracy: 0.0947\n",
      "Epoch 1468/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3041 - val_loss: 1.0929 - val_accuracy: 0.4035\n",
      "Epoch 1469/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3140 - val_loss: 1.1071 - val_accuracy: 0.0947\n",
      "Epoch 1470/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2996 - val_loss: 1.1022 - val_accuracy: 0.0947\n",
      "Epoch 1471/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3248 - val_loss: 1.1314 - val_accuracy: 0.0947\n",
      "Epoch 1472/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3169 - val_loss: 1.0895 - val_accuracy: 0.5018\n",
      "Epoch 1473/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3189 - val_loss: 1.0757 - val_accuracy: 0.4035\n",
      "Epoch 1474/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3094 - val_loss: 1.0892 - val_accuracy: 0.5018\n",
      "Epoch 1475/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3195 - val_loss: 1.0937 - val_accuracy: 0.4035\n",
      "Epoch 1476/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3093 - val_loss: 1.0868 - val_accuracy: 0.5018\n",
      "Epoch 1477/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3017 - val_loss: 1.1199 - val_accuracy: 0.0947\n",
      "Epoch 1478/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2840 - val_loss: 1.0802 - val_accuracy: 0.5018\n",
      "Epoch 1479/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3172 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 1480/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3179 - val_loss: 1.0970 - val_accuracy: 0.5018\n",
      "Epoch 1481/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3225 - val_loss: 1.1265 - val_accuracy: 0.0947\n",
      "Epoch 1482/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.2997 - val_loss: 1.0873 - val_accuracy: 0.4035\n",
      "Epoch 1483/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3072 - val_loss: 1.0771 - val_accuracy: 0.5018\n",
      "Epoch 1484/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3167 - val_loss: 1.1065 - val_accuracy: 0.4035\n",
      "Epoch 1485/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3064 - val_loss: 1.1231 - val_accuracy: 0.0947\n",
      "Epoch 1486/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3046 - val_loss: 1.1059 - val_accuracy: 0.0947\n",
      "Epoch 1487/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3063 - val_loss: 1.1021 - val_accuracy: 0.5018\n",
      "Epoch 1488/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3123 - val_loss: 1.1110 - val_accuracy: 0.0947\n",
      "Epoch 1489/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3137 - val_loss: 1.0944 - val_accuracy: 0.5018\n",
      "Epoch 1490/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3180 - val_loss: 1.1164 - val_accuracy: 0.0947\n",
      "Epoch 1491/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3024 - val_loss: 1.1162 - val_accuracy: 0.0947\n",
      "Epoch 1492/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.2928 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 1493/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2979 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 1494/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3041 - val_loss: 1.1298 - val_accuracy: 0.0947\n",
      "Epoch 1495/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2972 - val_loss: 1.0952 - val_accuracy: 0.5018\n",
      "Epoch 1496/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3096 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 1497/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3043 - val_loss: 1.1066 - val_accuracy: 0.0947\n",
      "Epoch 1498/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2936 - val_loss: 1.0908 - val_accuracy: 0.5018\n",
      "Epoch 1499/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3143 - val_loss: 1.0731 - val_accuracy: 0.5018\n",
      "Epoch 1500/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3035 - val_loss: 1.1197 - val_accuracy: 0.0947\n",
      "Epoch 1501/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3011 - accuracy: 0.2949 - val_loss: 1.0834 - val_accuracy: 0.5018\n",
      "Epoch 1502/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3084 - val_loss: 1.1040 - val_accuracy: 0.0947\n",
      "Epoch 1503/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3148 - val_loss: 1.1124 - val_accuracy: 0.0947\n",
      "Epoch 1504/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3205 - val_loss: 1.1097 - val_accuracy: 0.0947\n",
      "Epoch 1505/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3099 - val_loss: 1.1052 - val_accuracy: 0.4035\n",
      "Epoch 1506/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3132 - val_loss: 1.1146 - val_accuracy: 0.4035\n",
      "Epoch 1507/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2989 - val_loss: 1.0789 - val_accuracy: 0.5018\n",
      "Epoch 1508/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3119 - val_loss: 1.1006 - val_accuracy: 0.0947\n",
      "Epoch 1509/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3114 - val_loss: 1.1195 - val_accuracy: 0.0947\n",
      "Epoch 1510/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3203 - val_loss: 1.0585 - val_accuracy: 0.4035\n",
      "Epoch 1511/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3269 - val_loss: 1.1182 - val_accuracy: 0.0947\n",
      "Epoch 1512/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3179 - val_loss: 1.0940 - val_accuracy: 0.4035\n",
      "Epoch 1513/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3052 - val_loss: 1.0860 - val_accuracy: 0.5018\n",
      "Epoch 1514/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3038 - val_loss: 1.0967 - val_accuracy: 0.4035\n",
      "Epoch 1515/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3067 - val_loss: 1.1136 - val_accuracy: 0.0947\n",
      "Epoch 1516/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3080 - val_loss: 1.1047 - val_accuracy: 0.0947\n",
      "Epoch 1517/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3162 - val_loss: 1.0849 - val_accuracy: 0.5018\n",
      "Epoch 1518/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2907 - val_loss: 1.0912 - val_accuracy: 0.5018\n",
      "Epoch 1519/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3061 - val_loss: 1.1019 - val_accuracy: 0.0947\n",
      "Epoch 1520/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3160 - val_loss: 1.0819 - val_accuracy: 0.5018\n",
      "Epoch 1521/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3296 - val_loss: 1.1241 - val_accuracy: 0.0947\n",
      "Epoch 1522/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3031 - val_loss: 1.0879 - val_accuracy: 0.4035\n",
      "Epoch 1523/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3097 - val_loss: 1.0657 - val_accuracy: 0.5018\n",
      "Epoch 1524/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3137 - val_loss: 1.0738 - val_accuracy: 0.4035\n",
      "Epoch 1525/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3187 - val_loss: 1.0836 - val_accuracy: 0.5018\n",
      "Epoch 1526/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3057 - val_loss: 1.0833 - val_accuracy: 0.5018\n",
      "Epoch 1527/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3139 - val_loss: 1.0899 - val_accuracy: 0.4035\n",
      "Epoch 1528/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3085 - val_loss: 1.0944 - val_accuracy: 0.4035\n",
      "Epoch 1529/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3057 - val_loss: 1.1048 - val_accuracy: 0.0947\n",
      "Epoch 1530/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2984 - val_loss: 1.0852 - val_accuracy: 0.5018\n",
      "Epoch 1531/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3056 - val_loss: 1.0934 - val_accuracy: 0.5018\n",
      "Epoch 1532/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3127 - val_loss: 1.0920 - val_accuracy: 0.4035\n",
      "Epoch 1533/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3017 - val_loss: 1.0936 - val_accuracy: 0.5018\n",
      "Epoch 1534/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3250 - val_loss: 1.1326 - val_accuracy: 0.0947\n",
      "Epoch 1535/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3084 - val_loss: 1.0883 - val_accuracy: 0.5018\n",
      "Epoch 1536/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3039 - val_loss: 1.1141 - val_accuracy: 0.0947\n",
      "Epoch 1537/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3103 - val_loss: 1.1167 - val_accuracy: 0.0947\n",
      "Epoch 1538/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3088 - val_loss: 1.1058 - val_accuracy: 0.4035\n",
      "Epoch 1539/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3110 - val_loss: 1.1178 - val_accuracy: 0.0947\n",
      "Epoch 1540/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2965 - val_loss: 1.1143 - val_accuracy: 0.0947\n",
      "Epoch 1541/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3172 - val_loss: 1.0845 - val_accuracy: 0.4035\n",
      "Epoch 1542/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3126 - val_loss: 1.1308 - val_accuracy: 0.0947\n",
      "Epoch 1543/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3098 - val_loss: 1.1159 - val_accuracy: 0.4035\n",
      "Epoch 1544/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3157 - val_loss: 1.1535 - val_accuracy: 0.0947\n",
      "Epoch 1545/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3011 - val_loss: 1.1109 - val_accuracy: 0.0947\n",
      "Epoch 1546/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3140 - val_loss: 1.1066 - val_accuracy: 0.0947\n",
      "Epoch 1547/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3321 - val_loss: 1.1153 - val_accuracy: 0.0947\n",
      "Epoch 1548/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3139 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 1549/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3038 - val_loss: 1.0923 - val_accuracy: 0.4035\n",
      "Epoch 1550/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3104 - val_loss: 1.1008 - val_accuracy: 0.4035\n",
      "Epoch 1551/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3099 - val_loss: 1.1108 - val_accuracy: 0.0947\n",
      "Epoch 1552/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3079 - val_loss: 1.0811 - val_accuracy: 0.5018\n",
      "Epoch 1553/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3130 - val_loss: 1.1371 - val_accuracy: 0.0947\n",
      "Epoch 1554/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3058 - val_loss: 1.1029 - val_accuracy: 0.4035\n",
      "Epoch 1555/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3120 - val_loss: 1.0864 - val_accuracy: 0.5018\n",
      "Epoch 1556/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3165 - val_loss: 1.1075 - val_accuracy: 0.0947\n",
      "Epoch 1557/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3061 - val_loss: 1.1041 - val_accuracy: 0.0947\n",
      "Epoch 1558/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3076 - val_loss: 1.1046 - val_accuracy: 0.4035\n",
      "Epoch 1559/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3026 - val_loss: 1.1059 - val_accuracy: 0.0947\n",
      "Epoch 1560/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3206 - val_loss: 1.1225 - val_accuracy: 0.0947\n",
      "Epoch 1561/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3093 - val_loss: 1.0741 - val_accuracy: 0.4035\n",
      "Epoch 1562/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3116 - val_loss: 1.0941 - val_accuracy: 0.4035\n",
      "Epoch 1563/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3105 - val_loss: 1.1287 - val_accuracy: 0.0947\n",
      "Epoch 1564/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3014 - accuracy: 0.2957 - val_loss: 1.0672 - val_accuracy: 0.5018\n",
      "Epoch 1565/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3061 - val_loss: 1.1027 - val_accuracy: 0.4035\n",
      "Epoch 1566/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3176 - val_loss: 1.1021 - val_accuracy: 0.5018\n",
      "Epoch 1567/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3151 - val_loss: 1.0982 - val_accuracy: 0.5018\n",
      "Epoch 1568/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3053 - val_loss: 1.0707 - val_accuracy: 0.4035\n",
      "Epoch 1569/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3167 - val_loss: 1.0934 - val_accuracy: 0.5018\n",
      "Epoch 1570/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2944 - val_loss: 1.0923 - val_accuracy: 0.4035\n",
      "Epoch 1571/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3142 - val_loss: 1.0745 - val_accuracy: 0.5018\n",
      "Epoch 1572/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3146 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 1573/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3021 - val_loss: 1.0914 - val_accuracy: 0.5018\n",
      "Epoch 1574/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2990 - val_loss: 1.1246 - val_accuracy: 0.0947\n",
      "Epoch 1575/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2897 - val_loss: 1.0929 - val_accuracy: 0.5018\n",
      "Epoch 1576/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3176 - val_loss: 1.1085 - val_accuracy: 0.4035\n",
      "Epoch 1577/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3147 - val_loss: 1.0953 - val_accuracy: 0.4035\n",
      "Epoch 1578/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3094 - val_loss: 1.0848 - val_accuracy: 0.5018\n",
      "Epoch 1579/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3232 - val_loss: 1.0921 - val_accuracy: 0.5018\n",
      "Epoch 1580/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3166 - val_loss: 1.1077 - val_accuracy: 0.5018\n",
      "Epoch 1581/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3064 - val_loss: 1.0823 - val_accuracy: 0.5018\n",
      "Epoch 1582/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3034 - val_loss: 1.0999 - val_accuracy: 0.5018\n",
      "Epoch 1583/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3074 - val_loss: 1.0841 - val_accuracy: 0.4035\n",
      "Epoch 1584/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3052 - val_loss: 1.1017 - val_accuracy: 0.0947\n",
      "Epoch 1585/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3041 - val_loss: 1.0989 - val_accuracy: 0.5018\n",
      "Epoch 1586/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3114 - val_loss: 1.1019 - val_accuracy: 0.4035\n",
      "Epoch 1587/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3102 - val_loss: 1.0998 - val_accuracy: 0.4035\n",
      "Epoch 1588/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3032 - val_loss: 1.0961 - val_accuracy: 0.5018\n",
      "Epoch 1589/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3029 - val_loss: 1.0755 - val_accuracy: 0.4035\n",
      "Epoch 1590/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3003 - val_loss: 1.1204 - val_accuracy: 0.0947\n",
      "Epoch 1591/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3031 - val_loss: 1.0598 - val_accuracy: 0.5018\n",
      "Epoch 1592/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3106 - val_loss: 1.1180 - val_accuracy: 0.0947\n",
      "Epoch 1593/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3152 - val_loss: 1.1249 - val_accuracy: 0.0947\n",
      "Epoch 1594/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2960 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 1595/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3127 - val_loss: 1.0954 - val_accuracy: 0.5018\n",
      "Epoch 1596/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2993 - val_loss: 1.0878 - val_accuracy: 0.4035\n",
      "Epoch 1597/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2989 - val_loss: 1.0688 - val_accuracy: 0.5018\n",
      "Epoch 1598/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3079 - val_loss: 1.0997 - val_accuracy: 0.5018\n",
      "Epoch 1599/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3127 - val_loss: 1.0921 - val_accuracy: 0.5018\n",
      "Epoch 1600/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3102 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 1601/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2925 - val_loss: 1.1016 - val_accuracy: 0.4035\n",
      "Epoch 1602/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2962 - val_loss: 1.1420 - val_accuracy: 0.0947\n",
      "Epoch 1603/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2970 - val_loss: 1.1006 - val_accuracy: 0.4035\n",
      "Epoch 1604/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3031 - val_loss: 1.1215 - val_accuracy: 0.0947\n",
      "Epoch 1605/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3063 - val_loss: 1.1201 - val_accuracy: 0.0947\n",
      "Epoch 1606/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3158 - val_loss: 1.0764 - val_accuracy: 0.5018\n",
      "Epoch 1607/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3179 - val_loss: 1.0983 - val_accuracy: 0.5018\n",
      "Epoch 1608/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3102 - val_loss: 1.1130 - val_accuracy: 0.0947\n",
      "Epoch 1609/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3233 - val_loss: 1.1350 - val_accuracy: 0.0947\n",
      "Epoch 1610/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3137 - val_loss: 1.0963 - val_accuracy: 0.5018\n",
      "Epoch 1611/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2978 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 1612/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3103 - val_loss: 1.0992 - val_accuracy: 0.5018\n",
      "Epoch 1613/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2958 - val_loss: 1.1225 - val_accuracy: 0.0947\n",
      "Epoch 1614/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3142 - val_loss: 1.1119 - val_accuracy: 0.0947\n",
      "Epoch 1615/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3210 - val_loss: 1.0973 - val_accuracy: 0.4035\n",
      "Epoch 1616/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3299 - val_loss: 1.1173 - val_accuracy: 0.0947\n",
      "Epoch 1617/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3268 - val_loss: 1.0799 - val_accuracy: 0.4035\n",
      "Epoch 1618/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3102 - val_loss: 1.1199 - val_accuracy: 0.0947\n",
      "Epoch 1619/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2854 - val_loss: 1.0976 - val_accuracy: 0.4035\n",
      "Epoch 1620/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3121 - val_loss: 1.0789 - val_accuracy: 0.4035\n",
      "Epoch 1621/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2922 - val_loss: 1.1081 - val_accuracy: 0.0947\n",
      "Epoch 1622/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3003 - val_loss: 1.0915 - val_accuracy: 0.5018\n",
      "Epoch 1623/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3094 - val_loss: 1.1167 - val_accuracy: 0.0947\n",
      "Epoch 1624/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3024 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 1625/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3088 - val_loss: 1.1251 - val_accuracy: 0.0947\n",
      "Epoch 1626/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3058 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 1627/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3065 - val_loss: 1.1031 - val_accuracy: 0.4035\n",
      "Epoch 1628/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3144 - val_loss: 1.1110 - val_accuracy: 0.0947\n",
      "Epoch 1629/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2973 - val_loss: 1.0824 - val_accuracy: 0.4035\n",
      "Epoch 1630/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3145 - val_loss: 1.0962 - val_accuracy: 0.5018\n",
      "Epoch 1631/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3049 - val_loss: 1.1287 - val_accuracy: 0.0947\n",
      "Epoch 1632/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2983 - val_loss: 1.1109 - val_accuracy: 0.0947\n",
      "Epoch 1633/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3018 - val_loss: 1.0783 - val_accuracy: 0.5018\n",
      "Epoch 1634/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3142 - val_loss: 1.0764 - val_accuracy: 0.5018\n",
      "Epoch 1635/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2982 - val_loss: 1.0725 - val_accuracy: 0.5018\n",
      "Epoch 1636/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2816 - val_loss: 1.1166 - val_accuracy: 0.0947\n",
      "Epoch 1637/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3041 - val_loss: 1.0873 - val_accuracy: 0.4035\n",
      "Epoch 1638/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3197 - val_loss: 1.1181 - val_accuracy: 0.0947\n",
      "Epoch 1639/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3005 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 1640/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3017 - val_loss: 1.0648 - val_accuracy: 0.4035\n",
      "Epoch 1641/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3029 - val_loss: 1.0992 - val_accuracy: 0.0947\n",
      "Epoch 1642/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3128 - val_loss: 1.0868 - val_accuracy: 0.5018\n",
      "Epoch 1643/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3234 - val_loss: 1.1063 - val_accuracy: 0.0947\n",
      "Epoch 1644/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3060 - val_loss: 1.0616 - val_accuracy: 0.4035\n",
      "Epoch 1645/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3022 - val_loss: 1.0893 - val_accuracy: 0.5018\n",
      "Epoch 1646/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3132 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 1647/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3030 - val_loss: 1.0909 - val_accuracy: 0.4035\n",
      "Epoch 1648/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3175 - val_loss: 1.1134 - val_accuracy: 0.0947\n",
      "Epoch 1649/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3153 - val_loss: 1.0933 - val_accuracy: 0.4035\n",
      "Epoch 1650/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3066 - val_loss: 1.0904 - val_accuracy: 0.4035\n",
      "Epoch 1651/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3179 - val_loss: 1.0866 - val_accuracy: 0.4035\n",
      "Epoch 1652/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2887 - val_loss: 1.0912 - val_accuracy: 0.4035\n",
      "Epoch 1653/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3123 - val_loss: 1.0696 - val_accuracy: 0.4035\n",
      "Epoch 1654/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3107 - val_loss: 1.1200 - val_accuracy: 0.0947\n",
      "Epoch 1655/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3058 - val_loss: 1.0783 - val_accuracy: 0.4035\n",
      "Epoch 1656/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3170 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 1657/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3208 - val_loss: 1.1226 - val_accuracy: 0.0947\n",
      "Epoch 1658/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3154 - val_loss: 1.0824 - val_accuracy: 0.5018\n",
      "Epoch 1659/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3086 - val_loss: 1.1151 - val_accuracy: 0.0947\n",
      "Epoch 1660/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3062 - val_loss: 1.1019 - val_accuracy: 0.4035\n",
      "Epoch 1661/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3163 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 1662/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3111 - val_loss: 1.1010 - val_accuracy: 0.4035\n",
      "Epoch 1663/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3067 - val_loss: 1.0988 - val_accuracy: 0.5018\n",
      "Epoch 1664/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3023 - val_loss: 1.0803 - val_accuracy: 0.4035\n",
      "Epoch 1665/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3122 - val_loss: 1.1056 - val_accuracy: 0.0947\n",
      "Epoch 1666/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3088 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 1667/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2952 - val_loss: 1.0607 - val_accuracy: 0.4035\n",
      "Epoch 1668/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3006 - val_loss: 1.0928 - val_accuracy: 0.5018\n",
      "Epoch 1669/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3134 - val_loss: 1.0880 - val_accuracy: 0.5018\n",
      "Epoch 1670/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3106 - val_loss: 1.1110 - val_accuracy: 0.0947\n",
      "Epoch 1671/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3115 - val_loss: 1.0888 - val_accuracy: 0.4035\n",
      "Epoch 1672/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3076 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 1673/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3185 - val_loss: 1.1152 - val_accuracy: 0.0947\n",
      "Epoch 1674/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3033 - val_loss: 1.0804 - val_accuracy: 0.5018\n",
      "Epoch 1675/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2811 - val_loss: 1.0968 - val_accuracy: 0.4035\n",
      "Epoch 1676/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3062 - val_loss: 1.1158 - val_accuracy: 0.0947\n",
      "Epoch 1677/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3039 - val_loss: 1.0992 - val_accuracy: 0.5018\n",
      "Epoch 1678/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2984 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 1679/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3066 - val_loss: 1.0894 - val_accuracy: 0.5018\n",
      "Epoch 1680/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3036 - val_loss: 1.1558 - val_accuracy: 0.0947\n",
      "Epoch 1681/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3024 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 1682/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3270 - val_loss: 1.0830 - val_accuracy: 0.4035\n",
      "Epoch 1683/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3248 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 1684/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3042 - val_loss: 1.1030 - val_accuracy: 0.0947\n",
      "Epoch 1685/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2952 - val_loss: 1.0717 - val_accuracy: 0.4035\n",
      "Epoch 1686/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3232 - val_loss: 1.1113 - val_accuracy: 0.0947\n",
      "Epoch 1687/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3087 - val_loss: 1.0855 - val_accuracy: 0.4035\n",
      "Epoch 1688/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3164 - val_loss: 1.1142 - val_accuracy: 0.0947\n",
      "Epoch 1689/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3081 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 1690/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3068 - val_loss: 1.1051 - val_accuracy: 0.0947\n",
      "Epoch 1691/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2998 - val_loss: 1.0736 - val_accuracy: 0.5018\n",
      "Epoch 1692/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3007 - val_loss: 1.0874 - val_accuracy: 0.4035\n",
      "Epoch 1693/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3187 - val_loss: 1.1006 - val_accuracy: 0.0947\n",
      "Epoch 1694/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3040 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 1695/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3045 - val_loss: 1.0853 - val_accuracy: 0.5018\n",
      "Epoch 1696/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3073 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 1697/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2999 - val_loss: 1.0946 - val_accuracy: 0.4035\n",
      "Epoch 1698/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3245 - val_loss: 1.1043 - val_accuracy: 0.4035\n",
      "Epoch 1699/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3109 - val_loss: 1.1179 - val_accuracy: 0.0947\n",
      "Epoch 1700/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2967 - val_loss: 1.0502 - val_accuracy: 0.5018\n",
      "Epoch 1701/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3087 - val_loss: 1.1030 - val_accuracy: 0.0947\n",
      "Epoch 1702/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2989 - val_loss: 1.1055 - val_accuracy: 0.0947\n",
      "Epoch 1703/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3022 - val_loss: 1.0865 - val_accuracy: 0.4035\n",
      "Epoch 1704/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2977 - val_loss: 1.0845 - val_accuracy: 0.4035\n",
      "Epoch 1705/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3086 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 1706/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3068 - val_loss: 1.1606 - val_accuracy: 0.0947\n",
      "Epoch 1707/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3124 - val_loss: 1.0895 - val_accuracy: 0.4035\n",
      "Epoch 1708/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2781 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 1709/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3222 - val_loss: 1.0867 - val_accuracy: 0.4035\n",
      "Epoch 1710/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3010 - val_loss: 1.1220 - val_accuracy: 0.0947\n",
      "Epoch 1711/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3073 - val_loss: 1.1124 - val_accuracy: 0.0947\n",
      "Epoch 1712/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3272 - val_loss: 1.1135 - val_accuracy: 0.0947\n",
      "Epoch 1713/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3224 - val_loss: 1.1033 - val_accuracy: 0.4035\n",
      "Epoch 1714/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3086 - val_loss: 1.0938 - val_accuracy: 0.5018\n",
      "Epoch 1715/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2931 - val_loss: 1.1000 - val_accuracy: 0.0947\n",
      "Epoch 1716/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3299 - val_loss: 1.0785 - val_accuracy: 0.4035\n",
      "Epoch 1717/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3045 - val_loss: 1.0744 - val_accuracy: 0.5018\n",
      "Epoch 1718/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3153 - val_loss: 1.1165 - val_accuracy: 0.0947\n",
      "Epoch 1719/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3140 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 1720/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3072 - val_loss: 1.1031 - val_accuracy: 0.4035\n",
      "Epoch 1721/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3188 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 1722/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3196 - val_loss: 1.1065 - val_accuracy: 0.4035\n",
      "Epoch 1723/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3146 - val_loss: 1.0762 - val_accuracy: 0.5018\n",
      "Epoch 1724/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3063 - val_loss: 1.0972 - val_accuracy: 0.4035\n",
      "Epoch 1725/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3185 - val_loss: 1.1005 - val_accuracy: 0.4035\n",
      "Epoch 1726/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3004 - val_loss: 1.0819 - val_accuracy: 0.4035\n",
      "Epoch 1727/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3012 - accuracy: 0.3224 - val_loss: 1.0822 - val_accuracy: 0.5018\n",
      "Epoch 1728/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2973 - val_loss: 1.0944 - val_accuracy: 0.4035\n",
      "Epoch 1729/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3084 - val_loss: 1.1090 - val_accuracy: 0.0947\n",
      "Epoch 1730/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3034 - val_loss: 1.1053 - val_accuracy: 0.0947\n",
      "Epoch 1731/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3053 - val_loss: 1.1227 - val_accuracy: 0.0947\n",
      "Epoch 1732/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3066 - val_loss: 1.1287 - val_accuracy: 0.0947\n",
      "Epoch 1733/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2876 - val_loss: 1.0944 - val_accuracy: 0.4035\n",
      "Epoch 1734/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3133 - val_loss: 1.0910 - val_accuracy: 0.5018\n",
      "Epoch 1735/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3139 - val_loss: 1.0910 - val_accuracy: 0.5018\n",
      "Epoch 1736/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2980 - val_loss: 1.1078 - val_accuracy: 0.0947\n",
      "Epoch 1737/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3093 - val_loss: 1.0858 - val_accuracy: 0.4035\n",
      "Epoch 1738/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3197 - val_loss: 1.1043 - val_accuracy: 0.0947\n",
      "Epoch 1739/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3015 - val_loss: 1.1047 - val_accuracy: 0.0947\n",
      "Epoch 1740/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2985 - val_loss: 1.0868 - val_accuracy: 0.4035\n",
      "Epoch 1741/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3104 - val_loss: 1.0849 - val_accuracy: 0.4035\n",
      "Epoch 1742/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3225 - val_loss: 1.1041 - val_accuracy: 0.4035\n",
      "Epoch 1743/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3089 - val_loss: 1.1073 - val_accuracy: 0.0947\n",
      "Epoch 1744/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3217 - val_loss: 1.1204 - val_accuracy: 0.0947\n",
      "Epoch 1745/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3046 - val_loss: 1.0960 - val_accuracy: 0.4035\n",
      "Epoch 1746/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3179 - val_loss: 1.1083 - val_accuracy: 0.0947\n",
      "Epoch 1747/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3140 - val_loss: 1.0951 - val_accuracy: 0.4035\n",
      "Epoch 1748/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3063 - val_loss: 1.1102 - val_accuracy: 0.0947\n",
      "Epoch 1749/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3084 - val_loss: 1.1166 - val_accuracy: 0.0947\n",
      "Epoch 1750/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.2916 - val_loss: 1.0886 - val_accuracy: 0.5018\n",
      "Epoch 1751/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3093 - val_loss: 1.0628 - val_accuracy: 0.4035\n",
      "Epoch 1752/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2914 - val_loss: 1.1281 - val_accuracy: 0.0947\n",
      "Epoch 1753/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3169 - val_loss: 1.1158 - val_accuracy: 0.0947\n",
      "Epoch 1754/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2941 - val_loss: 1.0765 - val_accuracy: 0.5018\n",
      "Epoch 1755/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3100 - val_loss: 1.0706 - val_accuracy: 0.5018\n",
      "Epoch 1756/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2970 - val_loss: 1.0914 - val_accuracy: 0.5018\n",
      "Epoch 1757/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3262 - val_loss: 1.0926 - val_accuracy: 0.5018\n",
      "Epoch 1758/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3110 - val_loss: 1.0859 - val_accuracy: 0.5018\n",
      "Epoch 1759/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3106 - val_loss: 1.0738 - val_accuracy: 0.5018\n",
      "Epoch 1760/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2952 - val_loss: 1.0905 - val_accuracy: 0.4035\n",
      "Epoch 1761/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3239 - val_loss: 1.0990 - val_accuracy: 0.5018\n",
      "Epoch 1762/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3143 - val_loss: 1.0838 - val_accuracy: 0.4035\n",
      "Epoch 1763/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2970 - val_loss: 1.0918 - val_accuracy: 0.4035\n",
      "Epoch 1764/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3078 - val_loss: 1.1025 - val_accuracy: 0.5018\n",
      "Epoch 1765/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3089 - val_loss: 1.0780 - val_accuracy: 0.4035\n",
      "Epoch 1766/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2950 - val_loss: 1.0713 - val_accuracy: 0.4035\n",
      "Epoch 1767/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3044 - val_loss: 1.1217 - val_accuracy: 0.0947\n",
      "Epoch 1768/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3075 - val_loss: 1.1107 - val_accuracy: 0.0947\n",
      "Epoch 1769/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3059 - val_loss: 1.1043 - val_accuracy: 0.0947\n",
      "Epoch 1770/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2999 - val_loss: 1.1125 - val_accuracy: 0.0947\n",
      "Epoch 1771/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2980 - val_loss: 1.1174 - val_accuracy: 0.0947\n",
      "Epoch 1772/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3101 - val_loss: 1.1245 - val_accuracy: 0.0947\n",
      "Epoch 1773/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3111 - val_loss: 1.1104 - val_accuracy: 0.0947\n",
      "Epoch 1774/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3087 - val_loss: 1.0811 - val_accuracy: 0.5018\n",
      "Epoch 1775/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3115 - val_loss: 1.1116 - val_accuracy: 0.0947\n",
      "Epoch 1776/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3195 - val_loss: 1.0922 - val_accuracy: 0.5018\n",
      "Epoch 1777/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3061 - val_loss: 1.1040 - val_accuracy: 0.0947\n",
      "Epoch 1778/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3151 - val_loss: 1.1056 - val_accuracy: 0.4035\n",
      "Epoch 1779/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3257 - val_loss: 1.0978 - val_accuracy: 0.4035\n",
      "Epoch 1780/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3396 - val_loss: 1.0856 - val_accuracy: 0.5018\n",
      "Epoch 1781/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3043 - val_loss: 1.0913 - val_accuracy: 0.4035\n",
      "Epoch 1782/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2972 - val_loss: 1.0825 - val_accuracy: 0.5018\n",
      "Epoch 1783/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2960 - val_loss: 1.1020 - val_accuracy: 0.0947\n",
      "Epoch 1784/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3391 - val_loss: 1.0976 - val_accuracy: 0.4035\n",
      "Epoch 1785/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3084 - val_loss: 1.0878 - val_accuracy: 0.5018\n",
      "Epoch 1786/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3160 - val_loss: 1.0931 - val_accuracy: 0.4035\n",
      "Epoch 1787/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3287 - val_loss: 1.0891 - val_accuracy: 0.4035\n",
      "Epoch 1788/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2938 - val_loss: 1.0945 - val_accuracy: 0.4035\n",
      "Epoch 1789/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3016 - val_loss: 1.1057 - val_accuracy: 0.0947\n",
      "Epoch 1790/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3085 - val_loss: 1.1063 - val_accuracy: 0.4035\n",
      "Epoch 1791/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3016 - val_loss: 1.1143 - val_accuracy: 0.0947\n",
      "Epoch 1792/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3219 - val_loss: 1.0977 - val_accuracy: 0.5018\n",
      "Epoch 1793/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3176 - val_loss: 1.0982 - val_accuracy: 0.5018\n",
      "Epoch 1794/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3218 - val_loss: 1.1012 - val_accuracy: 0.5018\n",
      "Epoch 1795/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3100 - val_loss: 1.0924 - val_accuracy: 0.4035\n",
      "Epoch 1796/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2975 - val_loss: 1.0920 - val_accuracy: 0.4035\n",
      "Epoch 1797/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3108 - val_loss: 1.1303 - val_accuracy: 0.0947\n",
      "Epoch 1798/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3018 - accuracy: 0.2992 - val_loss: 1.1205 - val_accuracy: 0.0947\n",
      "Epoch 1799/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2905 - val_loss: 1.1039 - val_accuracy: 0.0947\n",
      "Epoch 1800/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3132 - val_loss: 1.0662 - val_accuracy: 0.5018\n",
      "Epoch 1801/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3174 - val_loss: 1.1321 - val_accuracy: 0.0947\n",
      "Epoch 1802/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2918 - val_loss: 1.0916 - val_accuracy: 0.5018\n",
      "Epoch 1803/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2936 - val_loss: 1.0879 - val_accuracy: 0.5018\n",
      "Epoch 1804/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2983 - val_loss: 1.1032 - val_accuracy: 0.0947\n",
      "Epoch 1805/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3046 - val_loss: 1.0954 - val_accuracy: 0.4035\n",
      "Epoch 1806/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3097 - val_loss: 1.1123 - val_accuracy: 0.0947\n",
      "Epoch 1807/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3110 - val_loss: 1.1281 - val_accuracy: 0.0947\n",
      "Epoch 1808/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3155 - val_loss: 1.0984 - val_accuracy: 0.4035\n",
      "Epoch 1809/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3225 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 1810/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2945 - val_loss: 1.0707 - val_accuracy: 0.5018\n",
      "Epoch 1811/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3092 - val_loss: 1.0898 - val_accuracy: 0.5018\n",
      "Epoch 1812/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2938 - val_loss: 1.0826 - val_accuracy: 0.5018\n",
      "Epoch 1813/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2994 - val_loss: 1.0854 - val_accuracy: 0.4035\n",
      "Epoch 1814/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2987 - val_loss: 1.1310 - val_accuracy: 0.0947\n",
      "Epoch 1815/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2888 - val_loss: 1.0921 - val_accuracy: 0.5018\n",
      "Epoch 1816/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3184 - val_loss: 1.1382 - val_accuracy: 0.0947\n",
      "Epoch 1817/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3006 - val_loss: 1.0947 - val_accuracy: 0.5018\n",
      "Epoch 1818/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3266 - val_loss: 1.1022 - val_accuracy: 0.5018\n",
      "Epoch 1819/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3086 - val_loss: 1.1177 - val_accuracy: 0.0947\n",
      "Epoch 1820/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3049 - val_loss: 1.1141 - val_accuracy: 0.0947\n",
      "Epoch 1821/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3012 - accuracy: 0.3065 - val_loss: 1.1215 - val_accuracy: 0.0947\n",
      "Epoch 1822/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2997 - val_loss: 1.1264 - val_accuracy: 0.0947\n",
      "Epoch 1823/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3059 - val_loss: 1.1514 - val_accuracy: 0.0947\n",
      "Epoch 1824/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2963 - val_loss: 1.1133 - val_accuracy: 0.0947\n",
      "Epoch 1825/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3338 - val_loss: 1.0728 - val_accuracy: 0.5018\n",
      "Epoch 1826/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2956 - val_loss: 1.0985 - val_accuracy: 0.5018\n",
      "Epoch 1827/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3057 - val_loss: 1.0788 - val_accuracy: 0.5018\n",
      "Epoch 1828/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2990 - val_loss: 1.0983 - val_accuracy: 0.4035\n",
      "Epoch 1829/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3133 - val_loss: 1.1116 - val_accuracy: 0.4035\n",
      "Epoch 1830/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2980 - val_loss: 1.0926 - val_accuracy: 0.4035\n",
      "Epoch 1831/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2903 - val_loss: 1.0952 - val_accuracy: 0.5018\n",
      "Epoch 1832/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3311 - val_loss: 1.1113 - val_accuracy: 0.0947\n",
      "Epoch 1833/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3167 - val_loss: 1.0955 - val_accuracy: 0.5018\n",
      "Epoch 1834/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3014 - val_loss: 1.0934 - val_accuracy: 0.4035\n",
      "Epoch 1835/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3086 - val_loss: 1.0923 - val_accuracy: 0.4035\n",
      "Epoch 1836/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3011 - accuracy: 0.3080 - val_loss: 1.1166 - val_accuracy: 0.0947\n",
      "Epoch 1837/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3070 - val_loss: 1.0928 - val_accuracy: 0.5018\n",
      "Epoch 1838/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3314 - val_loss: 1.0996 - val_accuracy: 0.4035\n",
      "Epoch 1839/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3128 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 1840/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3052 - val_loss: 1.1239 - val_accuracy: 0.0947\n",
      "Epoch 1841/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2985 - val_loss: 1.0872 - val_accuracy: 0.4035\n",
      "Epoch 1842/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3170 - val_loss: 1.0853 - val_accuracy: 0.4035\n",
      "Epoch 1843/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3034 - val_loss: 1.1013 - val_accuracy: 0.0947\n",
      "Epoch 1844/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3101 - val_loss: 1.1114 - val_accuracy: 0.0947\n",
      "Epoch 1845/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3197 - val_loss: 1.1237 - val_accuracy: 0.0947\n",
      "Epoch 1846/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3000 - val_loss: 1.1070 - val_accuracy: 0.0947\n",
      "Epoch 1847/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3077 - val_loss: 1.0709 - val_accuracy: 0.5018\n",
      "Epoch 1848/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3025 - val_loss: 1.0733 - val_accuracy: 0.5018\n",
      "Epoch 1849/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2991 - val_loss: 1.0817 - val_accuracy: 0.4035\n",
      "Epoch 1850/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3091 - val_loss: 1.1024 - val_accuracy: 0.0947\n",
      "Epoch 1851/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2963 - val_loss: 1.1066 - val_accuracy: 0.0947\n",
      "Epoch 1852/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2905 - val_loss: 1.1232 - val_accuracy: 0.0947\n",
      "Epoch 1853/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3069 - val_loss: 1.0979 - val_accuracy: 0.4035\n",
      "Epoch 1854/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3288 - val_loss: 1.0654 - val_accuracy: 0.5018\n",
      "Epoch 1855/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3283 - val_loss: 1.0929 - val_accuracy: 0.4035\n",
      "Epoch 1856/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3054 - val_loss: 1.1056 - val_accuracy: 0.0947\n",
      "Epoch 1857/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3140 - val_loss: 1.1256 - val_accuracy: 0.0947\n",
      "Epoch 1858/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3247 - val_loss: 1.0846 - val_accuracy: 0.5018\n",
      "Epoch 1859/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3004 - val_loss: 1.0872 - val_accuracy: 0.4035\n",
      "Epoch 1860/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3126 - val_loss: 1.1213 - val_accuracy: 0.0947\n",
      "Epoch 1861/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2974 - val_loss: 1.0767 - val_accuracy: 0.4035\n",
      "Epoch 1862/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3156 - val_loss: 1.0867 - val_accuracy: 0.5018\n",
      "Epoch 1863/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3183 - val_loss: 1.0819 - val_accuracy: 0.4035\n",
      "Epoch 1864/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2902 - val_loss: 1.1271 - val_accuracy: 0.0947\n",
      "Epoch 1865/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3074 - val_loss: 1.1254 - val_accuracy: 0.0947\n",
      "Epoch 1866/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3024 - val_loss: 1.1005 - val_accuracy: 0.5018\n",
      "Epoch 1867/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3064 - val_loss: 1.1212 - val_accuracy: 0.0947\n",
      "Epoch 1868/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3199 - val_loss: 1.1086 - val_accuracy: 0.0947\n",
      "Epoch 1869/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3158 - val_loss: 1.1051 - val_accuracy: 0.0947\n",
      "Epoch 1870/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3126 - val_loss: 1.0726 - val_accuracy: 0.5018\n",
      "Epoch 1871/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3167 - val_loss: 1.1277 - val_accuracy: 0.0947\n",
      "Epoch 1872/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2993 - val_loss: 1.0680 - val_accuracy: 0.4035\n",
      "Epoch 1873/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3099 - val_loss: 1.1007 - val_accuracy: 0.5018\n",
      "Epoch 1874/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3050 - val_loss: 1.0801 - val_accuracy: 0.5018\n",
      "Epoch 1875/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3215 - val_loss: 1.1300 - val_accuracy: 0.0947\n",
      "Epoch 1876/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3151 - val_loss: 1.1157 - val_accuracy: 0.0947\n",
      "Epoch 1877/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3149 - val_loss: 1.0970 - val_accuracy: 0.4035\n",
      "Epoch 1878/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3120 - val_loss: 1.1300 - val_accuracy: 0.0947\n",
      "Epoch 1879/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3089 - val_loss: 1.1159 - val_accuracy: 0.0947\n",
      "Epoch 1880/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3098 - val_loss: 1.0896 - val_accuracy: 0.5018\n",
      "Epoch 1881/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3103 - val_loss: 1.1145 - val_accuracy: 0.0947\n",
      "Epoch 1882/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2890 - val_loss: 1.0818 - val_accuracy: 0.5018\n",
      "Epoch 1883/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3106 - val_loss: 1.0831 - val_accuracy: 0.4035\n",
      "Epoch 1884/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3156 - val_loss: 1.1214 - val_accuracy: 0.0947\n",
      "Epoch 1885/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3168 - val_loss: 1.0827 - val_accuracy: 0.4035\n",
      "Epoch 1886/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3012 - val_loss: 1.0806 - val_accuracy: 0.4035\n",
      "Epoch 1887/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3276 - val_loss: 1.1022 - val_accuracy: 0.4035\n",
      "Epoch 1888/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2939 - val_loss: 1.0889 - val_accuracy: 0.4035\n",
      "Epoch 1889/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3146 - val_loss: 1.0999 - val_accuracy: 0.0947\n",
      "Epoch 1890/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3081 - val_loss: 1.0861 - val_accuracy: 0.5018\n",
      "Epoch 1891/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3148 - val_loss: 1.0812 - val_accuracy: 0.5018\n",
      "Epoch 1892/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3102 - val_loss: 1.1167 - val_accuracy: 0.0947\n",
      "Epoch 1893/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3020 - val_loss: 1.0769 - val_accuracy: 0.4035\n",
      "Epoch 1894/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3236 - val_loss: 1.0975 - val_accuracy: 0.5018\n",
      "Epoch 1895/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3186 - val_loss: 1.0930 - val_accuracy: 0.5018\n",
      "Epoch 1896/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3156 - val_loss: 1.0991 - val_accuracy: 0.0947\n",
      "Epoch 1897/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3024 - val_loss: 1.0729 - val_accuracy: 0.5018\n",
      "Epoch 1898/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3207 - val_loss: 1.1022 - val_accuracy: 0.5018\n",
      "Epoch 1899/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3215 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 1900/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3127 - val_loss: 1.0967 - val_accuracy: 0.5018\n",
      "Epoch 1901/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2944 - val_loss: 1.1050 - val_accuracy: 0.0947\n",
      "Epoch 1902/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3130 - val_loss: 1.1221 - val_accuracy: 0.0947\n",
      "Epoch 1903/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3149 - val_loss: 1.1168 - val_accuracy: 0.0947\n",
      "Epoch 1904/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3205 - val_loss: 1.1227 - val_accuracy: 0.0947\n",
      "Epoch 1905/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3234 - val_loss: 1.1113 - val_accuracy: 0.0947\n",
      "Epoch 1906/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3009 - val_loss: 1.0896 - val_accuracy: 0.4035\n",
      "Epoch 1907/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3149 - val_loss: 1.1078 - val_accuracy: 0.0947\n",
      "Epoch 1908/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2922 - val_loss: 1.0966 - val_accuracy: 0.5018\n",
      "Epoch 1909/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3146 - val_loss: 1.0958 - val_accuracy: 0.5018\n",
      "Epoch 1910/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.2893 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 1911/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3075 - val_loss: 1.0859 - val_accuracy: 0.4035\n",
      "Epoch 1912/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3165 - val_loss: 1.0838 - val_accuracy: 0.5018\n",
      "Epoch 1913/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3187 - val_loss: 1.0910 - val_accuracy: 0.5018\n",
      "Epoch 1914/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3116 - val_loss: 1.1003 - val_accuracy: 0.4035\n",
      "Epoch 1915/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3169 - val_loss: 1.1135 - val_accuracy: 0.0947\n",
      "Epoch 1916/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3059 - val_loss: 1.1128 - val_accuracy: 0.0947\n",
      "Epoch 1917/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2883 - val_loss: 1.1094 - val_accuracy: 0.4035\n",
      "Epoch 1918/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3098 - val_loss: 1.0830 - val_accuracy: 0.4035\n",
      "Epoch 1919/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3153 - val_loss: 1.1285 - val_accuracy: 0.0947\n",
      "Epoch 1920/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3105 - val_loss: 1.1044 - val_accuracy: 0.4035\n",
      "Epoch 1921/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3105 - val_loss: 1.0790 - val_accuracy: 0.4035\n",
      "Epoch 1922/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3050 - val_loss: 1.0922 - val_accuracy: 0.5018\n",
      "Epoch 1923/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3044 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 1924/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3042 - val_loss: 1.0652 - val_accuracy: 0.4035\n",
      "Epoch 1925/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2926 - val_loss: 1.0915 - val_accuracy: 0.4035\n",
      "Epoch 1926/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3112 - val_loss: 1.0886 - val_accuracy: 0.4035\n",
      "Epoch 1927/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3107 - val_loss: 1.0899 - val_accuracy: 0.4035\n",
      "Epoch 1928/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3134 - val_loss: 1.1031 - val_accuracy: 0.0947\n",
      "Epoch 1929/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3114 - val_loss: 1.0964 - val_accuracy: 0.4035\n",
      "Epoch 1930/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3113 - val_loss: 1.1133 - val_accuracy: 0.0947\n",
      "Epoch 1931/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3050 - val_loss: 1.0887 - val_accuracy: 0.5018\n",
      "Epoch 1932/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2886 - val_loss: 1.1001 - val_accuracy: 0.5018\n",
      "Epoch 1933/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3145 - val_loss: 1.1154 - val_accuracy: 0.0947\n",
      "Epoch 1934/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3086 - val_loss: 1.0989 - val_accuracy: 0.5018\n",
      "Epoch 1935/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3209 - val_loss: 1.1557 - val_accuracy: 0.0947\n",
      "Epoch 1936/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2997 - val_loss: 1.0681 - val_accuracy: 0.4035\n",
      "Epoch 1937/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2987 - val_loss: 1.0970 - val_accuracy: 0.4035\n",
      "Epoch 1938/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3433 - val_loss: 1.1112 - val_accuracy: 0.0947\n",
      "Epoch 1939/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3147 - val_loss: 1.0800 - val_accuracy: 0.5018\n",
      "Epoch 1940/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3140 - val_loss: 1.1176 - val_accuracy: 0.0947\n",
      "Epoch 1941/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2879 - val_loss: 1.0941 - val_accuracy: 0.4035\n",
      "Epoch 1942/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2899 - val_loss: 1.1135 - val_accuracy: 0.0947\n",
      "Epoch 1943/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.3073 - val_loss: 1.0974 - val_accuracy: 0.5018\n",
      "Epoch 1944/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3334 - val_loss: 1.1229 - val_accuracy: 0.0947\n",
      "Epoch 1945/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2975 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 1946/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3228 - val_loss: 1.0848 - val_accuracy: 0.4035\n",
      "Epoch 1947/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2996 - val_loss: 1.1258 - val_accuracy: 0.0947\n",
      "Epoch 1948/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3043 - val_loss: 1.1110 - val_accuracy: 0.0947\n",
      "Epoch 1949/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2998 - val_loss: 1.1275 - val_accuracy: 0.0947\n",
      "Epoch 1950/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3075 - val_loss: 1.0867 - val_accuracy: 0.5018\n",
      "Epoch 1951/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3017 - val_loss: 1.1369 - val_accuracy: 0.0947\n",
      "Epoch 1952/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2862 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 1953/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3106 - val_loss: 1.0899 - val_accuracy: 0.5018\n",
      "Epoch 1954/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2991 - val_loss: 1.0980 - val_accuracy: 0.4035\n",
      "Epoch 1955/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3330 - val_loss: 1.1095 - val_accuracy: 0.0947\n",
      "Epoch 1956/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3121 - val_loss: 1.0815 - val_accuracy: 0.4035\n",
      "Epoch 1957/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3046 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 1958/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3049 - val_loss: 1.1118 - val_accuracy: 0.0947\n",
      "Epoch 1959/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2992 - accuracy: 0.3042 - val_loss: 1.1014 - val_accuracy: 0.0947\n",
      "Epoch 1960/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2985 - val_loss: 1.1243 - val_accuracy: 0.0947\n",
      "Epoch 1961/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3147 - val_loss: 1.0876 - val_accuracy: 0.4035\n",
      "Epoch 1962/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3012 - accuracy: 0.3130 - val_loss: 1.1197 - val_accuracy: 0.0947\n",
      "Epoch 1963/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.2849 - val_loss: 1.1158 - val_accuracy: 0.0947\n",
      "Epoch 1964/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3032 - val_loss: 1.1057 - val_accuracy: 0.0947\n",
      "Epoch 1965/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3075 - val_loss: 1.1093 - val_accuracy: 0.0947\n",
      "Epoch 1966/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3301 - val_loss: 1.0872 - val_accuracy: 0.5018\n",
      "Epoch 1967/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3124 - val_loss: 1.0691 - val_accuracy: 0.4035\n",
      "Epoch 1968/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3234 - val_loss: 1.1157 - val_accuracy: 0.0947\n",
      "Epoch 1969/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3108 - val_loss: 1.1144 - val_accuracy: 0.0947\n",
      "Epoch 1970/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2954 - val_loss: 1.0885 - val_accuracy: 0.4035\n",
      "Epoch 1971/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3122 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 1972/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3228 - val_loss: 1.1355 - val_accuracy: 0.0947\n",
      "Epoch 1973/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3153 - val_loss: 1.0701 - val_accuracy: 0.4035\n",
      "Epoch 1974/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3118 - val_loss: 1.1168 - val_accuracy: 0.0947\n",
      "Epoch 1975/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3108 - val_loss: 1.0884 - val_accuracy: 0.4035\n",
      "Epoch 1976/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3033 - val_loss: 1.1061 - val_accuracy: 0.0947\n",
      "Epoch 1977/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2958 - val_loss: 1.1178 - val_accuracy: 0.0947\n",
      "Epoch 1978/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2955 - val_loss: 1.0957 - val_accuracy: 0.4035\n",
      "Epoch 1979/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3014 - val_loss: 1.1274 - val_accuracy: 0.0947\n",
      "Epoch 1980/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3203 - val_loss: 1.0977 - val_accuracy: 0.5018\n",
      "Epoch 1981/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3024 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 1982/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3201 - val_loss: 1.0672 - val_accuracy: 0.4035\n",
      "Epoch 1983/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3075 - val_loss: 1.1229 - val_accuracy: 0.0947\n",
      "Epoch 1984/2000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3056 - val_loss: 1.1083 - val_accuracy: 0.0947\n",
      "Epoch 1985/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3137 - val_loss: 1.0916 - val_accuracy: 0.5018\n",
      "Epoch 1986/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3076 - val_loss: 1.0997 - val_accuracy: 0.0947\n",
      "Epoch 1987/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2921 - val_loss: 1.0841 - val_accuracy: 0.4035\n",
      "Epoch 1988/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2878 - val_loss: 1.1048 - val_accuracy: 0.0947\n",
      "Epoch 1989/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3015 - val_loss: 1.1256 - val_accuracy: 0.0947\n",
      "Epoch 1990/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3034 - val_loss: 1.1258 - val_accuracy: 0.0947\n",
      "Epoch 1991/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3048 - val_loss: 1.0779 - val_accuracy: 0.5018\n",
      "Epoch 1992/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3060 - val_loss: 1.1256 - val_accuracy: 0.0947\n",
      "Epoch 1993/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3103 - val_loss: 1.1206 - val_accuracy: 0.0947\n",
      "Epoch 1994/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3155 - val_loss: 1.1237 - val_accuracy: 0.0947\n",
      "Epoch 1995/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3012 - accuracy: 0.2996 - val_loss: 1.0967 - val_accuracy: 0.4035\n",
      "Epoch 1996/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3076 - val_loss: 1.1357 - val_accuracy: 0.0947\n",
      "Epoch 1997/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3134 - val_loss: 1.1083 - val_accuracy: 0.0947\n",
      "Epoch 1998/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2993 - accuracy: 0.2999 - val_loss: 1.1092 - val_accuracy: 0.0947\n",
      "Epoch 1999/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3147 - val_loss: 1.0918 - val_accuracy: 0.4035\n",
      "Epoch 2000/2000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2949 - val_loss: 1.1200 - val_accuracy: 0.0947\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=2000,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpoint_cb],\n",
    "                    batch_size=2048,\n",
    "                    class_weight=class_weights_dict\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2001/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2955 - val_loss: 1.1002 - val_accuracy: 0.0947\n",
      "Epoch 2002/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.2992 - val_loss: 1.1058 - val_accuracy: 0.4035\n",
      "Epoch 2003/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3106 - val_loss: 1.0868 - val_accuracy: 0.5018\n",
      "Epoch 2004/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3093 - val_loss: 1.0888 - val_accuracy: 0.4035\n",
      "Epoch 2005/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3074 - val_loss: 1.0906 - val_accuracy: 0.5018\n",
      "Epoch 2006/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3101 - val_loss: 1.0675 - val_accuracy: 0.5018\n",
      "Epoch 2007/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3084 - val_loss: 1.1108 - val_accuracy: 0.0947\n",
      "Epoch 2008/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3042 - val_loss: 1.1329 - val_accuracy: 0.0947\n",
      "Epoch 2009/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3164 - val_loss: 1.1033 - val_accuracy: 0.0947\n",
      "Epoch 2010/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3056 - val_loss: 1.0892 - val_accuracy: 0.5018\n",
      "Epoch 2011/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3008 - val_loss: 1.1217 - val_accuracy: 0.0947\n",
      "Epoch 2012/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3182 - val_loss: 1.1087 - val_accuracy: 0.4035\n",
      "Epoch 2013/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3119 - val_loss: 1.1031 - val_accuracy: 0.4035\n",
      "Epoch 2014/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2954 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 2015/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2916 - val_loss: 1.0996 - val_accuracy: 0.4035\n",
      "Epoch 2016/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3002 - val_loss: 1.1059 - val_accuracy: 0.0947\n",
      "Epoch 2017/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3082 - val_loss: 1.1183 - val_accuracy: 0.0947\n",
      "Epoch 2018/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3006 - val_loss: 1.0776 - val_accuracy: 0.4035\n",
      "Epoch 2019/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2996 - val_loss: 1.0953 - val_accuracy: 0.5018\n",
      "Epoch 2020/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3161 - val_loss: 1.1334 - val_accuracy: 0.0947\n",
      "Epoch 2021/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3009 - val_loss: 1.1065 - val_accuracy: 0.0947\n",
      "Epoch 2022/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3127 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 2023/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3129 - val_loss: 1.0956 - val_accuracy: 0.4035\n",
      "Epoch 2024/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.3077 - val_loss: 1.0954 - val_accuracy: 0.4035\n",
      "Epoch 2025/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3219 - val_loss: 1.1165 - val_accuracy: 0.0947\n",
      "Epoch 2026/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.2927 - val_loss: 1.1229 - val_accuracy: 0.0947\n",
      "Epoch 2027/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3013 - val_loss: 1.0824 - val_accuracy: 0.5018\n",
      "Epoch 2028/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3176 - val_loss: 1.0982 - val_accuracy: 0.4035\n",
      "Epoch 2029/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3075 - val_loss: 1.0870 - val_accuracy: 0.4035\n",
      "Epoch 2030/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3197 - val_loss: 1.0853 - val_accuracy: 0.5018\n",
      "Epoch 2031/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3204 - val_loss: 1.0890 - val_accuracy: 0.5018\n",
      "Epoch 2032/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3060 - val_loss: 1.1173 - val_accuracy: 0.0947\n",
      "Epoch 2033/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2968 - val_loss: 1.0848 - val_accuracy: 0.4035\n",
      "Epoch 2034/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3064 - val_loss: 1.0950 - val_accuracy: 0.5018\n",
      "Epoch 2035/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2932 - val_loss: 1.0790 - val_accuracy: 0.5018\n",
      "Epoch 2036/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3081 - val_loss: 1.0849 - val_accuracy: 0.5018\n",
      "Epoch 2037/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3467 - val_loss: 1.0890 - val_accuracy: 0.5018\n",
      "Epoch 2038/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3027 - val_loss: 1.0991 - val_accuracy: 0.4035\n",
      "Epoch 2039/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3081 - val_loss: 1.1295 - val_accuracy: 0.0947\n",
      "Epoch 2040/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3257 - val_loss: 1.0919 - val_accuracy: 0.5018\n",
      "Epoch 2041/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3034 - val_loss: 1.0837 - val_accuracy: 0.5018\n",
      "Epoch 2042/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3125 - val_loss: 1.0968 - val_accuracy: 0.5018\n",
      "Epoch 2043/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3045 - val_loss: 1.0991 - val_accuracy: 0.5018\n",
      "Epoch 2044/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3026 - val_loss: 1.1096 - val_accuracy: 0.0947\n",
      "Epoch 2045/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3056 - val_loss: 1.0880 - val_accuracy: 0.4035\n",
      "Epoch 2046/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3010 - val_loss: 1.0916 - val_accuracy: 0.4035\n",
      "Epoch 2047/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3116 - val_loss: 1.0969 - val_accuracy: 0.5018\n",
      "Epoch 2048/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3088 - val_loss: 1.1062 - val_accuracy: 0.0947\n",
      "Epoch 2049/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3053 - val_loss: 1.0788 - val_accuracy: 0.5018\n",
      "Epoch 2050/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3093 - val_loss: 1.0868 - val_accuracy: 0.5018\n",
      "Epoch 2051/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3047 - val_loss: 1.1078 - val_accuracy: 0.0947\n",
      "Epoch 2052/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3164 - val_loss: 1.1191 - val_accuracy: 0.0947\n",
      "Epoch 2053/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2978 - val_loss: 1.0725 - val_accuracy: 0.4035\n",
      "Epoch 2054/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2941 - val_loss: 1.0787 - val_accuracy: 0.4035\n",
      "Epoch 2055/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3073 - val_loss: 1.0778 - val_accuracy: 0.4035\n",
      "Epoch 2056/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3040 - val_loss: 1.0987 - val_accuracy: 0.4035\n",
      "Epoch 2057/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.2993 - val_loss: 1.0937 - val_accuracy: 0.4035\n",
      "Epoch 2058/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3087 - val_loss: 1.0890 - val_accuracy: 0.5018\n",
      "Epoch 2059/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2941 - val_loss: 1.0775 - val_accuracy: 0.5018\n",
      "Epoch 2060/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3178 - val_loss: 1.1121 - val_accuracy: 0.0947\n",
      "Epoch 2061/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2992 - accuracy: 0.3153 - val_loss: 1.0836 - val_accuracy: 0.4035\n",
      "Epoch 2062/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3136 - val_loss: 1.0957 - val_accuracy: 0.4035\n",
      "Epoch 2063/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3266 - val_loss: 1.0748 - val_accuracy: 0.5018\n",
      "Epoch 2064/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3052 - val_loss: 1.1240 - val_accuracy: 0.0947\n",
      "Epoch 2065/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3166 - val_loss: 1.0965 - val_accuracy: 0.4035\n",
      "Epoch 2066/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3077 - val_loss: 1.0904 - val_accuracy: 0.4035\n",
      "Epoch 2067/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3066 - val_loss: 1.1011 - val_accuracy: 0.0947\n",
      "Epoch 2068/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3113 - val_loss: 1.0844 - val_accuracy: 0.5018\n",
      "Epoch 2069/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.2900 - val_loss: 1.0953 - val_accuracy: 0.5018\n",
      "Epoch 2070/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3000 - val_loss: 1.0754 - val_accuracy: 0.5018\n",
      "Epoch 2071/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.2996 - val_loss: 1.0886 - val_accuracy: 0.4035\n",
      "Epoch 2072/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3038 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 2073/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3009 - val_loss: 1.0811 - val_accuracy: 0.5018\n",
      "Epoch 2074/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3092 - val_loss: 1.0857 - val_accuracy: 0.5018\n",
      "Epoch 2075/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3202 - val_loss: 1.1304 - val_accuracy: 0.0947\n",
      "Epoch 2076/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3016 - accuracy: 0.3113 - val_loss: 1.1038 - val_accuracy: 0.0947\n",
      "Epoch 2077/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2877 - val_loss: 1.1240 - val_accuracy: 0.0947\n",
      "Epoch 2078/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2998 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 2079/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3010 - accuracy: 0.3028 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 2080/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3249 - val_loss: 1.0816 - val_accuracy: 0.4035\n",
      "Epoch 2081/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3067 - val_loss: 1.0928 - val_accuracy: 0.4035\n",
      "Epoch 2082/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2920 - val_loss: 1.0797 - val_accuracy: 0.4035\n",
      "Epoch 2083/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3048 - val_loss: 1.0959 - val_accuracy: 0.5018\n",
      "Epoch 2084/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3224 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 2085/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3164 - val_loss: 1.0731 - val_accuracy: 0.5018\n",
      "Epoch 2086/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3009 - val_loss: 1.0946 - val_accuracy: 0.4035\n",
      "Epoch 2087/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3130 - val_loss: 1.1047 - val_accuracy: 0.4035\n",
      "Epoch 2088/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3059 - val_loss: 1.0857 - val_accuracy: 0.5018\n",
      "Epoch 2089/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3094 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 2090/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3188 - val_loss: 1.1168 - val_accuracy: 0.0947\n",
      "Epoch 2091/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3063 - val_loss: 1.0817 - val_accuracy: 0.5018\n",
      "Epoch 2092/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3192 - val_loss: 1.0903 - val_accuracy: 0.5018\n",
      "Epoch 2093/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.2972 - val_loss: 1.1237 - val_accuracy: 0.0947\n",
      "Epoch 2094/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3110 - val_loss: 1.0787 - val_accuracy: 0.4035\n",
      "Epoch 2095/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3154 - val_loss: 1.1179 - val_accuracy: 0.0947\n",
      "Epoch 2096/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3070 - val_loss: 1.1010 - val_accuracy: 0.5018\n",
      "Epoch 2097/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3082 - val_loss: 1.1027 - val_accuracy: 0.0947\n",
      "Epoch 2098/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3214 - val_loss: 1.1074 - val_accuracy: 0.0947\n",
      "Epoch 2099/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3085 - val_loss: 1.1180 - val_accuracy: 0.0947\n",
      "Epoch 2100/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2986 - val_loss: 1.1020 - val_accuracy: 0.4035\n",
      "Epoch 2101/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3044 - val_loss: 1.0773 - val_accuracy: 0.5018\n",
      "Epoch 2102/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3277 - val_loss: 1.1029 - val_accuracy: 0.5018\n",
      "Epoch 2103/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3090 - val_loss: 1.0809 - val_accuracy: 0.5018\n",
      "Epoch 2104/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3192 - val_loss: 1.0932 - val_accuracy: 0.4035\n",
      "Epoch 2105/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3222 - val_loss: 1.0691 - val_accuracy: 0.5018\n",
      "Epoch 2106/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3171 - val_loss: 1.0814 - val_accuracy: 0.5018\n",
      "Epoch 2107/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3009 - val_loss: 1.1142 - val_accuracy: 0.0947\n",
      "Epoch 2108/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2984 - val_loss: 1.0702 - val_accuracy: 0.5018\n",
      "Epoch 2109/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3104 - val_loss: 1.0978 - val_accuracy: 0.5018\n",
      "Epoch 2110/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3197 - val_loss: 1.1011 - val_accuracy: 0.4035\n",
      "Epoch 2111/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3061 - val_loss: 1.0778 - val_accuracy: 0.5018\n",
      "Epoch 2112/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.3073 - val_loss: 1.0990 - val_accuracy: 0.4035\n",
      "Epoch 2113/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.2994 - val_loss: 1.0737 - val_accuracy: 0.4035\n",
      "Epoch 2114/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3118 - val_loss: 1.0822 - val_accuracy: 0.4035\n",
      "Epoch 2115/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3239 - val_loss: 1.0730 - val_accuracy: 0.5018\n",
      "Epoch 2116/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3006 - val_loss: 1.0937 - val_accuracy: 0.4035\n",
      "Epoch 2117/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3010 - accuracy: 0.3225 - val_loss: 1.0958 - val_accuracy: 0.4035\n",
      "Epoch 2118/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3028 - val_loss: 1.1424 - val_accuracy: 0.0947\n",
      "Epoch 2119/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3149 - val_loss: 1.1027 - val_accuracy: 0.4035\n",
      "Epoch 2120/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2978 - val_loss: 1.1043 - val_accuracy: 0.0947\n",
      "Epoch 2121/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3033 - val_loss: 1.1193 - val_accuracy: 0.0947\n",
      "Epoch 2122/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3123 - val_loss: 1.0761 - val_accuracy: 0.4035\n",
      "Epoch 2123/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.2994 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 2124/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3234 - val_loss: 1.1001 - val_accuracy: 0.0947\n",
      "Epoch 2125/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3054 - val_loss: 1.1001 - val_accuracy: 0.5018\n",
      "Epoch 2126/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3097 - val_loss: 1.0985 - val_accuracy: 0.5018\n",
      "Epoch 2127/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3235 - val_loss: 1.1168 - val_accuracy: 0.0947\n",
      "Epoch 2128/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3055 - val_loss: 1.1090 - val_accuracy: 0.0947\n",
      "Epoch 2129/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3091 - val_loss: 1.0751 - val_accuracy: 0.4035\n",
      "Epoch 2130/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2975 - val_loss: 1.0842 - val_accuracy: 0.4035\n",
      "Epoch 2131/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3073 - val_loss: 1.0922 - val_accuracy: 0.5018\n",
      "Epoch 2132/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3078 - val_loss: 1.0890 - val_accuracy: 0.4035\n",
      "Epoch 2133/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3142 - val_loss: 1.0993 - val_accuracy: 0.5018\n",
      "Epoch 2134/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3181 - val_loss: 1.0769 - val_accuracy: 0.5018\n",
      "Epoch 2135/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3062 - val_loss: 1.0926 - val_accuracy: 0.5018\n",
      "Epoch 2136/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3117 - val_loss: 1.1331 - val_accuracy: 0.0947\n",
      "Epoch 2137/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3157 - val_loss: 1.1475 - val_accuracy: 0.0947\n",
      "Epoch 2138/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3148 - val_loss: 1.0896 - val_accuracy: 0.5018\n",
      "Epoch 2139/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3208 - val_loss: 1.1378 - val_accuracy: 0.0947\n",
      "Epoch 2140/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2965 - val_loss: 1.0733 - val_accuracy: 0.5018\n",
      "Epoch 2141/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3078 - val_loss: 1.0746 - val_accuracy: 0.5018\n",
      "Epoch 2142/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.2828 - val_loss: 1.0914 - val_accuracy: 0.4035\n",
      "Epoch 2143/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3133 - val_loss: 1.1003 - val_accuracy: 0.5018\n",
      "Epoch 2144/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3082 - val_loss: 1.1141 - val_accuracy: 0.4035\n",
      "Epoch 2145/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2859 - val_loss: 1.0931 - val_accuracy: 0.5018\n",
      "Epoch 2146/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3055 - val_loss: 1.0864 - val_accuracy: 0.5018\n",
      "Epoch 2147/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3064 - val_loss: 1.0896 - val_accuracy: 0.5018\n",
      "Epoch 2148/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3006 - val_loss: 1.0950 - val_accuracy: 0.5018\n",
      "Epoch 2149/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3047 - val_loss: 1.1127 - val_accuracy: 0.0947\n",
      "Epoch 2150/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2959 - val_loss: 1.0643 - val_accuracy: 0.4035\n",
      "Epoch 2151/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3096 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 2152/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3049 - val_loss: 1.0998 - val_accuracy: 0.4035\n",
      "Epoch 2153/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.2983 - val_loss: 1.0873 - val_accuracy: 0.5018\n",
      "Epoch 2154/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3039 - val_loss: 1.0970 - val_accuracy: 0.5018\n",
      "Epoch 2155/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2993 - accuracy: 0.2912 - val_loss: 1.0921 - val_accuracy: 0.5018\n",
      "Epoch 2156/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3017 - val_loss: 1.0973 - val_accuracy: 0.4035\n",
      "Epoch 2157/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3107 - val_loss: 1.1010 - val_accuracy: 0.4035\n",
      "Epoch 2158/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.2995 - val_loss: 1.0694 - val_accuracy: 0.5018\n",
      "Epoch 2159/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3054 - val_loss: 1.1147 - val_accuracy: 0.4035\n",
      "Epoch 2160/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3009 - accuracy: 0.2993 - val_loss: 1.0856 - val_accuracy: 0.5018\n",
      "Epoch 2161/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3149 - val_loss: 1.0893 - val_accuracy: 0.5018\n",
      "Epoch 2162/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3121 - val_loss: 1.1013 - val_accuracy: 0.4035\n",
      "Epoch 2163/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3176 - val_loss: 1.0957 - val_accuracy: 0.4035\n",
      "Epoch 2164/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3415 - val_loss: 1.1019 - val_accuracy: 0.5018\n",
      "Epoch 2165/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3248 - val_loss: 1.0900 - val_accuracy: 0.5018\n",
      "Epoch 2166/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3009 - accuracy: 0.3196 - val_loss: 1.1093 - val_accuracy: 0.0947\n",
      "Epoch 2167/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3048 - val_loss: 1.0786 - val_accuracy: 0.5018\n",
      "Epoch 2168/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3192 - val_loss: 1.0834 - val_accuracy: 0.4035\n",
      "Epoch 2169/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3159 - val_loss: 1.0961 - val_accuracy: 0.4035\n",
      "Epoch 2170/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3082 - val_loss: 1.0994 - val_accuracy: 0.4035\n",
      "Epoch 2171/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3018 - val_loss: 1.1178 - val_accuracy: 0.0947\n",
      "Epoch 2172/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2936 - val_loss: 1.1221 - val_accuracy: 0.0947\n",
      "Epoch 2173/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3151 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 2174/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3103 - val_loss: 1.1030 - val_accuracy: 0.4035\n",
      "Epoch 2175/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3240 - val_loss: 1.1037 - val_accuracy: 0.0947\n",
      "Epoch 2176/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.2858 - val_loss: 1.1017 - val_accuracy: 0.4035\n",
      "Epoch 2177/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2932 - val_loss: 1.0743 - val_accuracy: 0.4035\n",
      "Epoch 2178/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3069 - val_loss: 1.1054 - val_accuracy: 0.0947\n",
      "Epoch 2179/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3101 - val_loss: 1.0989 - val_accuracy: 0.5018\n",
      "Epoch 2180/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3187 - val_loss: 1.1330 - val_accuracy: 0.0947\n",
      "Epoch 2181/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2913 - val_loss: 1.1413 - val_accuracy: 0.0947\n",
      "Epoch 2182/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3141 - val_loss: 1.0916 - val_accuracy: 0.5018\n",
      "Epoch 2183/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3084 - val_loss: 1.1239 - val_accuracy: 0.0947\n",
      "Epoch 2184/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3157 - val_loss: 1.1333 - val_accuracy: 0.0947\n",
      "Epoch 2185/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3171 - val_loss: 1.1035 - val_accuracy: 0.0947\n",
      "Epoch 2186/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3095 - val_loss: 1.0792 - val_accuracy: 0.5018\n",
      "Epoch 2187/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2929 - val_loss: 1.0857 - val_accuracy: 0.4035\n",
      "Epoch 2188/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3129 - val_loss: 1.0669 - val_accuracy: 0.4035\n",
      "Epoch 2189/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3219 - val_loss: 1.0783 - val_accuracy: 0.5018\n",
      "Epoch 2190/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3009 - accuracy: 0.3061 - val_loss: 1.1138 - val_accuracy: 0.0947\n",
      "Epoch 2191/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3068 - val_loss: 1.1048 - val_accuracy: 0.0947\n",
      "Epoch 2192/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2891 - val_loss: 1.0746 - val_accuracy: 0.5018\n",
      "Epoch 2193/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.2971 - val_loss: 1.0916 - val_accuracy: 0.5018\n",
      "Epoch 2194/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3064 - val_loss: 1.1039 - val_accuracy: 0.0947\n",
      "Epoch 2195/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3029 - val_loss: 1.1105 - val_accuracy: 0.0947\n",
      "Epoch 2196/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3061 - val_loss: 1.0838 - val_accuracy: 0.4035\n",
      "Epoch 2197/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3084 - val_loss: 1.0785 - val_accuracy: 0.5018\n",
      "Epoch 2198/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3004 - val_loss: 1.1145 - val_accuracy: 0.0947\n",
      "Epoch 2199/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3190 - val_loss: 1.1000 - val_accuracy: 0.0947\n",
      "Epoch 2200/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3019 - val_loss: 1.1272 - val_accuracy: 0.0947\n",
      "Epoch 2201/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3159 - val_loss: 1.1240 - val_accuracy: 0.0947\n",
      "Epoch 2202/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3220 - val_loss: 1.1095 - val_accuracy: 0.5018\n",
      "Epoch 2203/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3205 - val_loss: 1.0982 - val_accuracy: 0.5018\n",
      "Epoch 2204/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3082 - val_loss: 1.0884 - val_accuracy: 0.4035\n",
      "Epoch 2205/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3010 - val_loss: 1.0963 - val_accuracy: 0.4035\n",
      "Epoch 2206/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3007 - val_loss: 1.1182 - val_accuracy: 0.0947\n",
      "Epoch 2207/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3081 - val_loss: 1.0917 - val_accuracy: 0.4035\n",
      "Epoch 2208/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3036 - val_loss: 1.0700 - val_accuracy: 0.4035\n",
      "Epoch 2209/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3173 - val_loss: 1.1321 - val_accuracy: 0.0947\n",
      "Epoch 2210/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3011 - accuracy: 0.2872 - val_loss: 1.1295 - val_accuracy: 0.0947\n",
      "Epoch 2211/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3105 - val_loss: 1.1160 - val_accuracy: 0.0947\n",
      "Epoch 2212/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3185 - val_loss: 1.1079 - val_accuracy: 0.0947\n",
      "Epoch 2213/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3213 - val_loss: 1.0951 - val_accuracy: 0.4035\n",
      "Epoch 2214/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.2921 - val_loss: 1.0668 - val_accuracy: 0.5018\n",
      "Epoch 2215/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3052 - val_loss: 1.0940 - val_accuracy: 0.5018\n",
      "Epoch 2216/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3044 - val_loss: 1.0974 - val_accuracy: 0.4035\n",
      "Epoch 2217/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2988 - val_loss: 1.0909 - val_accuracy: 0.4035\n",
      "Epoch 2218/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2996 - val_loss: 1.0999 - val_accuracy: 0.0947\n",
      "Epoch 2219/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3060 - val_loss: 1.0707 - val_accuracy: 0.4035\n",
      "Epoch 2220/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3122 - val_loss: 1.1019 - val_accuracy: 0.0947\n",
      "Epoch 2221/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3007 - accuracy: 0.3023 - val_loss: 1.0770 - val_accuracy: 0.5018\n",
      "Epoch 2222/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3169 - val_loss: 1.1091 - val_accuracy: 0.0947\n",
      "Epoch 2223/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3124 - val_loss: 1.0780 - val_accuracy: 0.5018\n",
      "Epoch 2224/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3132 - val_loss: 1.1270 - val_accuracy: 0.0947\n",
      "Epoch 2225/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3095 - val_loss: 1.1105 - val_accuracy: 0.0947\n",
      "Epoch 2226/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2969 - val_loss: 1.1137 - val_accuracy: 0.4035\n",
      "Epoch 2227/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3102 - val_loss: 1.1171 - val_accuracy: 0.0947\n",
      "Epoch 2228/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3022 - val_loss: 1.0971 - val_accuracy: 0.4035\n",
      "Epoch 2229/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3072 - val_loss: 1.1253 - val_accuracy: 0.0947\n",
      "Epoch 2230/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3018 - val_loss: 1.1018 - val_accuracy: 0.0947\n",
      "Epoch 2231/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3085 - val_loss: 1.0622 - val_accuracy: 0.5018\n",
      "Epoch 2232/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3135 - val_loss: 1.1137 - val_accuracy: 0.0947\n",
      "Epoch 2233/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3236 - val_loss: 1.1226 - val_accuracy: 0.0947\n",
      "Epoch 2234/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3079 - val_loss: 1.0985 - val_accuracy: 0.4035\n",
      "Epoch 2235/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3017 - val_loss: 1.1150 - val_accuracy: 0.0947\n",
      "Epoch 2236/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3171 - val_loss: 1.0837 - val_accuracy: 0.4035\n",
      "Epoch 2237/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3134 - val_loss: 1.0702 - val_accuracy: 0.5018\n",
      "Epoch 2238/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3152 - val_loss: 1.0955 - val_accuracy: 0.4035\n",
      "Epoch 2239/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3031 - val_loss: 1.0977 - val_accuracy: 0.4035\n",
      "Epoch 2240/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3046 - val_loss: 1.0923 - val_accuracy: 0.4035\n",
      "Epoch 2241/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3076 - val_loss: 1.1009 - val_accuracy: 0.4035\n",
      "Epoch 2242/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3043 - val_loss: 1.1072 - val_accuracy: 0.0947\n",
      "Epoch 2243/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3153 - val_loss: 1.0839 - val_accuracy: 0.5018\n",
      "Epoch 2244/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3146 - val_loss: 1.0891 - val_accuracy: 0.5018\n",
      "Epoch 2245/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2994 - val_loss: 1.1211 - val_accuracy: 0.0947\n",
      "Epoch 2246/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3080 - val_loss: 1.1100 - val_accuracy: 0.0947\n",
      "Epoch 2247/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3000 - val_loss: 1.0793 - val_accuracy: 0.4035\n",
      "Epoch 2248/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3044 - val_loss: 1.0719 - val_accuracy: 0.5018\n",
      "Epoch 2249/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3112 - val_loss: 1.0704 - val_accuracy: 0.4035\n",
      "Epoch 2250/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3102 - val_loss: 1.1029 - val_accuracy: 0.0947\n",
      "Epoch 2251/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3072 - val_loss: 1.1024 - val_accuracy: 0.5018\n",
      "Epoch 2252/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3236 - val_loss: 1.0837 - val_accuracy: 0.5018\n",
      "Epoch 2253/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.2960 - val_loss: 1.0927 - val_accuracy: 0.5018\n",
      "Epoch 2254/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3259 - val_loss: 1.0812 - val_accuracy: 0.5018\n",
      "Epoch 2255/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2982 - val_loss: 1.1089 - val_accuracy: 0.0947\n",
      "Epoch 2256/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3019 - val_loss: 1.0936 - val_accuracy: 0.4035\n",
      "Epoch 2257/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2921 - val_loss: 1.0571 - val_accuracy: 0.5018\n",
      "Epoch 2258/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3127 - val_loss: 1.1194 - val_accuracy: 0.0947\n",
      "Epoch 2259/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3051 - val_loss: 1.1108 - val_accuracy: 0.0947\n",
      "Epoch 2260/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3029 - val_loss: 1.1001 - val_accuracy: 0.4035\n",
      "Epoch 2261/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3202 - val_loss: 1.0790 - val_accuracy: 0.5018\n",
      "Epoch 2262/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2951 - val_loss: 1.0806 - val_accuracy: 0.5018\n",
      "Epoch 2263/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3022 - val_loss: 1.1057 - val_accuracy: 0.0947\n",
      "Epoch 2264/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.2987 - val_loss: 1.1210 - val_accuracy: 0.0947\n",
      "Epoch 2265/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3015 - val_loss: 1.0943 - val_accuracy: 0.5018\n",
      "Epoch 2266/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3035 - val_loss: 1.1016 - val_accuracy: 0.4035\n",
      "Epoch 2267/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2923 - val_loss: 1.0899 - val_accuracy: 0.4035\n",
      "Epoch 2268/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3260 - val_loss: 1.1087 - val_accuracy: 0.0947\n",
      "Epoch 2269/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3036 - val_loss: 1.1115 - val_accuracy: 0.0947\n",
      "Epoch 2270/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3060 - val_loss: 1.1301 - val_accuracy: 0.0947\n",
      "Epoch 2271/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3224 - val_loss: 1.0818 - val_accuracy: 0.5018\n",
      "Epoch 2272/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3071 - val_loss: 1.1166 - val_accuracy: 0.0947\n",
      "Epoch 2273/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3063 - val_loss: 1.0908 - val_accuracy: 0.4035\n",
      "Epoch 2274/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.2982 - val_loss: 1.1249 - val_accuracy: 0.0947\n",
      "Epoch 2275/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2997 - accuracy: 0.3170 - val_loss: 1.0815 - val_accuracy: 0.5018\n",
      "Epoch 2276/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2895 - val_loss: 1.1170 - val_accuracy: 0.0947\n",
      "Epoch 2277/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3092 - val_loss: 1.0869 - val_accuracy: 0.4035\n",
      "Epoch 2278/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.2926 - val_loss: 1.0983 - val_accuracy: 0.5018\n",
      "Epoch 2279/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3130 - val_loss: 1.0982 - val_accuracy: 0.5018\n",
      "Epoch 2280/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3156 - val_loss: 1.1031 - val_accuracy: 0.0947\n",
      "Epoch 2281/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3154 - val_loss: 1.1029 - val_accuracy: 0.4035\n",
      "Epoch 2282/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3118 - val_loss: 1.1046 - val_accuracy: 0.4035\n",
      "Epoch 2283/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3031 - val_loss: 1.1058 - val_accuracy: 0.0947\n",
      "Epoch 2284/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3019 - val_loss: 1.0913 - val_accuracy: 0.5018\n",
      "Epoch 2285/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3114 - val_loss: 1.1130 - val_accuracy: 0.0947\n",
      "Epoch 2286/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3132 - val_loss: 1.0849 - val_accuracy: 0.5018\n",
      "Epoch 2287/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3024 - val_loss: 1.1208 - val_accuracy: 0.0947\n",
      "Epoch 2288/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3144 - val_loss: 1.0996 - val_accuracy: 0.4035\n",
      "Epoch 2289/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.2992 - val_loss: 1.1044 - val_accuracy: 0.0947\n",
      "Epoch 2290/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3021 - val_loss: 1.1022 - val_accuracy: 0.0947\n",
      "Epoch 2291/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3191 - val_loss: 1.0981 - val_accuracy: 0.4035\n",
      "Epoch 2292/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3217 - val_loss: 1.1286 - val_accuracy: 0.0947\n",
      "Epoch 2293/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3008 - accuracy: 0.3079 - val_loss: 1.1028 - val_accuracy: 0.0947\n",
      "Epoch 2294/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3043 - val_loss: 1.0701 - val_accuracy: 0.5018\n",
      "Epoch 2295/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3195 - val_loss: 1.1059 - val_accuracy: 0.4035\n",
      "Epoch 2296/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3165 - val_loss: 1.1086 - val_accuracy: 0.0947\n",
      "Epoch 2297/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3015 - val_loss: 1.0962 - val_accuracy: 0.5018\n",
      "Epoch 2298/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3177 - val_loss: 1.1116 - val_accuracy: 0.0947\n",
      "Epoch 2299/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3049 - val_loss: 1.1220 - val_accuracy: 0.0947\n",
      "Epoch 2300/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3152 - val_loss: 1.0649 - val_accuracy: 0.4035\n",
      "Epoch 2301/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3125 - val_loss: 1.0750 - val_accuracy: 0.5018\n",
      "Epoch 2302/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3083 - val_loss: 1.1013 - val_accuracy: 0.0947\n",
      "Epoch 2303/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3151 - val_loss: 1.1080 - val_accuracy: 0.0947\n",
      "Epoch 2304/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3101 - val_loss: 1.0951 - val_accuracy: 0.5018\n",
      "Epoch 2305/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3067 - val_loss: 1.0983 - val_accuracy: 0.5018\n",
      "Epoch 2306/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3040 - val_loss: 1.0960 - val_accuracy: 0.5018\n",
      "Epoch 2307/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3018 - val_loss: 1.1022 - val_accuracy: 0.5018\n",
      "Epoch 2308/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3091 - val_loss: 1.0974 - val_accuracy: 0.4035\n",
      "Epoch 2309/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3116 - val_loss: 1.0966 - val_accuracy: 0.5018\n",
      "Epoch 2310/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3168 - val_loss: 1.1103 - val_accuracy: 0.0947\n",
      "Epoch 2311/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2999 - accuracy: 0.3045 - val_loss: 1.0979 - val_accuracy: 0.5018\n",
      "Epoch 2312/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.2961 - val_loss: 1.0890 - val_accuracy: 0.4035\n",
      "Epoch 2313/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3012 - accuracy: 0.3070 - val_loss: 1.0922 - val_accuracy: 0.4035\n",
      "Epoch 2314/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3003 - val_loss: 1.1084 - val_accuracy: 0.0947\n",
      "Epoch 2315/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.3147 - val_loss: 1.1206 - val_accuracy: 0.0947\n",
      "Epoch 2316/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.2975 - val_loss: 1.1110 - val_accuracy: 0.0947\n",
      "Epoch 2317/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3010 - val_loss: 1.0901 - val_accuracy: 0.4035\n",
      "Epoch 2318/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2961 - val_loss: 1.0739 - val_accuracy: 0.4035\n",
      "Epoch 2319/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.3264 - val_loss: 1.1087 - val_accuracy: 0.0947\n",
      "Epoch 2320/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3138 - val_loss: 1.0918 - val_accuracy: 0.4035\n",
      "Epoch 2321/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3007 - val_loss: 1.1218 - val_accuracy: 0.0947\n",
      "Epoch 2322/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3006 - accuracy: 0.2938 - val_loss: 1.1139 - val_accuracy: 0.0947\n",
      "Epoch 2323/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2971 - val_loss: 1.0945 - val_accuracy: 0.4035\n",
      "Epoch 2324/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3125 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 2325/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2994 - accuracy: 0.3272 - val_loss: 1.1061 - val_accuracy: 0.4035\n",
      "Epoch 2326/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3042 - val_loss: 1.0961 - val_accuracy: 0.5018\n",
      "Epoch 2327/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3130 - val_loss: 1.1128 - val_accuracy: 0.0947\n",
      "Epoch 2328/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2996 - accuracy: 0.3049 - val_loss: 1.1220 - val_accuracy: 0.0947\n",
      "Epoch 2329/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3130 - val_loss: 1.1010 - val_accuracy: 0.4035\n",
      "Epoch 2330/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3202 - val_loss: 1.0926 - val_accuracy: 0.5018\n",
      "Epoch 2331/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3220 - val_loss: 1.1080 - val_accuracy: 0.4035\n",
      "Epoch 2332/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3177 - val_loss: 1.0872 - val_accuracy: 0.5018\n",
      "Epoch 2333/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3075 - val_loss: 1.1153 - val_accuracy: 0.0947\n",
      "Epoch 2334/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3110 - val_loss: 1.1029 - val_accuracy: 0.0947\n",
      "Epoch 2335/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3020 - val_loss: 1.1308 - val_accuracy: 0.0947\n",
      "Epoch 2336/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3012 - accuracy: 0.3087 - val_loss: 1.1391 - val_accuracy: 0.0947\n",
      "Epoch 2337/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3388 - val_loss: 1.1226 - val_accuracy: 0.0947\n",
      "Epoch 2338/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3169 - val_loss: 1.0967 - val_accuracy: 0.5018\n",
      "Epoch 2339/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3032 - val_loss: 1.1064 - val_accuracy: 0.0947\n",
      "Epoch 2340/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3049 - val_loss: 1.1031 - val_accuracy: 0.0947\n",
      "Epoch 2341/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.2947 - val_loss: 1.0964 - val_accuracy: 0.5018\n",
      "Epoch 2342/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3079 - val_loss: 1.0665 - val_accuracy: 0.4035\n",
      "Epoch 2343/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3003 - accuracy: 0.3063 - val_loss: 1.0868 - val_accuracy: 0.4035\n",
      "Epoch 2344/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3114 - val_loss: 1.0926 - val_accuracy: 0.5018\n",
      "Epoch 2345/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.2987 - val_loss: 1.1135 - val_accuracy: 0.0947\n",
      "Epoch 2346/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3066 - val_loss: 1.1198 - val_accuracy: 0.0947\n",
      "Epoch 2347/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3017 - val_loss: 1.0763 - val_accuracy: 0.5018\n",
      "Epoch 2348/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2998 - accuracy: 0.3163 - val_loss: 1.1124 - val_accuracy: 0.0947\n",
      "Epoch 2349/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3034 - val_loss: 1.0935 - val_accuracy: 0.4035\n",
      "Epoch 2350/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2968 - val_loss: 1.0987 - val_accuracy: 0.5018\n",
      "Epoch 2351/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2996 - accuracy: 0.3018 - val_loss: 1.1052 - val_accuracy: 0.4035\n",
      "Epoch 2352/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.2918 - val_loss: 1.0762 - val_accuracy: 0.4035\n",
      "Epoch 2353/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3002 - accuracy: 0.3067 - val_loss: 1.0893 - val_accuracy: 0.4035\n",
      "Epoch 2354/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2914 - val_loss: 1.1263 - val_accuracy: 0.0947\n",
      "Epoch 2355/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.3101 - val_loss: 1.1210 - val_accuracy: 0.0947\n",
      "Epoch 2356/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3007 - accuracy: 0.2996 - val_loss: 1.0784 - val_accuracy: 0.5018\n",
      "Epoch 2357/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2985 - val_loss: 1.0948 - val_accuracy: 0.4035\n",
      "Epoch 2358/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3112 - val_loss: 1.0951 - val_accuracy: 0.4035\n",
      "Epoch 2359/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3001 - accuracy: 0.3150 - val_loss: 1.0920 - val_accuracy: 0.5018\n",
      "Epoch 2360/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2995 - accuracy: 0.3315 - val_loss: 1.0860 - val_accuracy: 0.4035\n",
      "Epoch 2361/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3004 - accuracy: 0.3042 - val_loss: 1.1089 - val_accuracy: 0.0947\n",
      "Epoch 2362/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3000 - accuracy: 0.2958 - val_loss: 1.0780 - val_accuracy: 0.4035\n",
      "Epoch 2363/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.2994 - accuracy: 0.2973 - val_loss: 1.0955 - val_accuracy: 0.4035\n",
      "Epoch 2364/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.2937 - val_loss: 1.0757 - val_accuracy: 0.5018\n",
      "Epoch 2365/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3003 - accuracy: 0.3243 - val_loss: 1.1257 - val_accuracy: 0.0947\n",
      "Epoch 2366/200000\n",
      "351/351 [==============================] - 2s 5ms/step - loss: 3.3005 - accuracy: 0.2981 - val_loss: 1.0989 - val_accuracy: 0.4035\n",
      "Epoch 2367/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2995 - accuracy: 0.3078 - val_loss: 1.1114 - val_accuracy: 0.0947\n",
      "Epoch 2368/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3095 - val_loss: 1.1118 - val_accuracy: 0.0947\n",
      "Epoch 2369/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3002 - accuracy: 0.3107 - val_loss: 1.1169 - val_accuracy: 0.0947\n",
      "Epoch 2370/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2998 - accuracy: 0.3052 - val_loss: 1.0886 - val_accuracy: 0.4035\n",
      "Epoch 2371/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3005 - accuracy: 0.3074 - val_loss: 1.1017 - val_accuracy: 0.5018\n",
      "Epoch 2372/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3010 - val_loss: 1.0867 - val_accuracy: 0.4035\n",
      "Epoch 2373/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2997 - accuracy: 0.3204 - val_loss: 1.1036 - val_accuracy: 0.5018\n",
      "Epoch 2374/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3030 - val_loss: 1.0899 - val_accuracy: 0.4035\n",
      "Epoch 2375/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3006 - accuracy: 0.3178 - val_loss: 1.0998 - val_accuracy: 0.5018\n",
      "Epoch 2376/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3001 - accuracy: 0.3082 - val_loss: 1.1125 - val_accuracy: 0.0947\n",
      "Epoch 2377/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3008 - accuracy: 0.3162 - val_loss: 1.0957 - val_accuracy: 0.5018\n",
      "Epoch 2378/200000\n",
      "351/351 [==============================] - 5s 13ms/step - loss: 3.3001 - accuracy: 0.3103 - val_loss: 1.1160 - val_accuracy: 0.4035\n",
      "Epoch 2379/200000\n",
      "351/351 [==============================] - 3s 10ms/step - loss: 3.2997 - accuracy: 0.3097 - val_loss: 1.0930 - val_accuracy: 0.5018\n",
      "Epoch 2380/200000\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 3.3000 - accuracy: 0.3190 - val_loss: 1.1120 - val_accuracy: 0.0947\n",
      "Epoch 2381/200000\n",
      "351/351 [==============================] - 3s 9ms/step - loss: 3.3001 - accuracy: 0.3107 - val_loss: 1.0956 - val_accuracy: 0.5018\n",
      "Epoch 2382/200000\n",
      "351/351 [==============================] - 2s 7ms/step - loss: 3.2997 - accuracy: 0.3132 - val_loss: 1.1002 - val_accuracy: 0.5018\n",
      "Epoch 2383/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.2953 - val_loss: 1.0744 - val_accuracy: 0.4035\n",
      "Epoch 2384/200000\n",
      "351/351 [==============================] - 2s 7ms/step - loss: 3.2998 - accuracy: 0.2907 - val_loss: 1.1018 - val_accuracy: 0.5018\n",
      "Epoch 2385/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3224 - val_loss: 1.0973 - val_accuracy: 0.5018\n",
      "Epoch 2386/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.2999 - accuracy: 0.3038 - val_loss: 1.1186 - val_accuracy: 0.0947\n",
      "Epoch 2387/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3000 - accuracy: 0.3054 - val_loss: 1.0884 - val_accuracy: 0.5018\n",
      "Epoch 2388/200000\n",
      "351/351 [==============================] - 2s 6ms/step - loss: 3.3004 - accuracy: 0.3184 - val_loss: 1.0925 - val_accuracy: 0.5018\n",
      "Epoch 2389/200000\n",
      "343/351 [============================>.] - ETA: 0s - loss: 3.2995 - accuracy: 0.3061"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1606\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1593\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1594\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1604\u001b[0m         steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1605\u001b[0m     )\n\u001b[1;32m-> 1606\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1618\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1619\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1620\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   1621\u001b[0m }\n\u001b[0;32m   1622\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Andy\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200000, initial_epoch=2000,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[checkpoint_cb],\n",
    "                    batch_size=2048,\n",
    "                    class_weight=class_weights_dict\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(X_test, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33608276, 0.339707  , 0.32421026]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
